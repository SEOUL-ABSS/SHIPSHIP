{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuTPs8nlELpofvoY37cmUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/SHIPSHIP/blob/main/SONAR6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#                 DeepShip/MBARI 수중 음향 분류 프로젝트 (Data Leakage 해결 최종본)\n",
        "# ==============================================================================\n",
        "# 이 프로젝트는 YAMNet 모델을 이용하여 수중 음향 데이터를 분류하는 안정적이고 재현 가능한\n",
        "# 베이스라인 파이프라인을 구축합니다. 최종 전문가 검토 의견을 반영하여 치명적 오류,\n",
        "# 데이터 누수, 재현성 문제를 해결하고, 평가 파트를 강화하여 심층적인 분석을 수행합니다.\n",
        "#\n",
        "# [주요 개선 사항]\n",
        "# 1. 데이터 유출 방지: GroupShuffleSplit을 사용하여 세그먼트가 아닌 파일 단위로 데이터를 분할.\n",
        "#                      이를 통해 동일 파일의 세그먼트가 훈련/테스트셋에 섞이는 것을 원천 차단.\n",
        "# 2. 안정성 및 재현성: 이전 검토 의견을 모두 반영하여 안정적인 파이프라인 유지.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 1. 환경 설정 및 라이브러리 임포트\n",
        "# ==============================================================================\n",
        "print(\"1. 환경 설정 및 라이브러리 임포트 중...\")\n",
        "\n",
        "# --- 라이브러리 설치 ---\n",
        "!pip install -q tensorflow tensorflow_hub soundfile librosa boto3 noisereduce umap-learn\n",
        "\n",
        "# --- 모든 라이브러리 임포트 ---\n",
        "import os, sys, subprocess, random, tempfile, shutil, gc, math\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa, librosa.display, soundfile as sf\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit # << GroupShuffleSplit 추가\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import umap.umap_ as umap\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# 평가지표 확장을 위해 추가\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import noisereduce as nr\n",
        "\n",
        "# --- 전역 시드 설정 (재현성 확보) ---\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- Matplotlib 한글 폰트 설정 ---\n",
        "!sudo apt-get -y install fonts-nanum > /dev/null\n",
        "!sudo fc-cache -fv > /dev/null\n",
        "import matplotlib.font_manager as fm\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "if os.path.exists(font_path):\n",
        "    fm.fontManager.addfont(font_path); plt.rc('font', family='NanumGothic'); plt.rcParams['axes.unicode_minus'] = False\n",
        "    print(\"\\nMatplotlib 폰트 설정 완료: NanumGothic\")\n",
        "else:\n",
        "    print(\"\\n경고: 나눔고딕 폰트를 찾을 수 없습니다.\")\n",
        "\n",
        "# --- 전역 상수 정의 ---\n",
        "print(\"\\n전역 상수 정의 중...\")\n",
        "YAMNET_SAMPLE_RATE = 16000\n",
        "DEEPSHIP_BASE_PATH = '/content/DeepShip'\n",
        "MBARI_NOISE_BASE_DIR = '/content/MBARI_noise_data'\n",
        "MODELS_TO_PROCESS = ['YAMNet']\n",
        "print(\"전역 상수 정의 완료.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 2. 데이터 확보\n",
        "# ==============================================================================\n",
        "print(\"\\n2. 데이터 확보...\")\n",
        "if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    try:\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', 'https://github.com/irfankamboh/DeepShip.git', DEEPSHIP_BASE_PATH], check=True, capture_output=True)\n",
        "        print(\"DeepShip 클론 완료.\")\n",
        "    except Exception as e: print(f\"오류: DeepShip 클론 실패: {e}\")\n",
        "else: print(f\"DeepShip이 이미 존재합니다.\")\n",
        "\n",
        "os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "if os.listdir(MBARI_NOISE_BASE_DIR): print(f\"MBARI 노이즈 데이터가 이미 존재합니다.\")\n",
        "else:\n",
        "    print(f\"MBARI 노이즈 데이터 다운로드 시도 중...\")\n",
        "    try:\n",
        "        s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "        pages = s3.get_paginator('list_objects_v2').paginate(Bucket='pacific-sound-16khz', Prefix='2018/01/')\n",
        "        dl_count = 0; MAX_DL = 10\n",
        "        for page in pages:\n",
        "            for obj in page.get('Contents', []):\n",
        "                if obj['Key'].endswith('.wav') and obj.get('Size', 0) > 0:\n",
        "                    local_path = os.path.join(MBARI_NOISE_BASE_DIR, os.path.basename(obj['Key']))\n",
        "                    if not os.path.exists(local_path):\n",
        "                        s3.download_file('pacific-sound-16khz', obj['Key'], local_path)\n",
        "                        dl_count += 1\n",
        "                if dl_count >= MAX_DL: break\n",
        "            if dl_count >= MAX_DL: break\n",
        "        print(f\"MBARI 다운로드 완료. (파일 수: {dl_count})\")\n",
        "    except Exception as e: print(f\"오류: MBARI 노이즈 데이터 다운로드 실패: {e}\")\n",
        "print(\"2. 데이터 확보 단계 완료.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 3. 데이터 처리 및 세그먼테이션 함수 정의\n",
        "# ==============================================================================\n",
        "def load_and_segment_data(ship_path, noise_path, segment_duration=5.0, segment_overlap=0.5, undersample=True):\n",
        "    hop_length = segment_duration * (1 - segment_overlap)\n",
        "    all_data = []\n",
        "\n",
        "    def _process_directory(base_path, label):\n",
        "        segments = []\n",
        "        print(f\"'{label}' 클래스 데이터 처리 중: {base_path}\")\n",
        "        if not os.path.exists(base_path): return segments\n",
        "        for root, _, files in os.walk(base_path):\n",
        "            for file_name in sorted(files):\n",
        "                if file_name.endswith('.wav'):\n",
        "                    file_path = os.path.join(root, file_name)\n",
        "                    try:\n",
        "                        info = sf.info(file_path)\n",
        "                        duration = info.duration\n",
        "                        if duration < segment_duration: continue\n",
        "                        for start_time in np.arange(0, duration - segment_duration + 1, hop_length):\n",
        "                            segments.append(((file_path, start_time, info.samplerate), label))\n",
        "                    except Exception as e: continue\n",
        "        print(f\"  '{label}' 클래스에서 총 {len(segments)}개의 세그먼트 생성 완료.\")\n",
        "        return segments\n",
        "\n",
        "    ship_data = _process_directory(ship_path, 'ship')\n",
        "    noise_data = _process_directory(noise_path, 'noise')\n",
        "    all_data = ship_data + noise_data\n",
        "\n",
        "    if undersample and ship_data and noise_data:\n",
        "        n_ship = len(ship_data)\n",
        "        n_noise = len(noise_data)\n",
        "        if n_ship != n_noise:\n",
        "            min_samples = min(n_ship, n_noise)\n",
        "            print(f\"\\n클래스 불균형(Ship:{n_ship}, Noise:{n_noise}) -> 언더샘플링({min_samples}개) 수행.\")\n",
        "            ship_samples = random.sample(ship_data, min_samples)\n",
        "            noise_samples = random.sample(noise_data, min_samples)\n",
        "            all_data = ship_samples + noise_samples\n",
        "            random.shuffle(all_data)\n",
        "\n",
        "    if not all_data: print(\"\\n오류: 처리할 세그먼트가 없습니다.\"); return [], [], False\n",
        "    all_segments_info, all_labels = zip(*all_data)\n",
        "    print(\"\\n데이터 로드 및 세그먼테이션 완료.\")\n",
        "    return list(all_segments_info), list(all_labels), True\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 4. 전처리 데이터셋 품질 평가 함수 정의\n",
        "# ==============================================================================\n",
        "def visualize_embeddings_with_umap(embeddings, labels, class_names):\n",
        "    print(\"\\n[데이터 품질 평가] UMAP 임베딩 시각화 실행 중...\")\n",
        "    if len(embeddings) < 3:\n",
        "        print(\"  UMAP: 표본이 3개 미만이어서 시각화를 생략합니다.\")\n",
        "        return\n",
        "    n_neighbors = max(2, min(15, len(embeddings) - 1))\n",
        "    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=0.1, n_components=2, random_state=SEED)\n",
        "    embeddings_2d = reducer.fit_transform(embeddings)\n",
        "    df = pd.DataFrame(embeddings_2d, columns=['x', 'y']); df['label'] = [class_names[l] for l in labels]\n",
        "    plt.figure(figsize=(10, 8)); sns.scatterplot(data=df, x='x', y='y', hue='label', style='label', s=50, alpha=0.7)\n",
        "    plt.title('UMAP을 이용한 임베딩 분포 시각화 (학습 전 진단)'); plt.grid(True); plt.show()\n",
        "\n",
        "def visualize_spectrogram_samples(segments_info, labels, class_names, segment_duration, num_samples=3):\n",
        "    print(\"\\n[데이터 품질 평가] 스펙트로그램 샘플 시각화 실행 중...\")\n",
        "    unique_labels = np.unique(labels)\n",
        "    fig, axes = plt.subplots(len(unique_labels), num_samples, figsize=(5*num_samples, 4*len(unique_labels)), squeeze=False)\n",
        "    fig.suptitle('클래스별 스펙트로그램 샘플', fontsize=16)\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        if not len(indices): continue\n",
        "        sample_indices = random.sample(list(indices), min(num_samples, len(indices)))\n",
        "        for j, idx in enumerate(sample_indices):\n",
        "            file_path, start_time, _ = segments_info[idx]\n",
        "            ax = axes[i, j]\n",
        "            try:\n",
        "                y, _ = librosa.load(file_path, sr=YAMNET_SAMPLE_RATE, offset=start_time, duration=segment_duration)\n",
        "                D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "                librosa.display.specshow(D, sr=YAMNET_SAMPLE_RATE, x_axis='time', y_axis='log', ax=ax)\n",
        "                ax.set_title(f\"{class_names[label]} Sample {j+1}\")\n",
        "            except Exception as e: ax.set_title(f\"오디오 로드 실패\")\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]); plt.show()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 5. 오디오 전처리 및 임베딩 추출 함수 정의\n",
        "# ==============================================================================\n",
        "def mix_at_snr(clean, noise, snr_db):\n",
        "    L = min(len(clean), len(noise))\n",
        "    c, n = clean[:L].astype(np.float32), noise[:L].astype(np.float32)\n",
        "    c_power = np.sqrt(np.mean(c**2)); n_power = np.sqrt(np.mean(n**2))\n",
        "    if n_power < 1e-8: return c\n",
        "    alpha = c_power / (n_power * (10**(snr_db / 20)))\n",
        "    return c + alpha * n\n",
        "\n",
        "def load_and_process_segment_efficient(file_info, duration, target_sr, config):\n",
        "    file_path, start_time, orig_sr = file_info\n",
        "    try:\n",
        "        start_frame = int(start_time * orig_sr)\n",
        "        num_frames = int(duration * orig_sr)\n",
        "        y_segment, _ = sf.read(file_path, start=start_frame, stop=start_frame + num_frames, dtype='float32', always_2d=False)\n",
        "        if y_segment.ndim > 1: y_segment = np.mean(y_segment, axis=1)\n",
        "        if orig_sr != target_sr: y_segment = librosa.resample(y=y_segment, orig_sr=orig_sr, target_sr=target_sr)\n",
        "        if config.get(\"apply_noise_reduction\", False): y_segment = nr.reduce_noise(y=y_segment, sr=target_sr)\n",
        "        if config.get(\"apply_rms_norm\", False):\n",
        "            rms = np.sqrt(np.mean(y_segment**2))\n",
        "            if rms > 1e-6: y_segment = y_segment * (10.0**(-20.0/20.0)/rms)\n",
        "        return y_segment\n",
        "    except Exception as e: return None\n",
        "\n",
        "def extract_yamnet_embedding(audio_info, model, config, noise_audio_infos=None, augment=False):\n",
        "    try:\n",
        "        y_segment = load_and_process_segment_efficient(audio_info, config[\"segment_duration\"], YAMNET_SAMPLE_RATE, config)\n",
        "        if y_segment is None: return None\n",
        "        if augment and noise_audio_infos:\n",
        "            noise_info = random.choice(noise_audio_infos)\n",
        "            y_noise = load_and_process_segment_efficient(noise_info, config[\"segment_duration\"], YAMNET_SAMPLE_RATE, {\"apply_noise_reduction\":False, \"apply_rms_norm\":True})\n",
        "            if y_noise is not None:\n",
        "                if config.get(\"use_snr_augmentation\", False):\n",
        "                    snr_db = random.uniform(config[\"snr_min_db\"], config[\"snr_max_db\"])\n",
        "                    y_segment = mix_at_snr(y_segment, y_noise, snr_db)\n",
        "                else:\n",
        "                    min_len = min(len(y_segment), len(y_noise))\n",
        "                    y_segment = y_segment[:min_len] + y_noise[:min_len] * config[\"noise_level\"]\n",
        "        _, embeddings, _ = model(y_segment)\n",
        "        return tf.reduce_mean(embeddings, axis=0).numpy() if embeddings.shape[0] > 0 else None\n",
        "    except Exception as e: return None\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 6. 모델 관련 함수 정의 (평가 파트 강화)\n",
        "# ==============================================================================\n",
        "def load_audio_models():\n",
        "    models = {}; print(\"\\n오디오 모델 로드 중...\")\n",
        "    try:\n",
        "        models['YAMNet'] = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "        print(\"  YAMNet 모델 로드: 성공\"); return models, True\n",
        "    except Exception as e:\n",
        "        print(f\"  모델 로드 실패: {e}\"); return {}, False\n",
        "\n",
        "def build_classifier_model(input_shape, num_classes, learning_rate):\n",
        "    inp = Input(shape=(input_shape,), name='embedding_input')\n",
        "    x = Dense(256, activation='relu')(inp); x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x); x = Dropout(0.5)(x)\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def analyze_top_errors(y_true, y_pred_probs, segments_info, class_names, top_k=5):\n",
        "    \"\"\"모델이 가장 헷갈려하는 Top-K 오류 샘플을 분석하고 스펙트로그램을 시각화합니다.\"\"\"\n",
        "    print(f\"\\n--- Top-{top_k} 오류 심층 분석 ---\")\n",
        "    errors = []\n",
        "    ship_idx = list(class_names).index('ship')\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_label = y_true[i]\n",
        "        pred_label = np.argmax(y_pred_probs[i])\n",
        "\n",
        "        if true_label != pred_label:\n",
        "            error_magnitude = 0; error_type = \"\"\n",
        "            if pred_label == ship_idx: # False Positive (Noise -> Ship)\n",
        "                error_type = \"FP (Noise->Ship)\"; error_magnitude = y_pred_probs[i][ship_idx]\n",
        "            else: # False Negative (Ship -> Noise)\n",
        "                error_type = \"FN (Ship->Noise)\"; error_magnitude = 1 - y_pred_probs[i][ship_idx]\n",
        "            errors.append({\n",
        "                \"index\": i, \"type\": error_type, \"magnitude\": error_magnitude, \"info\": segments_info[i],\n",
        "                \"true_label\": class_names[true_label], \"pred_label\": class_names[pred_label],\n",
        "                \"confidence\": y_pred_probs[i][pred_label]\n",
        "            })\n",
        "\n",
        "    sorted_errors = sorted(errors, key=lambda x: x['magnitude'], reverse=True)\n",
        "    if not sorted_errors: print(\"  오류가 발견되지 않았습니다.\"); return\n",
        "\n",
        "    print(f\"가장 확신하며 틀린 {min(top_k, len(sorted_errors))}개 샘플:\")\n",
        "    for error in sorted_errors[:top_k]:\n",
        "        print(f\"  - 타입: {error['type']}, 신뢰도: {error['confidence']:.2f}, 실제: {error['true_label']}, 예측: {error['pred_label']}\")\n",
        "        print(f\"    - 파일: {os.path.basename(error['info'][0])} (시작: {error['info'][1]:.2f}s)\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, min(top_k, len(sorted_errors)), figsize=(5*min(top_k, len(sorted_errors)), 4), squeeze=False)\n",
        "    fig.suptitle('Top-K 오류 샘플 스펙트로그램', fontsize=16)\n",
        "    for i, error in enumerate(sorted_errors[:top_k]):\n",
        "        ax = axes[0, i]\n",
        "        file_path, start_time, _ = error['info']\n",
        "        try:\n",
        "            y, _ = librosa.load(file_path, sr=YAMNET_SAMPLE_RATE, offset=start_time, duration=5.0)\n",
        "            D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "            librosa.display.specshow(D, sr=YAMNET_SAMPLE_RATE, x_axis='time', y_axis='log', ax=ax)\n",
        "            ax.set_title(f\"{error['type']}\\nTrue:{error['true_label']}, Pred:{error['pred_label']} ({error['confidence']:.2f})\")\n",
        "        except Exception as e: ax.set_title(\"로드 실패\")\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.93]); plt.show()\n",
        "\n",
        "def evaluate_and_visualize_model(model_name, trained_model, history, test_ds, test_steps, y_true_filtered, test_segments_info, label_encoder):\n",
        "    print(f\"\\n--- {model_name} 모델 성능 평가 및 시각화 ---\")\n",
        "    loss, accuracy = trained_model.evaluate(test_ds, steps=test_steps, verbose=0)\n",
        "    y_pred_probs = trained_model.predict(test_ds, steps=test_steps)\n",
        "    if len(y_pred_probs) != len(y_true_filtered): y_pred_probs = y_pred_probs[:len(y_true_filtered)]\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    report_dict = classification_report(y_true_filtered, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    f1_macro = report_dict['macro avg']['f1-score']\n",
        "\n",
        "    ship_idx = list(label_encoder.classes_).index('ship')\n",
        "    y_scores = y_pred_probs[:, ship_idx]\n",
        "    fpr, tpr, _ = roc_curve(y_true_filtered, y_scores, pos_label=ship_idx)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "\n",
        "    print(f\"  테스트 손실: {loss:.4f}, 정확도: {accuracy:.4f}, Macro F1: {f1_macro:.4f}, AUC: {auc_score:.4f}\")\n",
        "\n",
        "    print(\"\\n  [분류 리포트]\"); print(classification_report(y_true_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "    cm = confusion_matrix(y_true_filtered, y_pred)\n",
        "    plt.figure(figsize=(6, 5)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "    plt.xlabel('예측 레이블'); plt.ylabel('실제 레이블'); plt.title(f'{model_name} 혼동 행렬'); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 6)); plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--'); plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('Receiver Operating Characteristic (ROC) Curve'); plt.legend(loc=\"lower right\"); plt.grid(True); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 5)); plt.subplot(1, 2, 1); plt.plot(history.history['accuracy'], label='훈련 정확도'); plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "    plt.title('훈련 및 검증 정확도'); plt.legend(); plt.subplot(1, 2, 2); plt.plot(history.history['loss'], label='훈련 손실'); plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "    plt.title('훈련 및 검증 손실'); plt.legend(); plt.show()\n",
        "\n",
        "    analyze_top_errors(y_true_filtered, y_pred_probs, test_segments_info, label_encoder.classes_)\n",
        "\n",
        "    return {'loss': loss, 'accuracy': accuracy, 'f1_macro': f1_macro, 'auc': auc_score}\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 7. 전체 파이프라인 실행 및 결과 비교\n",
        "# ==============================================================================\n",
        "CONFIG = {\n",
        "    \"segment_duration\": 5.0, \"segment_overlap\": 0.5, \"undersample\": True,\n",
        "    \"apply_noise_reduction\": False, \"apply_rms_norm\": True,\n",
        "    \"use_snr_augmentation\": True, \"snr_min_db\": 0, \"snr_max_db\": 15, \"noise_level\": 0.05,\n",
        "    \"run_quality_evaluation\": True, \"quality_eval_samples\": 300,\n",
        "    \"test_size\": 0.2, \"epochs\": 50, \"batch_size\": 16, \"learning_rate\": 0.0005,\n",
        "}\n",
        "\n",
        "print(\">>> 1. 데이터 로드 및 세그먼테이션 시작...\")\n",
        "all_segments_info, all_labels, is_data_ready = load_and_segment_data(DEEPSHIP_BASE_PATH, MBARI_NOISE_BASE_DIR, **{k:v for k,v in CONFIG.items() if k in ['segment_duration', 'segment_overlap', 'undersample']})\n",
        "\n",
        "if is_data_ready:\n",
        "    print(\"\\n>>> 2. Group-based 데이터 분할 시작...\")\n",
        "    label_encoder = LabelEncoder(); encoded_labels = label_encoder.fit_transform(all_labels)\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    groups = [info[0] for info in all_segments_info]\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=CONFIG[\"test_size\"], random_state=SEED)\n",
        "    train_idx, test_idx = next(gss.split(all_segments_info, encoded_labels, groups))\n",
        "    X_train_info = [all_segments_info[i] for i in train_idx]; y_train_enc = encoded_labels[train_idx]\n",
        "    X_test_info = [all_segments_info[i] for i in test_idx]; y_test_enc = encoded_labels[test_idx]\n",
        "    print(f\"데이터 분할 완료 (파일 단위): 훈련 {len(X_train_info)}개, 테스트 {len(X_test_info)}개\")\n",
        "    train_files_set = set(info[0] for info in X_train_info); test_files_set = set(info[0] for info in X_test_info)\n",
        "    print(f\"  훈련셋 고유 파일 수: {len(train_files_set)}\"); print(f\"  테스트셋 고유 파일 수: {len(test_files_set)}\"); print(f\"  두 세트 간 중복 파일 수: {len(train_files_set.intersection(test_files_set))}\")\n",
        "else: is_data_ready = False\n",
        "\n",
        "if is_data_ready:\n",
        "    print(\"\\n>>> 3. 오디오 모델 로드 시작...\"); loaded_models, are_models_loaded = load_audio_models()\n",
        "    if not are_models_loaded: is_data_ready = False\n",
        "\n",
        "if is_data_ready and CONFIG[\"run_quality_evaluation\"]:\n",
        "    print(\"\\n>>> 4. 데이터셋 품질 사전 평가 시작...\")\n",
        "    sample_indices = random.sample(range(len(X_train_info)), min(CONFIG[\"quality_eval_samples\"], len(X_train_info)))\n",
        "    sample_info = [X_train_info[i] for i in sample_indices]; sample_labels = y_train_enc[sample_indices]\n",
        "    sample_embeddings = [extract_yamnet_embedding(info, loaded_models['YAMNet'], CONFIG) for info in sample_info]\n",
        "    valid_embeddings = [emb for emb in sample_embeddings if emb is not None]; valid_labels = [label for emb, label in zip(sample_embeddings, sample_labels) if emb is not None]\n",
        "    if valid_embeddings:\n",
        "        visualize_embeddings_with_umap(np.array(valid_embeddings), valid_labels, label_encoder.classes_)\n",
        "        visualize_spectrogram_samples(X_train_info, y_train_enc, label_encoder.classes_, CONFIG[\"segment_duration\"])\n",
        "    else: print(\"품질 평가용 임베딩 추출 실패.\")\n",
        "\n",
        "if is_data_ready:\n",
        "    print(\"\\n>>> 5. 모델별 학습, 평가 및 결과 비교 시작...\")\n",
        "    evaluation_results = {}; temp_dir = tempfile.mkdtemp()\n",
        "    noise_files_train = [info for info, lbl in zip(X_train_info, y_train_enc) if label_encoder.inverse_transform([lbl])[0] == 'noise']\n",
        "    if not noise_files_train: print(\"경고: 훈련 데이터에 노이즈 샘플이 없어 증강을 수행할 수 없습니다.\")\n",
        "\n",
        "    def make_dataset(file_paths, batch_size, num_classes, input_dim):\n",
        "        def gen():\n",
        "            while True:\n",
        "                random.shuffle(file_paths)\n",
        "                for i in range(0, len(file_paths), batch_size):\n",
        "                    paths = file_paths[i:i+batch_size]; embs, labs = [], []\n",
        "                    for p in paths:\n",
        "                        try:\n",
        "                            with np.load(p) as d: embs.append(d['embedding']); labs.append(d['label'])\n",
        "                        except Exception as e: continue\n",
        "                    if not embs: continue\n",
        "                    yield (np.asarray(embs, dtype=np.float32), tf.keras.utils.to_categorical(np.array(labs), num_classes=num_classes))\n",
        "        output_signature = (tf.TensorSpec(shape=(None, input_dim), dtype=tf.float32), tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32))\n",
        "        return tf.data.Dataset.from_generator(gen, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    for model_name in MODELS_TO_PROCESS:\n",
        "        print(f\"\\n{'='*25} {model_name} 모델 처리 시작 {'='*25}\")\n",
        "        model_hub = loaded_models[model_name]; train_files, test_files, y_train_filt, y_test_filt = [], [], [], []\n",
        "\n",
        "        for split, info_list, y_list, out_files, out_y in [('train', X_train_info, y_train_enc, train_files, y_train_filt), ('test', X_test_info, y_test_enc, test_files, y_test_filt)]:\n",
        "            print(f\"  {model_name}: {split} 데이터 임베딩 추출 중...\")\n",
        "            for i, (segment_info, label) in enumerate(zip(info_list, y_list)):\n",
        "                is_ship = (label_encoder.inverse_transform([label])[0] == 'ship')\n",
        "                noise_src = noise_files_train if split == 'train' else None\n",
        "                emb = extract_yamnet_embedding(segment_info, model_hub, CONFIG, noise_audio_infos=noise_src, augment=(split=='train' and is_ship))\n",
        "                if emb is not None:\n",
        "                    path = os.path.join(temp_dir, f'{model_name}_{split}_{i}.npz')\n",
        "                    np.savez_compressed(path, embedding=emb, label=label)\n",
        "                    out_files.append(path); out_y.append(label)\n",
        "\n",
        "        if len(train_files) < CONFIG[\"batch_size\"] or not test_files:\n",
        "            print(f\"  {model_name}: 데이터 부족으로 학습/평가를 건너뜁니다.\"); continue\n",
        "\n",
        "        try:\n",
        "            with np.load(train_files[0]) as data: input_dim = data['embedding'].shape[-1]\n",
        "            print(f\"  임베딩 차원을 동적으로 확인: {input_dim}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  임베딩 차원 확인 실패. 기본값을 사용합니다.\"); input_dim = YAMNET_EMBEDDING_DIM\n",
        "\n",
        "        classifier = build_classifier_model(input_dim, num_classes, CONFIG[\"learning_rate\"])\n",
        "        train_ds = make_dataset(train_files, CONFIG[\"batch_size\"], num_classes, input_dim)\n",
        "        test_ds  = make_dataset(test_files,  CONFIG[\"batch_size\"], num_classes, input_dim)\n",
        "        train_steps = math.ceil(len(train_files) / CONFIG[\"batch_size\"]); test_steps = math.ceil(len(test_files) / CONFIG[\"batch_size\"])\n",
        "\n",
        "        history = classifier.fit(train_ds,\n",
        "            steps_per_epoch=train_steps, validation_data=test_ds, validation_steps=test_steps,\n",
        "            epochs=CONFIG[\"epochs\"],\n",
        "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True), ReduceLROnPlateau(patience=5)], verbose=1\n",
        "        )\n",
        "\n",
        "        results = evaluate_and_visualize_model(model_name, classifier, history, test_ds, test_steps, np.array(y_test_filt), X_test_info, label_encoder)\n",
        "        evaluation_results[model_name] = results; gc.collect()\n",
        "\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(\"\\n--- 6. 최종 성능 비교 (F1, AUC 포함) ---\")\n",
        "    if evaluation_results:\n",
        "        results_df = pd.DataFrame(evaluation_results).T.sort_values('auc', ascending=False)\n",
        "        print(results_df.to_string(formatters={\n",
        "            'loss': '{:.4f}'.format, 'accuracy': '{:.4f}'.format,\n",
        "            'f1_macro': '{:.4f}'.format, 'auc': '{:.4f}'.format\n",
        "        }))\n",
        "    else: print(\"평가된 모델이 없습니다.\")\n",
        "\n",
        "print(\"\\n🎉 전체 파이프라인 실행 완료.\")"
      ],
      "metadata": {
        "id": "1-ZIkHcXGlzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}