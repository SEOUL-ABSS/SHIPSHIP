{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5xB6k7swDIU7zyNomIY7q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/SHIPSHIP/blob/main/SONAR6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =- coding: utf-8 -*-\n",
        "# ==============================================================================\n",
        "#                 DeepShip/MBARI 수중 음향 분류 프로젝트 (RAM 최적화 v2 최종본)\n",
        "# ==============================================================================\n",
        "# 최종 전문가 검토 의견을 반영하여, 후보 탐색 과정의 RAM 사용량을 최소화하는 스트리밍 및\n",
        "# 최소 힙(min-heap) 방식을 도입한 최종 버전입니다.\n",
        "#\n",
        "# [주요 개선 사항]\n",
        "# 1. RAM 사용량 최소화: 모든 후보를 메모리에 저장하는 대신, Top-K개만 유지하는 힙 자료구조를\n",
        "#                      사용하여 대용량 MBARI 데이터셋을 안정적으로 처리합니다.\n",
        "# 2. 속도 향상: 후보 임베딩을 배치 단위로 예측하여 탐색 속도를 개선합니다.\n",
        "# 3. 제어 강화: 후보 탐색 간격, 배치 크기 등을 CONFIG에서 쉽게 조절할 수 있도록 파라미터화.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 1. 환경 설정 및 라이브러리 임포트\n",
        "# ==============================================================================\n",
        "print(\"1. 환경 설정 및 라이브러리 임포트 중...\")\n",
        "\n",
        "# --- 라이브러리 설치 ---\n",
        "!pip install -q tensorflow tensorflow_hub soundfile librosa boto3 noisereduce umap-learn\n",
        "\n",
        "# --- 모든 라이브러리 임포트 ---\n",
        "import os, sys, subprocess, random, tempfile, shutil, gc, math, warnings, heapq\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa, librosa.display, soundfile as sf\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import umap.umap_ as umap\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# 불필요한 경고 메시지 숨기기\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# --- 전역 시드 설정 (재현성 확보) ---\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- Matplotlib 한글 폰트 (선택) ---\n",
        "!sudo apt-get -y install fonts-nanum > /dev/null\n",
        "!sudo fc-cache -fv > /dev/null\n",
        "import matplotlib.font_manager as fm\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "if os.path.exists(font_path):\n",
        "    fm.fontManager.addfont(font_path)\n",
        "    plt.rc('font', family='NanumGothic')\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "    print(\"\\nMatplotlib 폰트 설정 완료: NanumGothic\")\n",
        "else:\n",
        "    print(\"\\n경고: 나눔고딕 폰트를 찾을 수 없습니다.\")\n",
        "\n",
        "# --- 전역 상수 정의 ---\n",
        "print(\"\\n전역 상수 정의 중...\")\n",
        "YAMNET_SAMPLE_RATE = 16000\n",
        "DEEPSHIP_BASE_PATH = '/content/DeepShip'\n",
        "MBARI_NOISE_BASE_DIR = '/content/MBARI_noise_data'\n",
        "CANDIDATE_DIR = '/content/review_candidates'   # 후보 오디오/리포트 저장 경로\n",
        "VERIFIED_DIR  = '/content/verified_ships'      # 사용자가 직접 옮길 경로\n",
        "MODELS_TO_PROCESS = ['YAMNet']\n",
        "print(\"전역 상수 정의 완료.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 2. 데이터 확보 (DeepShip 클론 + MBARI 일부 샘플 다운로드)\n",
        "# ==============================================================================\n",
        "print(\"\\n2. 데이터 확보...\")\n",
        "\n",
        "# DeepShip\n",
        "if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            ['git', 'clone', '--depth', '1',\n",
        "             'https://github.com/irfankamboh/DeepShip.git', DEEPSHIP_BASE_PATH],\n",
        "            check=True, capture_output=True\n",
        "        )\n",
        "        print(\"DeepShip 클론 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"오류: DeepShip 클론 실패: {e}\")\n",
        "else:\n",
        "    print(\"DeepShip이 이미 존재합니다.\")\n",
        "\n",
        "# MBARI (샘플 10개)\n",
        "os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "if os.listdir(MBARI_NOISE_BASE_DIR):\n",
        "    print(\"MBARI 노이즈 데이터가 이미 존재합니다.\")\n",
        "else:\n",
        "    print(\"MBARI 노이즈 데이터 다운로드 시도 중...\")\n",
        "    try:\n",
        "        s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "        pages = s3.get_paginator('list_objects_v2').paginate(\n",
        "            Bucket='pacific-sound-16khz', Prefix='2018/01/'\n",
        "        )\n",
        "        dl_count, MAX_DL = 0, 10\n",
        "        for page in pages:\n",
        "            for obj in page.get('Contents', []):\n",
        "                if obj['Key'].endswith('.wav') and obj.get('Size', 0) > 0:\n",
        "                    local_path = os.path.join(MBARI_NOISE_BASE_DIR, os.path.basename(obj['Key']))\n",
        "                    if not os.path.exists(local_path):\n",
        "                        s3.download_file('pacific-sound-16khz', obj['Key'], local_path)\n",
        "                        dl_count += 1\n",
        "                if dl_count >= MAX_DL:\n",
        "                    break\n",
        "            if dl_count >= MAX_DL:\n",
        "                break\n",
        "        print(f\"MBARI 다운로드 완료. (파일 수: {dl_count})\")\n",
        "    except Exception as e:\n",
        "        print(f\"오류: MBARI 노이즈 데이터 다운로드 실패: {e}\")\n",
        "print(\"2. 데이터 확보 단계 완료.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 3. 세그먼테이션 (활동/비활동 초 단위) + 데이터 로더\n",
        "# ==============================================================================\n",
        "\n",
        "def get_activity_intervals(file_path, target_sr, top_db=25):\n",
        "    \"\"\"활동/비활동 구간을 '초 단위' 튜플 리스트로 반환.\"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=target_sr)\n",
        "        intervals_samples = librosa.effects.split(\n",
        "            y, top_db=top_db, frame_length=2048, hop_length=512\n",
        "        )\n",
        "        active = [(s / target_sr, e / target_sr) for s, e in intervals_samples]\n",
        "        inactive = []\n",
        "        last_end, duration = 0.0, len(y) / target_sr\n",
        "        for s_sec, e_sec in active:\n",
        "            if s_sec > last_end:\n",
        "                inactive.append((last_end, s_sec))\n",
        "            last_end = e_sec\n",
        "        if last_end < duration:\n",
        "            inactive.append((last_end, duration))\n",
        "        return active, inactive\n",
        "    except Exception:\n",
        "        return [], []\n",
        "\n",
        "def load_and_segment_data_final(\n",
        "    ship_paths, noise_paths, verified_ship_path,\n",
        "    segment_duration=5.0, segment_overlap=0.5, undersample=True\n",
        "):\n",
        "    \"\"\"DeepShip + (선택)검증선박 + MBARI 노이즈 → (file,start,sr), label 리스트 생성.\"\"\"\n",
        "    hop_length = segment_duration * (1 - segment_overlap)\n",
        "    ship_segments, noise_segments = [], []\n",
        "\n",
        "    # ✅ None-safe 처리\n",
        "    all_ship_folders = list(ship_paths)\n",
        "    if verified_ship_path and os.path.exists(verified_ship_path):\n",
        "        all_ship_folders.append(verified_ship_path)\n",
        "\n",
        "    # Ship 폴더들: 활동 구간=ship, 비활동 구간=noise\n",
        "    for folder_path in all_ship_folders:\n",
        "        print(f\"'ship' 클래스 데이터 처리 중: {folder_path}\")\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for fn in sorted([f for f in files if f.endswith('.wav')]):\n",
        "                fp = os.path.join(root, fn)\n",
        "                try:\n",
        "                    info = sf.info(fp)\n",
        "                except:\n",
        "                    continue\n",
        "                active, inactive = get_activity_intervals(fp, YAMNET_SAMPLE_RATE)\n",
        "                # 활동 구간 -> ship\n",
        "                for s_sec, e_sec in active:\n",
        "                    if e_sec - s_sec >= segment_duration:\n",
        "                        for seg_start in np.arange(s_sec, e_sec - segment_duration + 1e-9, hop_length):\n",
        "                            ship_segments.append(((fp, float(seg_start), info.samplerate), 'ship'))\n",
        "                # 비활동 구간 -> noise\n",
        "                for s_sec, e_sec in inactive:\n",
        "                    if e_sec - s_sec >= segment_duration:\n",
        "                        for seg_start in np.arange(s_sec, e_sec - segment_duration + 1e-9, hop_length):\n",
        "                            noise_segments.append(((fp, float(seg_start), info.samplerate), 'noise'))\n",
        "\n",
        "    # Noise 폴더들: 전구간=noise\n",
        "    for folder_path in noise_paths:\n",
        "        print(f\"'noise' 클래스 데이터 처리 중: {folder_path}\")\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for fn in sorted([f for f in files if f.endswith('.wav')]):\n",
        "                fp = os.path.join(root, fn)\n",
        "                try:\n",
        "                    info = sf.info(fp)\n",
        "                except:\n",
        "                    continue\n",
        "                dur = info.duration\n",
        "                if dur < segment_duration:\n",
        "                    continue\n",
        "                for seg_start in np.arange(0, dur - segment_duration + 1e-9, hop_length):\n",
        "                    noise_segments.append(((fp, float(seg_start), info.samplerate), 'noise'))\n",
        "\n",
        "    print(f\"  총 'ship' 세그먼트: {len(ship_segments)}개, 총 'noise' 세그먼트: {len(noise_segments)}개\")\n",
        "    all_data = ship_segments + noise_segments\n",
        "\n",
        "    if undersample and ship_segments and noise_segments:\n",
        "        k = min(len(ship_segments), len(noise_segments))\n",
        "        print(f\"\\n클래스 불균형 -> 언더샘플링({k}개) 수행.\")\n",
        "        all_data = random.sample(ship_segments, k) + random.sample(noise_segments, k)\n",
        "        random.shuffle(all_data)\n",
        "\n",
        "    if not all_data:\n",
        "        return [], [], False\n",
        "    infos, labels = zip(*all_data)\n",
        "    print(\"\\n데이터 로드 및 세그먼테이션 완료.\")\n",
        "    return list(infos), list(labels), True\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 4. 전처리/임베딩/모델/유틸 함수\n",
        "# ==============================================================================\n",
        "\n",
        "def mix_at_snr(clean, noise, snr_db):\n",
        "    L = min(len(clean), len(noise))\n",
        "    c, n = clean[:L].astype(np.float32), noise[:L].astype(np.float32)\n",
        "    c_power = np.sqrt(np.mean(c**2)); n_power = np.sqrt(np.mean(n**2))\n",
        "    if n_power < 1e-8:\n",
        "        return c\n",
        "    alpha = c_power / (n_power * (10 ** (snr_db / 20)))\n",
        "    return c + alpha * n\n",
        "\n",
        "def load_and_process_segment_efficient(file_info, duration, target_sr, config):\n",
        "    file_path, start_time, orig_sr = file_info\n",
        "    try:\n",
        "        start_frame = int(start_time * orig_sr)\n",
        "        num_frames  = int(duration * orig_sr)\n",
        "        y_segment, _ = sf.read(\n",
        "            file_path, start=start_frame, stop=start_frame + num_frames,\n",
        "            dtype='float32', always_2d=False\n",
        "        )\n",
        "        if y_segment.ndim > 1:\n",
        "            y_segment = np.mean(y_segment, axis=1)\n",
        "        if orig_sr != target_sr:\n",
        "            y_segment = librosa.resample(y=y_segment, orig_sr=orig_sr, target_sr=target_sr)\n",
        "        if config.get(\"apply_noise_reduction\", False):\n",
        "            y_segment = nr.reduce_noise(y=y_segment, sr=target_sr)\n",
        "        if config.get(\"apply_rms_norm\", True):\n",
        "            rms = np.sqrt(np.mean(y_segment ** 2))\n",
        "            if rms > 1e-6:\n",
        "                y_segment = y_segment * (10.0 ** (-20.0 / 20.0) / rms)\n",
        "        return y_segment\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def extract_yamnet_embedding(audio_info, model, config, noise_audio_infos=None, augment=False):\n",
        "    try:\n",
        "        y_segment = load_and_process_segment_efficient(\n",
        "            audio_info, config[\"segment_duration\"], YAMNET_SAMPLE_RATE, config\n",
        "        )\n",
        "        if y_segment is None:\n",
        "            return None\n",
        "        if augment and noise_audio_infos:\n",
        "            noise_info = random.choice(noise_audio_infos)\n",
        "            y_noise = load_and_process_segment_efficient(\n",
        "                noise_info, config[\"segment_duration\"], YAMNET_SAMPLE_RATE,\n",
        "                {\"apply_noise_reduction\": False, \"apply_rms_norm\": True}\n",
        "            )\n",
        "            if y_noise is not None:\n",
        "                if config.get(\"use_snr_augmentation\", False):\n",
        "                    snr_db = random.uniform(config[\"snr_min_db\"], config[\"snr_max_db\"])\n",
        "                    y_segment = mix_at_snr(y_segment, y_noise, snr_db)\n",
        "                else:\n",
        "                    L = min(len(y_segment), len(y_noise))\n",
        "                    y_segment = y_segment[:L] + config.get(\"noise_level\", 0.05) * y_noise[:L]\n",
        "        _, embeddings, _ = model(y_segment)\n",
        "        emb = tf.reduce_mean(embeddings, axis=0).numpy() if embeddings.shape[0] > 0 else None\n",
        "        return emb\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def load_audio_models():\n",
        "    models = {}\n",
        "    print(\"\\n오디오 모델 로드 중...\")\n",
        "    try:\n",
        "        models['YAMNet'] = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "        print(\"  YAMNet 모델 로드: 성공\")\n",
        "        return models, True\n",
        "    except Exception as e:\n",
        "        print(f\"  모델 로드 실패: {e}\")\n",
        "        return {}, False\n",
        "\n",
        "def build_classifier_model(input_shape, num_classes, learning_rate):\n",
        "    inp = Input(shape=(input_shape,), name='embedding_input')\n",
        "    x = Dense(256, activation='relu')(inp); x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x); x = Dropout(0.5)(x)\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def embed_infos(infos, labels, model_hub, config, label_encoder,\n",
        "                noise_infos_for_train=None, augment_ship_only=True):\n",
        "    \"\"\"세그먼트 리스트 → (X, y onehot, infos_kept) 임베딩.\"\"\"\n",
        "    embs, labs, kept_infos = [], [], []\n",
        "    for info, lab in zip(infos, labels):\n",
        "        is_ship = (label_encoder.inverse_transform([lab])[0] == 'ship')\n",
        "        use_aug = bool(noise_infos_for_train) and (augment_ship_only and is_ship)\n",
        "        noise_src = noise_infos_for_train if use_aug else None\n",
        "        emb = extract_yamnet_embedding(info, model_hub, config,\n",
        "                                       noise_audio_infos=noise_src, augment=use_aug)\n",
        "        if emb is not None:\n",
        "            embs.append(emb); labs.append(lab); kept_infos.append(info)\n",
        "    if not embs:\n",
        "        return np.array([]), np.array([]), []\n",
        "    X = np.asarray(embs, dtype=np.float32)\n",
        "    y = tf.keras.utils.to_categorical(np.asarray(labs), num_classes=len(label_encoder.classes_))\n",
        "    return X, y, kept_infos\n",
        "\n",
        "def summarize_metrics(y_true_onehot, y_prob, label_encoder, title=\"\"):\n",
        "    \"\"\"정확도, Macro-F1, AUC(ship)을 계산하여 출력. AUC는 가드 처리.\"\"\"\n",
        "    y_true = y_true_onehot.argmax(axis=1)\n",
        "    y_pred = y_prob.argmax(axis=1)\n",
        "    acc  = (y_pred == y_true).mean()\n",
        "    f1m  = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "    try:\n",
        "        ship_idx = list(label_encoder.classes_).index('ship')\n",
        "        y_true_bin = (y_true == ship_idx).astype(int)\n",
        "        if len(np.unique(y_true_bin)) < 2:\n",
        "            auc_score = float('nan')\n",
        "        else:\n",
        "            auc_score = roc_auc_score(y_true_bin, y_prob[:, ship_idx])\n",
        "    except Exception:\n",
        "        auc_score = float('nan')\n",
        "\n",
        "    print(f\"{title}Acc: {acc:.4f}, Macro-F1: {f1m:.4f}, AUC(ship): {auc_score:.4f}\")\n",
        "    return acc, f1m, auc_score\n",
        "\n",
        "def plot_confusion(y_true_onehot, y_prob, label_encoder, title=\"Confusion Matrix\"):\n",
        "    y_true = y_true_onehot.argmax(axis=1)\n",
        "    y_pred = y_prob.argmax(axis=1)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d',\n",
        "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_,\n",
        "                cmap='Blues')\n",
        "    plt.xlabel('예측 레이블'); plt.ylabel('실제 레이블'); plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "def generate_candidate_report_zip(candidate_dir, candidates, sr=YAMNET_SAMPLE_RATE):\n",
        "    \"\"\"candidates: list of dict({ 'wav':np.array, 'name':str })\"\"\"\n",
        "    os.makedirs(candidate_dir, exist_ok=True)\n",
        "    html_path = os.path.join(candidate_dir, \"candidate_report.html\")\n",
        "    report = [\"<h1>선박 소리 후보 (검증 필요)</h1><hr>\"]\n",
        "\n",
        "    for item in candidates:\n",
        "        out_wav_path = os.path.join(candidate_dir, item['name'])\n",
        "        sf.write(out_wav_path, item['wav'], sr)\n",
        "        # HTML에서 상대경로로 접근 (Colab/로컬 다운로드 후에도 재생 가능)\n",
        "        report += [\n",
        "            f\"<h3>{item['name']}</h3>\",\n",
        "            f\"<p>Ship Probability: {item['ship_prob']:.2%}</p>\",\n",
        "            f\"<audio controls src='{item['name']}'></audio><br>\"\n",
        "        ]\n",
        "    with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"\\n\".join(report))\n",
        "\n",
        "    bundle_path = \"/content/review_candidates_bundle\"\n",
        "    shutil.make_archive(bundle_path, 'zip', candidate_dir)\n",
        "    print(f\"\\n[작업 요청] '{bundle_path}.zip' 파일을 다운로드하여 압축을 풀고, HTML 리포트를 확인하세요.\")\n",
        "    print(f\"검증된 파일을 '{VERIFIED_DIR}' 폴더로 옮기거나, 마지막 단계에서 파일명을 직접 입력해도 됩니다.\")\n",
        "\n",
        "def parse_verified_filenames_to_infos(verified_filenames, base_dir):\n",
        "    \"\"\"후보 파일명 → (원본경로, 시작초, sr) 복원.\"\"\"\n",
        "    out_infos = []\n",
        "    for fname in verified_filenames:\n",
        "        try:\n",
        "            base = fname.rsplit('.', 1)[0]\n",
        "            parts = base.split('__')\n",
        "            original_base = parts[0]\n",
        "            start_sec = float(parts[1].split('s')[0])\n",
        "\n",
        "            original_path = None\n",
        "            for root, _, files in os.walk(base_dir):\n",
        "                if f\"{original_base}.wav\" in files:\n",
        "                    original_path = os.path.join(root, f\"{original_base}.wav\")\n",
        "                    break\n",
        "            if original_path:\n",
        "                info = sf.info(original_path)\n",
        "                out_infos.append(((original_path, start_sec, info.samplerate), 'ship'))\n",
        "            else:\n",
        "                print(f\"[경고] 원본 파일 탐색 실패: {original_base}.wav\")\n",
        "        except Exception as e:\n",
        "            print(f\"[경고] 검증 파일 파싱 실패: {fname} ({e})\")\n",
        "    return out_infos\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 5. 메인 파이프라인 1단계: 스카우트 모델 학습 & 후보 탐색\n",
        "# ==============================================================================\n",
        "CONFIG_SCOUT = {\"segment_duration\": 5.0, \"segment_overlap\": 0.5, \"undersample\": True, \"apply_noise_reduction\": False, \"apply_rms_norm\": True, \"use_snr_augmentation\": True, \"snr_min_db\": 0, \"snr_max_db\": 15, \"noise_level\": 0.05, \"test_size\": 0.2, \"epochs\": 20, \"batch_size\": 32, \"learning_rate\": 0.0005, \"top_k_candidates\": 50, \"candidate_stride\": 5.0, \"candidate_batch\": 32, \"max_mbari_files\": 10}\n",
        "\n",
        "print(\"\\n>>> [1단계] 스카우트 모델 학습 및 후보 탐색 시작...\")\n",
        "\n",
        "scout_infos, scout_labels, scout_ok = load_and_segment_data_final(ship_paths=[DEEPSHIP_BASE_PATH], noise_paths=[MBARI_NOISE_BASE_DIR], verified_ship_path=None, **{k:v for k,v in CONFIG_SCOUT.items() if k in ['segment_duration','segment_overlap','undersample']})\n",
        "scout_model = None\n",
        "if scout_ok:\n",
        "    le_scout = LabelEncoder(); y_all = le_scout.fit_transform(scout_labels); groups = [info[0] for info in scout_infos]\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=CONFIG_SCOUT[\"test_size\"], random_state=SEED)\n",
        "    tr_idx, te_idx = next(gss.split(scout_infos, y_all, groups))\n",
        "    Xtr_infos = [scout_infos[i] for i in tr_idx]; ytr_enc = y_all[tr_idx]\n",
        "    Xte_infos = [scout_infos[i] for i in te_idx]; yte_enc = y_all[te_idx]\n",
        "\n",
        "    models_hub, ok = load_audio_models()\n",
        "    if ok:\n",
        "        print(\"\\n초기 모델 학습 시작...\")\n",
        "        noise_tr = [info for info, lab in zip(Xtr_infos, ytr_enc) if le_scout.inverse_transform([lab])[0] == 'noise']\n",
        "        Xtr, ytr, _ = embed_infos(Xtr_infos, ytr_enc, models_hub['YAMNet'], CONFIG_SCOUT, le_scout, noise_infos_for_train=noise_tr)\n",
        "        Xte, yte, _ = embed_infos(Xte_infos, yte_enc, models_hub['YAMNet'], CONFIG_SCOUT, le_scout)\n",
        "        if len(Xtr) == 0 or len(Xte) == 0: print(\"오류: 임베딩 추출 실패(학습/평가 샘플이 없음).\"); scout_model = None\n",
        "        else:\n",
        "            input_dim = Xtr.shape[-1]; num_classes = ytr.shape[-1]\n",
        "            clf = build_classifier_model(input_dim, num_classes, CONFIG_SCOUT[\"learning_rate\"])\n",
        "            hist = clf.fit(Xtr, ytr, validation_data=(Xte, yte), epochs=CONFIG_SCOUT[\"epochs\"], batch_size=CONFIG_SCOUT[\"batch_size\"], callbacks=[EarlyStopping(patience=5, restore_best_weights=True), ReduceLROnPlateau(patience=3)], verbose=1)\n",
        "            scout_model = clf\n",
        "            prob_te = scout_model.predict(Xte, verbose=0); summarize_metrics(yte, prob_te, le_scout, title=\"[스카우트] \")\n",
        "\n",
        "def stream_topk_candidates(scout_model, yamnet_model, label_encoder, mbari_dir, config):\n",
        "    ship_idx = list(label_encoder.classes_).index('ship'); top_k = int(config.get(\"top_k_candidates\", 50))\n",
        "    stride = float(config.get(\"candidate_stride\", config[\"segment_duration\"])); batch_size = int(config.get(\"candidate_batch\", 32))\n",
        "    max_files = int(config.get(\"max_mbari_files\", 1000000)); heap = []; batch_embs, batch_infos = [], []\n",
        "\n",
        "    def flush_batch():\n",
        "        nonlocal heap\n",
        "        if not batch_embs: return\n",
        "        probs = scout_model.predict(np.asarray(batch_embs, dtype=np.float32), verbose=0)\n",
        "        for p, info in zip(probs, batch_infos):\n",
        "            prob_ship = float(p[ship_idx])\n",
        "            if len(heap) < top_k: heapq.heappush(heap, (prob_ship, info))\n",
        "            elif prob_ship > heap[0][0]: heapq.heapreplace(heap, (prob_ship, info))\n",
        "        batch_embs.clear(); batch_infos.clear(); gc.collect()\n",
        "\n",
        "    mbari_files = sorted([f for f in os.listdir(mbari_dir) if f.endswith('.wav')])[:max_files]\n",
        "    print(f\"  총 {len(mbari_files)}개의 MBARI 파일을 스트리밍으로 처리합니다.\")\n",
        "    for fi, fn in enumerate(mbari_files, 1):\n",
        "        fp = os.path.join(mbari_dir, fn)\n",
        "        try: info = sf.info(fp)\n",
        "        except: continue\n",
        "\n",
        "        starts = np.arange(0, info.duration - config[\"segment_duration\"] + 1e-9, stride)\n",
        "\n",
        "        for seg_start in starts:\n",
        "            seg_info = (fp, float(seg_start), info.samplerate)\n",
        "            emb = extract_yamnet_embedding(seg_info, yamnet_model, config, augment=False)\n",
        "            if emb is None: continue\n",
        "            batch_embs.append(emb); batch_infos.append(seg_info)\n",
        "            if len(batch_embs) >= batch_size: flush_batch()\n",
        "        flush_batch()\n",
        "        if fi % 5 == 0: print(f\"  진행 상황: {fi}/{len(mbari_files)}개 파일 처리 완료…\"); gc.collect()\n",
        "\n",
        "    heap.sort(reverse=True)\n",
        "    return heap\n",
        "\n",
        "if scout_model:\n",
        "    print(\"\\n>>> MBARI 후보 탐색 (RAM 절약 스트리밍 모드)…\")\n",
        "    topk_heap = stream_topk_candidates(scout_model, models_hub['YAMNet'], le_scout, MBARI_NOISE_BASE_DIR, CONFIG_SCOUT)\n",
        "    print(f\"  Top-{len(topk_heap)} 후보 확보.\")\n",
        "    cand_items = []\n",
        "    for prob, info in topk_heap:\n",
        "        yseg = load_and_process_segment_efficient(info, CONFIG_SCOUT[\"segment_duration\"], YAMNET_SAMPLE_RATE, CONFIG_SCOUT)\n",
        "        if yseg is None: continue\n",
        "        base_name = f\"{os.path.basename(info[0]).replace('.wav','')}__{info[1]:.2f}s_prob{prob:.2f}.wav\"\n",
        "        cand_items.append({'name': base_name, 'wav': yseg, 'ship_prob': prob})\n",
        "    generate_candidate_report_zip(CANDIDATE_DIR, cand_items, sr=YAMNET_SAMPLE_RATE)\n",
        "    os.makedirs(VERIFIED_DIR, exist_ok=True)\n",
        "else:\n",
        "    print(\"\\n스카우트 모델이 없어 후보 탐색을 건너뜁니다.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 6. 메인 파이프라인 2단계: 검증된 데이터로 최종 학습\n",
        "# ==============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"## 6. 최종 모델 학습 단계\")\n",
        "print(\"  - 1단계에서 생성된 'review_candidates_bundle.zip' 파일을 확인하세요.\")\n",
        "print(f\"  - 선박 소음이 확실한 WAV 파일들을 Colab의 '{VERIFIED_DIR}' 폴더로 업로드해주세요.\")\n",
        "print(\"  - 준비가 되면 이 셀을 실행하세요.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not os.path.exists(VERIFIED_DIR) or not any(f.endswith('.wav') for f in os.listdir(VERIFIED_DIR)):\n",
        "    print(f\"\\n경고: '{VERIFIED_DIR}' 폴더에 검증된 파일이 없습니다. 검증 데이터 없이 학습을 진행합니다.\")\n",
        "\n",
        "CONFIG_FINAL = CONFIG_SCOUT.copy(); CONFIG_FINAL['epochs'] = 50\n",
        "print(\"\\n>>> [2단계] 최종 데이터셋 로드...\")\n",
        "final_infos, final_labels, ok = load_and_segment_data_final(\n",
        "    ship_paths=[DEEPSHIP_BASE_PATH],\n",
        "    noise_paths=[MBARI_NOISE_BASE_DIR],\n",
        "    verified_ship_path=VERIFIED_DIR,\n",
        "    **{k: v for k, v in CONFIG_FINAL.items() if k in ['segment_duration', 'segment_overlap', 'undersample']}\n",
        ")\n",
        "\n",
        "if ok:\n",
        "    le_final = LabelEncoder(); y_all = le_final.fit_transform(final_labels)\n",
        "    groups = [info[0] for info in final_infos]\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=CONFIG_FINAL[\"test_size\"], random_state=SEED)\n",
        "    tr_idx, te_idx = next(gss.split(final_infos, y_all, groups))\n",
        "    Xtr_infos = [final_infos[i] for i in tr_idx]; ytr_enc = y_all[tr_idx]\n",
        "    Xte_infos = [final_infos[i] for i in te_idx]; yte_enc = y_all[te_idx]\n",
        "\n",
        "    models_final, ok2 = load_audio_models()\n",
        "    if ok2:\n",
        "        noise_tr = [info for info, lab in zip(Xtr_infos, ytr_enc) if le_final.inverse_transform([lab])[0]=='noise']\n",
        "        Xtr, ytr, _ = embed_infos(Xtr_infos, ytr_enc, models_final['YAMNet'], CONFIG_FINAL, le_final, noise_infos_for_train=noise_tr)\n",
        "        Xte, yte, _ = embed_infos(Xte_infos, yte_enc, models_final['YAMNet'], CONFIG_FINAL, le_final)\n",
        "        if len(Xtr) == 0 or len(Xte) == 0: print(\"최종 임베딩 추출 실패\")\n",
        "        else:\n",
        "            input_dim = Xtr.shape[-1]; num_classes = ytr.shape[-1]\n",
        "            clf = build_classifier_model(input_dim, num_classes, CONFIG_FINAL[\"learning_rate\"])\n",
        "            hist = clf.fit(Xtr, ytr, validation_data=(Xte, yte), epochs=CONFIG_FINAL[\"epochs\"], batch_size=CONFIG_FINAL[\"batch_size\"],\n",
        "                           callbacks=[EarlyStopping(patience=8, restore_best_weights=True), ReduceLROnPlateau(patience=4)], verbose=1)\n",
        "            probs = clf.predict(Xte, verbose=0)\n",
        "            summarize_metrics(yte, probs, le_final, title=\"[최종] \")\n",
        "            plot_confusion(yte, probs, le_final, title=\"최종 모델 혼동 행렬\")\n",
        "    else: print(\"최종 모델 로드 실패\")\n",
        "else: print(\"최종 데이터 준비 실패\")\n",
        "\n",
        "print(\"\\n🎉 전체 파이프라인 실행 완료.\")"
      ],
      "metadata": {
        "id": "1-ZIkHcXGlzx",
        "collapsed": true,
        "outputId": "c63b44c8-0436-4eb9-e6f2-7ac49493db57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 환경 설정 및 라이브러리 임포트 중...\n",
            "\n",
            "Matplotlib 폰트 설정 완료: NanumGothic\n",
            "\n",
            "전역 상수 정의 중...\n",
            "전역 상수 정의 완료.\n",
            "\n",
            "2. 데이터 확보...\n",
            "DeepShip이 이미 존재합니다.\n",
            "MBARI 노이즈 데이터가 이미 존재합니다.\n",
            "2. 데이터 확보 단계 완료.\n",
            "\n",
            ">>> [1단계] 스카우트 모델 학습 및 후보 탐색 시작...\n",
            "'ship' 클래스 데이터 처리 중: /content/DeepShip\n",
            "'noise' 클래스 데이터 처리 중: /content/MBARI_noise_data\n",
            "  총 'ship' 세그먼트: 2201개, 총 'noise' 세그먼트: 345590개\n",
            "\n",
            "클래스 불균형 -> 언더샘플링(2201개) 수행.\n",
            "\n",
            "데이터 로드 및 세그먼테이션 완료.\n",
            "\n",
            "오디오 모델 로드 중...\n",
            "  YAMNet 모델 로드: 성공\n",
            "\n",
            "초기 모델 학습 시작...\n"
          ]
        }
      ]
    }
  ]
}