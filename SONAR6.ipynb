{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuTPs8nlELpofvoY37cmUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/SHIPSHIP/blob/main/SONAR6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "#                 DeepShip/MBARI ìˆ˜ì¤‘ ìŒí–¥ ë¶„ë¥˜ í”„ë¡œì íŠ¸ (Data Leakage í•´ê²° ìµœì¢…ë³¸)\n",
        "# ==============================================================================\n",
        "# ì´ í”„ë¡œì íŠ¸ëŠ” YAMNet ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ìˆ˜ì¤‘ ìŒí–¥ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì•ˆì •ì ì´ê³  ì¬í˜„ ê°€ëŠ¥í•œ\n",
        "# ë² ì´ìŠ¤ë¼ì¸ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤. ìµœì¢… ì „ë¬¸ê°€ ê²€í†  ì˜ê²¬ì„ ë°˜ì˜í•˜ì—¬ ì¹˜ëª…ì  ì˜¤ë¥˜,\n",
        "# ë°ì´í„° ëˆ„ìˆ˜, ì¬í˜„ì„± ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , í‰ê°€ íŒŒíŠ¸ë¥¼ ê°•í™”í•˜ì—¬ ì‹¬ì¸µì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
        "#\n",
        "# [ì£¼ìš” ê°œì„  ì‚¬í•­]\n",
        "# 1. ë°ì´í„° ìœ ì¶œ ë°©ì§€: GroupShuffleSplitì„ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ê°€ ì•„ë‹Œ íŒŒì¼ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë¶„í• .\n",
        "#                      ì´ë¥¼ í†µí•´ ë™ì¼ íŒŒì¼ì˜ ì„¸ê·¸ë¨¼íŠ¸ê°€ í›ˆë ¨/í…ŒìŠ¤íŠ¸ì…‹ì— ì„ì´ëŠ” ê²ƒì„ ì›ì²œ ì°¨ë‹¨.\n",
        "# 2. ì•ˆì •ì„± ë° ì¬í˜„ì„±: ì´ì „ ê²€í†  ì˜ê²¬ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ì•ˆì •ì ì¸ íŒŒì´í”„ë¼ì¸ ìœ ì§€.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "# ==============================================================================\n",
        "print(\"1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì¤‘...\")\n",
        "\n",
        "# --- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ---\n",
        "!pip install -q tensorflow tensorflow_hub soundfile librosa boto3 noisereduce umap-learn\n",
        "\n",
        "# --- ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ---\n",
        "import os, sys, subprocess, random, tempfile, shutil, gc, math\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa, librosa.display, soundfile as sf\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.client import Config\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit # << GroupShuffleSplit ì¶”ê°€\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import umap.umap_ as umap\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "# í‰ê°€ì§€í‘œ í™•ì¥ì„ ìœ„í•´ ì¶”ê°€\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import noisereduce as nr\n",
        "\n",
        "# --- ì „ì—­ ì‹œë“œ ì„¤ì • (ì¬í˜„ì„± í™•ë³´) ---\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- Matplotlib í•œê¸€ í°íŠ¸ ì„¤ì • ---\n",
        "!sudo apt-get -y install fonts-nanum > /dev/null\n",
        "!sudo fc-cache -fv > /dev/null\n",
        "import matplotlib.font_manager as fm\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "if os.path.exists(font_path):\n",
        "    fm.fontManager.addfont(font_path); plt.rc('font', family='NanumGothic'); plt.rcParams['axes.unicode_minus'] = False\n",
        "    print(\"\\nMatplotlib í°íŠ¸ ì„¤ì • ì™„ë£Œ: NanumGothic\")\n",
        "else:\n",
        "    print(\"\\nê²½ê³ : ë‚˜ëˆ”ê³ ë”• í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# --- ì „ì—­ ìƒìˆ˜ ì •ì˜ ---\n",
        "print(\"\\nì „ì—­ ìƒìˆ˜ ì •ì˜ ì¤‘...\")\n",
        "YAMNET_SAMPLE_RATE = 16000\n",
        "DEEPSHIP_BASE_PATH = '/content/DeepShip'\n",
        "MBARI_NOISE_BASE_DIR = '/content/MBARI_noise_data'\n",
        "MODELS_TO_PROCESS = ['YAMNet']\n",
        "print(\"ì „ì—­ ìƒìˆ˜ ì •ì˜ ì™„ë£Œ.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 2. ë°ì´í„° í™•ë³´\n",
        "# ==============================================================================\n",
        "print(\"\\n2. ë°ì´í„° í™•ë³´...\")\n",
        "if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    try:\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', 'https://github.com/irfankamboh/DeepShip.git', DEEPSHIP_BASE_PATH], check=True, capture_output=True)\n",
        "        print(\"DeepShip í´ë¡  ì™„ë£Œ.\")\n",
        "    except Exception as e: print(f\"ì˜¤ë¥˜: DeepShip í´ë¡  ì‹¤íŒ¨: {e}\")\n",
        "else: print(f\"DeepShipì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "if os.listdir(MBARI_NOISE_BASE_DIR): print(f\"MBARI ë…¸ì´ì¦ˆ ë°ì´í„°ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
        "else:\n",
        "    print(f\"MBARI ë…¸ì´ì¦ˆ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œë„ ì¤‘...\")\n",
        "    try:\n",
        "        s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "        pages = s3.get_paginator('list_objects_v2').paginate(Bucket='pacific-sound-16khz', Prefix='2018/01/')\n",
        "        dl_count = 0; MAX_DL = 10\n",
        "        for page in pages:\n",
        "            for obj in page.get('Contents', []):\n",
        "                if obj['Key'].endswith('.wav') and obj.get('Size', 0) > 0:\n",
        "                    local_path = os.path.join(MBARI_NOISE_BASE_DIR, os.path.basename(obj['Key']))\n",
        "                    if not os.path.exists(local_path):\n",
        "                        s3.download_file('pacific-sound-16khz', obj['Key'], local_path)\n",
        "                        dl_count += 1\n",
        "                if dl_count >= MAX_DL: break\n",
        "            if dl_count >= MAX_DL: break\n",
        "        print(f\"MBARI ë‹¤ìš´ë¡œë“œ ì™„ë£Œ. (íŒŒì¼ ìˆ˜: {dl_count})\")\n",
        "    except Exception as e: print(f\"ì˜¤ë¥˜: MBARI ë…¸ì´ì¦ˆ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "print(\"2. ë°ì´í„° í™•ë³´ ë‹¨ê³„ ì™„ë£Œ.\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 3. ë°ì´í„° ì²˜ë¦¬ ë° ì„¸ê·¸ë¨¼í…Œì´ì…˜ í•¨ìˆ˜ ì •ì˜\n",
        "# ==============================================================================\n",
        "def load_and_segment_data(ship_path, noise_path, segment_duration=5.0, segment_overlap=0.5, undersample=True):\n",
        "    hop_length = segment_duration * (1 - segment_overlap)\n",
        "    all_data = []\n",
        "\n",
        "    def _process_directory(base_path, label):\n",
        "        segments = []\n",
        "        print(f\"'{label}' í´ë˜ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ì¤‘: {base_path}\")\n",
        "        if not os.path.exists(base_path): return segments\n",
        "        for root, _, files in os.walk(base_path):\n",
        "            for file_name in sorted(files):\n",
        "                if file_name.endswith('.wav'):\n",
        "                    file_path = os.path.join(root, file_name)\n",
        "                    try:\n",
        "                        info = sf.info(file_path)\n",
        "                        duration = info.duration\n",
        "                        if duration < segment_duration: continue\n",
        "                        for start_time in np.arange(0, duration - segment_duration + 1, hop_length):\n",
        "                            segments.append(((file_path, start_time, info.samplerate), label))\n",
        "                    except Exception as e: continue\n",
        "        print(f\"  '{label}' í´ë˜ìŠ¤ì—ì„œ ì´ {len(segments)}ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± ì™„ë£Œ.\")\n",
        "        return segments\n",
        "\n",
        "    ship_data = _process_directory(ship_path, 'ship')\n",
        "    noise_data = _process_directory(noise_path, 'noise')\n",
        "    all_data = ship_data + noise_data\n",
        "\n",
        "    if undersample and ship_data and noise_data:\n",
        "        n_ship = len(ship_data)\n",
        "        n_noise = len(noise_data)\n",
        "        if n_ship != n_noise:\n",
        "            min_samples = min(n_ship, n_noise)\n",
        "            print(f\"\\ní´ë˜ìŠ¤ ë¶ˆê· í˜•(Ship:{n_ship}, Noise:{n_noise}) -> ì–¸ë”ìƒ˜í”Œë§({min_samples}ê°œ) ìˆ˜í–‰.\")\n",
        "            ship_samples = random.sample(ship_data, min_samples)\n",
        "            noise_samples = random.sample(noise_data, min_samples)\n",
        "            all_data = ship_samples + noise_samples\n",
        "            random.shuffle(all_data)\n",
        "\n",
        "    if not all_data: print(\"\\nì˜¤ë¥˜: ì²˜ë¦¬í•  ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.\"); return [], [], False\n",
        "    all_segments_info, all_labels = zip(*all_data)\n",
        "    print(\"\\në°ì´í„° ë¡œë“œ ë° ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì™„ë£Œ.\")\n",
        "    return list(all_segments_info), list(all_labels), True\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 4. ì „ì²˜ë¦¬ ë°ì´í„°ì…‹ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
        "# ==============================================================================\n",
        "def visualize_embeddings_with_umap(embeddings, labels, class_names):\n",
        "    print(\"\\n[ë°ì´í„° í’ˆì§ˆ í‰ê°€] UMAP ì„ë² ë”© ì‹œê°í™” ì‹¤í–‰ ì¤‘...\")\n",
        "    if len(embeddings) < 3:\n",
        "        print(\"  UMAP: í‘œë³¸ì´ 3ê°œ ë¯¸ë§Œì´ì–´ì„œ ì‹œê°í™”ë¥¼ ìƒëµí•©ë‹ˆë‹¤.\")\n",
        "        return\n",
        "    n_neighbors = max(2, min(15, len(embeddings) - 1))\n",
        "    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=0.1, n_components=2, random_state=SEED)\n",
        "    embeddings_2d = reducer.fit_transform(embeddings)\n",
        "    df = pd.DataFrame(embeddings_2d, columns=['x', 'y']); df['label'] = [class_names[l] for l in labels]\n",
        "    plt.figure(figsize=(10, 8)); sns.scatterplot(data=df, x='x', y='y', hue='label', style='label', s=50, alpha=0.7)\n",
        "    plt.title('UMAPì„ ì´ìš©í•œ ì„ë² ë”© ë¶„í¬ ì‹œê°í™” (í•™ìŠµ ì „ ì§„ë‹¨)'); plt.grid(True); plt.show()\n",
        "\n",
        "def visualize_spectrogram_samples(segments_info, labels, class_names, segment_duration, num_samples=3):\n",
        "    print(\"\\n[ë°ì´í„° í’ˆì§ˆ í‰ê°€] ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒ˜í”Œ ì‹œê°í™” ì‹¤í–‰ ì¤‘...\")\n",
        "    unique_labels = np.unique(labels)\n",
        "    fig, axes = plt.subplots(len(unique_labels), num_samples, figsize=(5*num_samples, 4*len(unique_labels)), squeeze=False)\n",
        "    fig.suptitle('í´ë˜ìŠ¤ë³„ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒ˜í”Œ', fontsize=16)\n",
        "    for i, label in enumerate(unique_labels):\n",
        "        indices = np.where(labels == label)[0]\n",
        "        if not len(indices): continue\n",
        "        sample_indices = random.sample(list(indices), min(num_samples, len(indices)))\n",
        "        for j, idx in enumerate(sample_indices):\n",
        "            file_path, start_time, _ = segments_info[idx]\n",
        "            ax = axes[i, j]\n",
        "            try:\n",
        "                y, _ = librosa.load(file_path, sr=YAMNET_SAMPLE_RATE, offset=start_time, duration=segment_duration)\n",
        "                D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "                librosa.display.specshow(D, sr=YAMNET_SAMPLE_RATE, x_axis='time', y_axis='log', ax=ax)\n",
        "                ax.set_title(f\"{class_names[label]} Sample {j+1}\")\n",
        "            except Exception as e: ax.set_title(f\"ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨\")\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95]); plt.show()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 5. ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ë° ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜\n",
        "# ==============================================================================\n",
        "def mix_at_snr(clean, noise, snr_db):\n",
        "    L = min(len(clean), len(noise))\n",
        "    c, n = clean[:L].astype(np.float32), noise[:L].astype(np.float32)\n",
        "    c_power = np.sqrt(np.mean(c**2)); n_power = np.sqrt(np.mean(n**2))\n",
        "    if n_power < 1e-8: return c\n",
        "    alpha = c_power / (n_power * (10**(snr_db / 20)))\n",
        "    return c + alpha * n\n",
        "\n",
        "def load_and_process_segment_efficient(file_info, duration, target_sr, config):\n",
        "    file_path, start_time, orig_sr = file_info\n",
        "    try:\n",
        "        start_frame = int(start_time * orig_sr)\n",
        "        num_frames = int(duration * orig_sr)\n",
        "        y_segment, _ = sf.read(file_path, start=start_frame, stop=start_frame + num_frames, dtype='float32', always_2d=False)\n",
        "        if y_segment.ndim > 1: y_segment = np.mean(y_segment, axis=1)\n",
        "        if orig_sr != target_sr: y_segment = librosa.resample(y=y_segment, orig_sr=orig_sr, target_sr=target_sr)\n",
        "        if config.get(\"apply_noise_reduction\", False): y_segment = nr.reduce_noise(y=y_segment, sr=target_sr)\n",
        "        if config.get(\"apply_rms_norm\", False):\n",
        "            rms = np.sqrt(np.mean(y_segment**2))\n",
        "            if rms > 1e-6: y_segment = y_segment * (10.0**(-20.0/20.0)/rms)\n",
        "        return y_segment\n",
        "    except Exception as e: return None\n",
        "\n",
        "def extract_yamnet_embedding(audio_info, model, config, noise_audio_infos=None, augment=False):\n",
        "    try:\n",
        "        y_segment = load_and_process_segment_efficient(audio_info, config[\"segment_duration\"], YAMNET_SAMPLE_RATE, config)\n",
        "        if y_segment is None: return None\n",
        "        if augment and noise_audio_infos:\n",
        "            noise_info = random.choice(noise_audio_infos)\n",
        "            y_noise = load_and_process_segment_efficient(noise_info, config[\"segment_duration\"], YAMNET_SAMPLE_RATE, {\"apply_noise_reduction\":False, \"apply_rms_norm\":True})\n",
        "            if y_noise is not None:\n",
        "                if config.get(\"use_snr_augmentation\", False):\n",
        "                    snr_db = random.uniform(config[\"snr_min_db\"], config[\"snr_max_db\"])\n",
        "                    y_segment = mix_at_snr(y_segment, y_noise, snr_db)\n",
        "                else:\n",
        "                    min_len = min(len(y_segment), len(y_noise))\n",
        "                    y_segment = y_segment[:min_len] + y_noise[:min_len] * config[\"noise_level\"]\n",
        "        _, embeddings, _ = model(y_segment)\n",
        "        return tf.reduce_mean(embeddings, axis=0).numpy() if embeddings.shape[0] > 0 else None\n",
        "    except Exception as e: return None\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 6. ëª¨ë¸ ê´€ë ¨ í•¨ìˆ˜ ì •ì˜ (í‰ê°€ íŒŒíŠ¸ ê°•í™”)\n",
        "# ==============================================================================\n",
        "def load_audio_models():\n",
        "    models = {}; print(\"\\nì˜¤ë””ì˜¤ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
        "    try:\n",
        "        models['YAMNet'] = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "        print(\"  YAMNet ëª¨ë¸ ë¡œë“œ: ì„±ê³µ\"); return models, True\n",
        "    except Exception as e:\n",
        "        print(f\"  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\"); return {}, False\n",
        "\n",
        "def build_classifier_model(input_shape, num_classes, learning_rate):\n",
        "    inp = Input(shape=(input_shape,), name='embedding_input')\n",
        "    x = Dense(256, activation='relu')(inp); x = Dropout(0.5)(x)\n",
        "    x = Dense(128, activation='relu')(x); x = Dropout(0.5)(x)\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def analyze_top_errors(y_true, y_pred_probs, segments_info, class_names, top_k=5):\n",
        "    \"\"\"ëª¨ë¸ì´ ê°€ì¥ í—·ê°ˆë ¤í•˜ëŠ” Top-K ì˜¤ë¥˜ ìƒ˜í”Œì„ ë¶„ì„í•˜ê³  ìŠ¤í™íŠ¸ë¡œê·¸ë¨ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.\"\"\"\n",
        "    print(f\"\\n--- Top-{top_k} ì˜¤ë¥˜ ì‹¬ì¸µ ë¶„ì„ ---\")\n",
        "    errors = []\n",
        "    ship_idx = list(class_names).index('ship')\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_label = y_true[i]\n",
        "        pred_label = np.argmax(y_pred_probs[i])\n",
        "\n",
        "        if true_label != pred_label:\n",
        "            error_magnitude = 0; error_type = \"\"\n",
        "            if pred_label == ship_idx: # False Positive (Noise -> Ship)\n",
        "                error_type = \"FP (Noise->Ship)\"; error_magnitude = y_pred_probs[i][ship_idx]\n",
        "            else: # False Negative (Ship -> Noise)\n",
        "                error_type = \"FN (Ship->Noise)\"; error_magnitude = 1 - y_pred_probs[i][ship_idx]\n",
        "            errors.append({\n",
        "                \"index\": i, \"type\": error_type, \"magnitude\": error_magnitude, \"info\": segments_info[i],\n",
        "                \"true_label\": class_names[true_label], \"pred_label\": class_names[pred_label],\n",
        "                \"confidence\": y_pred_probs[i][pred_label]\n",
        "            })\n",
        "\n",
        "    sorted_errors = sorted(errors, key=lambda x: x['magnitude'], reverse=True)\n",
        "    if not sorted_errors: print(\"  ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"); return\n",
        "\n",
        "    print(f\"ê°€ì¥ í™•ì‹ í•˜ë©° í‹€ë¦° {min(top_k, len(sorted_errors))}ê°œ ìƒ˜í”Œ:\")\n",
        "    for error in sorted_errors[:top_k]:\n",
        "        print(f\"  - íƒ€ì…: {error['type']}, ì‹ ë¢°ë„: {error['confidence']:.2f}, ì‹¤ì œ: {error['true_label']}, ì˜ˆì¸¡: {error['pred_label']}\")\n",
        "        print(f\"    - íŒŒì¼: {os.path.basename(error['info'][0])} (ì‹œì‘: {error['info'][1]:.2f}s)\")\n",
        "\n",
        "    fig, axes = plt.subplots(1, min(top_k, len(sorted_errors)), figsize=(5*min(top_k, len(sorted_errors)), 4), squeeze=False)\n",
        "    fig.suptitle('Top-K ì˜¤ë¥˜ ìƒ˜í”Œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨', fontsize=16)\n",
        "    for i, error in enumerate(sorted_errors[:top_k]):\n",
        "        ax = axes[0, i]\n",
        "        file_path, start_time, _ = error['info']\n",
        "        try:\n",
        "            y, _ = librosa.load(file_path, sr=YAMNET_SAMPLE_RATE, offset=start_time, duration=5.0)\n",
        "            D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "            librosa.display.specshow(D, sr=YAMNET_SAMPLE_RATE, x_axis='time', y_axis='log', ax=ax)\n",
        "            ax.set_title(f\"{error['type']}\\nTrue:{error['true_label']}, Pred:{error['pred_label']} ({error['confidence']:.2f})\")\n",
        "        except Exception as e: ax.set_title(\"ë¡œë“œ ì‹¤íŒ¨\")\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.93]); plt.show()\n",
        "\n",
        "def evaluate_and_visualize_model(model_name, trained_model, history, test_ds, test_steps, y_true_filtered, test_segments_info, label_encoder):\n",
        "    print(f\"\\n--- {model_name} ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ì‹œê°í™” ---\")\n",
        "    loss, accuracy = trained_model.evaluate(test_ds, steps=test_steps, verbose=0)\n",
        "    y_pred_probs = trained_model.predict(test_ds, steps=test_steps)\n",
        "    if len(y_pred_probs) != len(y_true_filtered): y_pred_probs = y_pred_probs[:len(y_true_filtered)]\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "    report_dict = classification_report(y_true_filtered, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    f1_macro = report_dict['macro avg']['f1-score']\n",
        "\n",
        "    ship_idx = list(label_encoder.classes_).index('ship')\n",
        "    y_scores = y_pred_probs[:, ship_idx]\n",
        "    fpr, tpr, _ = roc_curve(y_true_filtered, y_scores, pos_label=ship_idx)\n",
        "    auc_score = auc(fpr, tpr)\n",
        "\n",
        "    print(f\"  í…ŒìŠ¤íŠ¸ ì†ì‹¤: {loss:.4f}, ì •í™•ë„: {accuracy:.4f}, Macro F1: {f1_macro:.4f}, AUC: {auc_score:.4f}\")\n",
        "\n",
        "    print(\"\\n  [ë¶„ë¥˜ ë¦¬í¬íŠ¸]\"); print(classification_report(y_true_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "    cm = confusion_matrix(y_true_filtered, y_pred)\n",
        "    plt.figure(figsize=(6, 5)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "    plt.xlabel('ì˜ˆì¸¡ ë ˆì´ë¸”'); plt.ylabel('ì‹¤ì œ ë ˆì´ë¸”'); plt.title(f'{model_name} í˜¼ë™ í–‰ë ¬'); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(7, 6)); plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {auc_score:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--'); plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('Receiver Operating Characteristic (ROC) Curve'); plt.legend(loc=\"lower right\"); plt.grid(True); plt.show()\n",
        "\n",
        "    plt.figure(figsize=(12, 5)); plt.subplot(1, 2, 1); plt.plot(history.history['accuracy'], label='í›ˆë ¨ ì •í™•ë„'); plt.plot(history.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„')\n",
        "    plt.title('í›ˆë ¨ ë° ê²€ì¦ ì •í™•ë„'); plt.legend(); plt.subplot(1, 2, 2); plt.plot(history.history['loss'], label='í›ˆë ¨ ì†ì‹¤'); plt.plot(history.history['val_loss'], label='ê²€ì¦ ì†ì‹¤')\n",
        "    plt.title('í›ˆë ¨ ë° ê²€ì¦ ì†ì‹¤'); plt.legend(); plt.show()\n",
        "\n",
        "    analyze_top_errors(y_true_filtered, y_pred_probs, test_segments_info, label_encoder.classes_)\n",
        "\n",
        "    return {'loss': loss, 'accuracy': accuracy, 'f1_macro': f1_macro, 'auc': auc_score}\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# ## 7. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ë¹„êµ\n",
        "# ==============================================================================\n",
        "CONFIG = {\n",
        "    \"segment_duration\": 5.0, \"segment_overlap\": 0.5, \"undersample\": True,\n",
        "    \"apply_noise_reduction\": False, \"apply_rms_norm\": True,\n",
        "    \"use_snr_augmentation\": True, \"snr_min_db\": 0, \"snr_max_db\": 15, \"noise_level\": 0.05,\n",
        "    \"run_quality_evaluation\": True, \"quality_eval_samples\": 300,\n",
        "    \"test_size\": 0.2, \"epochs\": 50, \"batch_size\": 16, \"learning_rate\": 0.0005,\n",
        "}\n",
        "\n",
        "print(\">>> 1. ë°ì´í„° ë¡œë“œ ë° ì„¸ê·¸ë¨¼í…Œì´ì…˜ ì‹œì‘...\")\n",
        "all_segments_info, all_labels, is_data_ready = load_and_segment_data(DEEPSHIP_BASE_PATH, MBARI_NOISE_BASE_DIR, **{k:v for k,v in CONFIG.items() if k in ['segment_duration', 'segment_overlap', 'undersample']})\n",
        "\n",
        "if is_data_ready:\n",
        "    print(\"\\n>>> 2. Group-based ë°ì´í„° ë¶„í•  ì‹œì‘...\")\n",
        "    label_encoder = LabelEncoder(); encoded_labels = label_encoder.fit_transform(all_labels)\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    groups = [info[0] for info in all_segments_info]\n",
        "    gss = GroupShuffleSplit(n_splits=1, test_size=CONFIG[\"test_size\"], random_state=SEED)\n",
        "    train_idx, test_idx = next(gss.split(all_segments_info, encoded_labels, groups))\n",
        "    X_train_info = [all_segments_info[i] for i in train_idx]; y_train_enc = encoded_labels[train_idx]\n",
        "    X_test_info = [all_segments_info[i] for i in test_idx]; y_test_enc = encoded_labels[test_idx]\n",
        "    print(f\"ë°ì´í„° ë¶„í•  ì™„ë£Œ (íŒŒì¼ ë‹¨ìœ„): í›ˆë ¨ {len(X_train_info)}ê°œ, í…ŒìŠ¤íŠ¸ {len(X_test_info)}ê°œ\")\n",
        "    train_files_set = set(info[0] for info in X_train_info); test_files_set = set(info[0] for info in X_test_info)\n",
        "    print(f\"  í›ˆë ¨ì…‹ ê³ ìœ  íŒŒì¼ ìˆ˜: {len(train_files_set)}\"); print(f\"  í…ŒìŠ¤íŠ¸ì…‹ ê³ ìœ  íŒŒì¼ ìˆ˜: {len(test_files_set)}\"); print(f\"  ë‘ ì„¸íŠ¸ ê°„ ì¤‘ë³µ íŒŒì¼ ìˆ˜: {len(train_files_set.intersection(test_files_set))}\")\n",
        "else: is_data_ready = False\n",
        "\n",
        "if is_data_ready:\n",
        "    print(\"\\n>>> 3. ì˜¤ë””ì˜¤ ëª¨ë¸ ë¡œë“œ ì‹œì‘...\"); loaded_models, are_models_loaded = load_audio_models()\n",
        "    if not are_models_loaded: is_data_ready = False\n",
        "\n",
        "if is_data_ready and CONFIG[\"run_quality_evaluation\"]:\n",
        "    print(\"\\n>>> 4. ë°ì´í„°ì…‹ í’ˆì§ˆ ì‚¬ì „ í‰ê°€ ì‹œì‘...\")\n",
        "    sample_indices = random.sample(range(len(X_train_info)), min(CONFIG[\"quality_eval_samples\"], len(X_train_info)))\n",
        "    sample_info = [X_train_info[i] for i in sample_indices]; sample_labels = y_train_enc[sample_indices]\n",
        "    sample_embeddings = [extract_yamnet_embedding(info, loaded_models['YAMNet'], CONFIG) for info in sample_info]\n",
        "    valid_embeddings = [emb for emb in sample_embeddings if emb is not None]; valid_labels = [label for emb, label in zip(sample_embeddings, sample_labels) if emb is not None]\n",
        "    if valid_embeddings:\n",
        "        visualize_embeddings_with_umap(np.array(valid_embeddings), valid_labels, label_encoder.classes_)\n",
        "        visualize_spectrogram_samples(X_train_info, y_train_enc, label_encoder.classes_, CONFIG[\"segment_duration\"])\n",
        "    else: print(\"í’ˆì§ˆ í‰ê°€ìš© ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨.\")\n",
        "\n",
        "if is_data_ready:\n",
        "    print(\"\\n>>> 5. ëª¨ë¸ë³„ í•™ìŠµ, í‰ê°€ ë° ê²°ê³¼ ë¹„êµ ì‹œì‘...\")\n",
        "    evaluation_results = {}; temp_dir = tempfile.mkdtemp()\n",
        "    noise_files_train = [info for info, lbl in zip(X_train_info, y_train_enc) if label_encoder.inverse_transform([lbl])[0] == 'noise']\n",
        "    if not noise_files_train: print(\"ê²½ê³ : í›ˆë ¨ ë°ì´í„°ì— ë…¸ì´ì¦ˆ ìƒ˜í”Œì´ ì—†ì–´ ì¦ê°•ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    def make_dataset(file_paths, batch_size, num_classes, input_dim):\n",
        "        def gen():\n",
        "            while True:\n",
        "                random.shuffle(file_paths)\n",
        "                for i in range(0, len(file_paths), batch_size):\n",
        "                    paths = file_paths[i:i+batch_size]; embs, labs = [], []\n",
        "                    for p in paths:\n",
        "                        try:\n",
        "                            with np.load(p) as d: embs.append(d['embedding']); labs.append(d['label'])\n",
        "                        except Exception as e: continue\n",
        "                    if not embs: continue\n",
        "                    yield (np.asarray(embs, dtype=np.float32), tf.keras.utils.to_categorical(np.array(labs), num_classes=num_classes))\n",
        "        output_signature = (tf.TensorSpec(shape=(None, input_dim), dtype=tf.float32), tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32))\n",
        "        return tf.data.Dataset.from_generator(gen, output_signature=output_signature).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    for model_name in MODELS_TO_PROCESS:\n",
        "        print(f\"\\n{'='*25} {model_name} ëª¨ë¸ ì²˜ë¦¬ ì‹œì‘ {'='*25}\")\n",
        "        model_hub = loaded_models[model_name]; train_files, test_files, y_train_filt, y_test_filt = [], [], [], []\n",
        "\n",
        "        for split, info_list, y_list, out_files, out_y in [('train', X_train_info, y_train_enc, train_files, y_train_filt), ('test', X_test_info, y_test_enc, test_files, y_test_filt)]:\n",
        "            print(f\"  {model_name}: {split} ë°ì´í„° ì„ë² ë”© ì¶”ì¶œ ì¤‘...\")\n",
        "            for i, (segment_info, label) in enumerate(zip(info_list, y_list)):\n",
        "                is_ship = (label_encoder.inverse_transform([label])[0] == 'ship')\n",
        "                noise_src = noise_files_train if split == 'train' else None\n",
        "                emb = extract_yamnet_embedding(segment_info, model_hub, CONFIG, noise_audio_infos=noise_src, augment=(split=='train' and is_ship))\n",
        "                if emb is not None:\n",
        "                    path = os.path.join(temp_dir, f'{model_name}_{split}_{i}.npz')\n",
        "                    np.savez_compressed(path, embedding=emb, label=label)\n",
        "                    out_files.append(path); out_y.append(label)\n",
        "\n",
        "        if len(train_files) < CONFIG[\"batch_size\"] or not test_files:\n",
        "            print(f\"  {model_name}: ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ í•™ìŠµ/í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\"); continue\n",
        "\n",
        "        try:\n",
        "            with np.load(train_files[0]) as data: input_dim = data['embedding'].shape[-1]\n",
        "            print(f\"  ì„ë² ë”© ì°¨ì›ì„ ë™ì ìœ¼ë¡œ í™•ì¸: {input_dim}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ì„ë² ë”© ì°¨ì› í™•ì¸ ì‹¤íŒ¨. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\"); input_dim = YAMNET_EMBEDDING_DIM\n",
        "\n",
        "        classifier = build_classifier_model(input_dim, num_classes, CONFIG[\"learning_rate\"])\n",
        "        train_ds = make_dataset(train_files, CONFIG[\"batch_size\"], num_classes, input_dim)\n",
        "        test_ds  = make_dataset(test_files,  CONFIG[\"batch_size\"], num_classes, input_dim)\n",
        "        train_steps = math.ceil(len(train_files) / CONFIG[\"batch_size\"]); test_steps = math.ceil(len(test_files) / CONFIG[\"batch_size\"])\n",
        "\n",
        "        history = classifier.fit(train_ds,\n",
        "            steps_per_epoch=train_steps, validation_data=test_ds, validation_steps=test_steps,\n",
        "            epochs=CONFIG[\"epochs\"],\n",
        "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True), ReduceLROnPlateau(patience=5)], verbose=1\n",
        "        )\n",
        "\n",
        "        results = evaluate_and_visualize_model(model_name, classifier, history, test_ds, test_steps, np.array(y_test_filt), X_test_info, label_encoder)\n",
        "        evaluation_results[model_name] = results; gc.collect()\n",
        "\n",
        "    shutil.rmtree(temp_dir)\n",
        "    print(\"\\n--- 6. ìµœì¢… ì„±ëŠ¥ ë¹„êµ (F1, AUC í¬í•¨) ---\")\n",
        "    if evaluation_results:\n",
        "        results_df = pd.DataFrame(evaluation_results).T.sort_values('auc', ascending=False)\n",
        "        print(results_df.to_string(formatters={\n",
        "            'loss': '{:.4f}'.format, 'accuracy': '{:.4f}'.format,\n",
        "            'f1_macro': '{:.4f}'.format, 'auc': '{:.4f}'.format\n",
        "        }))\n",
        "    else: print(\"í‰ê°€ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "print(\"\\nğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ.\")"
      ],
      "metadata": {
        "id": "1-ZIkHcXGlzx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}