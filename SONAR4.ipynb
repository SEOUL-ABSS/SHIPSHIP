{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "SONAR4.ipynb",
      "history_visible": true,
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyPKLCNoC5L/0ERKoA2tFAId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/SHIPSHIP/blob/main/SONAR4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ceae40"
      },
      "source": [
        "## 1. 환경 설정 및 필수 라이브러리 임포트\n",
        "\n",
        "프로젝트에 필요한 라이브러리를 설치/임포트하고, 전역 상수 및 기본 설정을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16f4c6a",
        "outputId": "c3e35628-5929-45f4-b31e-99f5c039782e"
      },
      "source": [
        "# Install tensorflow\n",
        "!pip install -q tensorflow tensorflow-hub soundfile librosa\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. 환경 설정 및 필수 라이브러리 임포트\n",
        "# ==============================================================================\n",
        "print(\"1. 환경 설정 및 라이브러리 임포트 중...\")\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import soundfile as sf # WAV 파일 처리용\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager as fm # 폰트 관리자 임포트\n",
        "import requests # MBARI 데이터 다운로드용\n",
        "import subprocess # 오프라인 환경 패키지 다운로드용 (선택 사항)\n",
        "# from tensorflow_addons.optimizers import RectifiedAdam # 예시: TFA 옵티마이저 사용 시\n",
        "\n",
        "print(\"라이브러리 임포트 완료.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Matplotlib 한글 폰트 설정 (오류 수정 및 안정화)\n",
        "# ==============================================================================\n",
        "print(\"\\nMatplotlib 한글 폰트 설정 중...\")\n",
        "\n",
        "# Colab 환경에서 나눔고딕 폰트 설치 및 설정 시도\n",
        "# 설치 오류 방지를 위해 출력을 숨깁니다.\n",
        "!sudo apt-get update > /dev/null # Ensure apt cache is updated\n",
        "!sudo apt-get install -y fonts-nanum > /dev/null\n",
        "!sudo fc-cache -fv > /dev_null\n",
        "\n",
        "# 폰트 관리자 캐시 재로드 및 폰트 설정\n",
        "try:\n",
        "    # 나눔고딕 폰트 파일 경로 (Colab에 일반적으로 설치되는 위치)\n",
        "    font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "    if os.path.exists(font_path):\n",
        "        fm.fontManager.addfont(font_path)\n",
        "        plt.rc('font', family='NanumGothic') # 나눔고딕으로 설정\n",
        "        plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지\n",
        "        print(\"Matplotlib 폰트 설정 완료: NanumGothic\")\n",
        "    else:\n",
        "        print(f\"경고: 폰트 파일 '{font_path}'를 찾을 수 없습니다. 기본 폰트를 사용합니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"Matplotlib 폰트 설정 중 오류 발생: {e}. 기본 폰트를 사용합니다.\")\n",
        "\n",
        "print(\"Matplotlib 폰트 설정 완료.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 전역 상수 정의\n",
        "# ==============================================================================\n",
        "print(\"\\n전역 상수 정의 중...\")\n",
        "YAMNET_SAMPLE_RATE = 16000\n",
        "YAMNET_EMBEDDING_DIM = 1024 # YAMNet embedding dimension\n",
        "\n",
        "# VGGish embedding dimension (usually 128)\n",
        "# Based on TF Hub documentation for vggish/1, the output is 128-dimensional.\n",
        "VGGISH_EMBEDDING_DIM = 128\n",
        "\n",
        "# PANNs embedding dimension (using YAMNet placeholder for now)\n",
        "# If using a real PANNs model, this dimension would need to be updated based on the model's output.\n",
        "PANNS_EMBEDDING_DIM = YAMNET_EMBEDDING_DIM # Placeholder dimension, assuming similar output shape to YAMNet placeholder\n",
        "\n",
        "# Dataset Paths\n",
        "DEEPSHIP_BASE_PATH = '/content/DeepShip'\n",
        "# Directory where MBARI Noise Data will be stored.\n",
        "# Assuming this directory will contain .wav files acting as 'noise'.\n",
        "MBARI_NOISE_BASE_DIR = '/content/MBARI_noise_data'\n",
        "\n",
        "# List of DeepShip ship classes\n",
        "DEEPSHIP_CLASSES = ['Cargo', 'Passengership', 'Tanker', 'Tug']\n",
        "\n",
        "# List of models to process for comparison\n",
        "MODELS_TO_PROCESS = ['YAMNet', 'PANNs', 'VGGish'] # Use 'PANNs' as the key for the placeholder\n",
        "\n",
        "print(\"전역 상수 정의 완료.\")\n",
        "\n",
        "import os\n",
        "\n",
        "# Assuming DEEPSHIP_BASE_PATH and MBARI_NOISE_BASE_DIR are defined\n",
        "\n",
        "print(\"\\nDeepShip 데이터 디렉토리 내용 확인:\")\n",
        "if os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    print(f\"'{DEEPSHIP_BASE_PATH}' 내용:\")\n",
        "    # List contents of the DeepShip base directory, focusing on the expected class folders\n",
        "    expected_deepship_subdirs = DEEPSHIP_CLASSES # Use the global constant\n",
        "    found_content = False\n",
        "    for item in os.listdir(DEEPSHIP_BASE_PATH):\n",
        "        item_path = os.path.join(DEEPSHIP_BASE_PATH, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"  {item}/\")\n",
        "            # If it's an expected class directory, list some of its contents\n",
        "            if item in expected_deepship_subdirs:\n",
        "                 try:\n",
        "                     files_in_class_dir = os.listdir(item_path)\n",
        "                     print(f\"    ({len(files_in_class_dir)} items)\")\n",
        "                     for f in files_in_class_dir[:5]: # List up to 5 files\n",
        "                         print(f\"      {f}\")\n",
        "                     if len(files_in_class_dir) > 5:\n",
        "                         print(\"      ...\")\n",
        "                     found_content = True\n",
        "                 except Exception as e:\n",
        "                      print(f\"    오류: 디렉토리 내용 확인 중 오류 발생: {e}\")\n",
        "            else:\n",
        "                 # List contents of unexpected subdirectories briefly\n",
        "                 try:\n",
        "                      sub_items = os.listdir(item_path)\n",
        "                      print(f\"    ({len(sub_items)} items)\")\n",
        "                      for f in sub_items[:3]: # List up to 3 items in other subdirs\n",
        "                          print(f\"      {f}\")\n",
        "                      if len(sub_items) > 3:\n",
        "                          print(\"      ...\")\n",
        "                 except Exception as e:\n",
        "                      print(f\"    오류: 디렉토리 내용 확인 중 오류 발생: {e}\")\n",
        "\n",
        "        elif os.path.isfile(item_path):\n",
        "            print(f\"  {item}\")\n",
        "            found_content = True\n",
        "\n",
        "    if not found_content:\n",
        "        print(\"  (디렉토리가 비어 있습니다)\")\n",
        "\n",
        "else:\n",
        "    print(f\"경고: DeepShip Base Path '{DEEPSHIP_BASE_PATH}'를 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\nMBARI 노이즈 데이터 디렉토리 내용 확인:\")\n",
        "if os.path.exists(MBARI_NOISE_BASE_DIR):\n",
        "    print(f\"'{MBARI_NOISE_BASE_DIR}' 내용:\")\n",
        "    found_noise_content = False\n",
        "    for root, dirs, files in os.walk(MBARI_NOISE_BASE_DIR):\n",
        "        level = root.replace(MBARI_NOISE_BASE_DIR, '').count(os.sep)\n",
        "        indent = '  ' * level\n",
        "        print(f'{indent}{os.path.basename(root)}/')\n",
        "        subindent = '  ' * (level + 1)\n",
        "        if dirs:\n",
        "             for d in dirs[:5]: # List up to 5 subdirectories\n",
        "                  print(f'{subindent}{d}/')\n",
        "             if len(dirs) > 5:\n",
        "                  print(f'{subindent}...')\n",
        "\n",
        "        if files:\n",
        "             print(f'{subindent}파일들 ({len(files)}개):')\n",
        "             for f in files[:5]: # List up to 5 files\n",
        "                 print(f'{subindent}{f}')\n",
        "                 if f.endswith('.wav'):\n",
        "                      found_noise_content = True # Found at least one wav file\n",
        "             if len(files) > 5:\n",
        "                  print(f'{subindent}...')\n",
        "        if not dirs and not files:\n",
        "             print(f'{subindent}(비어 있음)')\n",
        "\n",
        "\n",
        "    if not found_noise_content:\n",
        "        print(\"\\n경고: MBARI 노이즈 데이터 디렉토리에서 .wav 파일을 찾지 못했습니다.\")\n",
        "\n",
        "else:\n",
        "    print(f\"경고: MBARI Noise Base Directory '{MBARI_NOISE_BASE_DIR}'를 찾을 수 없습니다.\")\n",
        "\n",
        "print(\"\\n데이터 디렉토리 내용 확인 완료.\")\n",
        "\n",
        "# Install boto3 for S3 access\n",
        "!pip install -q boto3\n",
        "print(\"boto3 설치 완료.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 환경 설정 및 라이브러리 임포트 중...\n",
            "라이브러리 임포트 완료.\n",
            "\n",
            "Matplotlib 한글 폰트 설정 중...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Matplotlib 폰트 설정 완료: NanumGothic\n",
            "Matplotlib 폰트 설정 완료.\n",
            "\n",
            "전역 상수 정의 중...\n",
            "전역 상수 정의 완료.\n",
            "\n",
            "DeepShip 데이터 디렉토리 내용 확인:\n",
            "'/content/DeepShip' 내용:\n",
            "  Cargo/\n",
            "    (13 items)\n",
            "      38.wav\n",
            "      15.wav\n",
            "      69.wav\n",
            "      cargo-metafile\n",
            "      27.wav\n",
            "      ...\n",
            "  Tanker/\n",
            "    (29 items)\n",
            "      10.wav\n",
            "      30.wav\n",
            "      38.wav\n",
            "      18.wav\n",
            "      13.wav\n",
            "      ...\n",
            "  README.txt\n",
            "  .git/\n",
            "    (12 items)\n",
            "      objects\n",
            "      logs\n",
            "      shallow\n",
            "      ...\n",
            "  Tug/\n",
            "    (4 items)\n",
            "      40.wav\n",
            "      9.wav\n",
            "      49.wav\n",
            "      tug-metafile\n",
            "  Passengership/\n",
            "    (21 items)\n",
            "      30.wav\n",
            "      37.wav\n",
            "      23.wav\n",
            "      27.wav\n",
            "      31.wav\n",
            "      ...\n",
            "\n",
            "MBARI 노이즈 데이터 디렉토리 내용 확인:\n",
            "'/content/MBARI_noise_data' 내용:\n",
            "MBARI_noise_data/\n",
            "  파일들 (10개):\n",
            "  MARS-20180105T000000Z-16kHz.wav\n",
            "  MARS-20180108T000000Z-16kHz.wav\n",
            "  MARS-20180107T000000Z-16kHz.wav\n",
            "  MARS-20180101T000000Z-16kHz.wav\n",
            "  MARS-20180109T000000Z-16kHz.wav\n",
            "  ...\n",
            "\n",
            "데이터 디렉토리 내용 확인 완료.\n",
            "boto3 설치 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45088e0e"
      },
      "source": [
        "## 2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비\n",
        "\n",
        "DeepShip 데이터셋을 클론하고, MBARI 노이즈 데이터 디렉토리를 준비합니다. 이전에 다운로드된 MBARI 노이즈 샘플 파일이 있다면 해당 디렉토리로 이동시킵니다.\n",
        "\n",
        "**주의**: 실제 MBARI Pacific Sound 16kHz 데이터셋은 직접 다운로드 또는 접근 설정이 필요할 수 있습니다. 아래 코드는 DeepShip 클론 및 샘플 노이즈 파일 처리를 위한 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b99722d3",
        "outputId": "534955b8-2200-4b78-e4bc-4409b7c3ccee"
      },
      "source": [
        "# ==============================================================================\n",
        "# 2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 (MBARI 다운로드 포함)\n",
        "# ==============================================================================\n",
        "import boto3 # Ensure boto3 is imported\n",
        "from botocore import UNSIGNED # Ensure UNSIGNED config is imported\n",
        "from botocore.client import Config # Ensure Config is imported\n",
        "from pathlib import Path # Ensure Path is imported\n",
        "import io # Ensure io is imported for potential in-memory reads (though we're downloading)\n",
        "from six.moves.urllib.request import urlopen # Ensure urlopen is imported if still needed (less likely with direct S3 download)\n",
        "import os # Ensure os is imported\n",
        "import subprocess # Ensure subprocess is imported\n",
        "\n",
        "print(\"\\n2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 중...\")\n",
        "\n",
        "# Check if DeepShip is already cloned\n",
        "if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    print(f\"DeepShip 데이터셋 클론 중: {DEEPSHIP_BASE_PATH}\")\n",
        "    # Clone the DeepShip repository\n",
        "    # Use --depth 1 to clone only the latest commit, saving time and space\n",
        "    try:\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', 'https://github.com/irfankamboh/DeepShip.git', DEEPSHIP_BASE_PATH], check=True, capture_output=True)\n",
        "        print(\"DeepShip 데이터셋 클론 완료.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"오류: DeepShip 데이터셋 클론 실패: {e.stderr.decode()}\")\n",
        "        print(\"수동으로 https://github.com/irfankamboh/DeepShip.git 를 클론하거나 다운로드하여\")\n",
        "        print(f\"'{DEEPSHIP_BASE_PATH}' 경로에 위치시켜주세요.\")\n",
        "    except Exception as e:\n",
        "         print(f\"오류: DeepShip 데이터셋 클론 중 예기치 않은 오류 발생: {e}\")\n",
        "else:\n",
        "    print(f\"DeepShip 데이터셋이 이미 존재합니다: {DEEPSHIP_BASE_PATH}\")\n",
        "\n",
        "# Ensure the MBARI noise base directory exists\n",
        "os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "print(f\"MBARI 노이즈 데이터 디렉토리 확인/생성 완료: {MBARI_NOISE_BASE_DIR}\")\n",
        "\n",
        "# --- Check if MBARI Noise Data already exists ---\n",
        "# Count the number of .wav files in the MBARI_NOISE_BASE_DIR\n",
        "existing_noise_files = [f for f in os.listdir(MBARI_NOISE_BASE_DIR) if f.endswith('.wav')]\n",
        "\n",
        "if existing_noise_files:\n",
        "    print(f\"\\nMBARI 노이즈 데이터가 지정된 디렉토리('{MBARI_NOISE_BASE_DIR}')에 이미 존재합니다. 다운로드를 건너뜁니다. (발견된 .wav 파일 수: {len(existing_noise_files)})\")\n",
        "else:\n",
        "    # --- MBARI Noise Data Download ---\n",
        "    # Use Boto3 to access the public S3 bucket and download a limited number of files\n",
        "    # Based on the provided documentation example.\n",
        "    s3_client = boto3.client('s3',\n",
        "        aws_access_key_id='',\n",
        "        aws_secret_access_key='',\n",
        "        config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "    bucket = 'pacific-sound-16khz'\n",
        "    # Define a prefix to narrow down the files (e.g., a specific year and month)\n",
        "    # The documentation example uses '2018/01/'. Let's keep this or choose another if needed.\n",
        "    prefix = '2018/01/' # Using January 2018 data as example\n",
        "\n",
        "    # Limit the number of files to download to avoid excessive processing time and storage\n",
        "    MAX_NOISE_FILES_TO_DOWNLOAD = 10 # Set the limit to 10 as requested\n",
        "\n",
        "    print(f\"\\nMBARI 노이즈 데이터 다운로드 시도 중 (S3 버킷: {bucket}, Prefix: {prefix}, 최대 {MAX_NOISE_FILES_TO_DOWNLOAD} 파일):\")\n",
        "\n",
        "    try:\n",
        "        # List objects in the specified bucket and prefix, potentially in pages\n",
        "        paginator = s3_client.get_paginator('list_objects_v2')\n",
        "        pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
        "\n",
        "        downloaded_count = 0\n",
        "        found_any_objects = False # Track if any objects were found at all\n",
        "\n",
        "        for page in pages:\n",
        "            if 'Contents' in page:\n",
        "                found_any_objects = True\n",
        "                # print(f\"  페이지에서 {len(page['Contents'])}개의 파일 발견. 다운로드 가능한 .wav 파일 탐색 중...\") # Too verbose\n",
        "\n",
        "                for obj in page['Contents']:\n",
        "                    key = obj['Key']\n",
        "                    # Only download .wav files and avoid directories or empty files\n",
        "                    if key.endswith('.wav') and obj.get('Size', 0) > 0:\n",
        "                        # Construct the local file path to save within the MBARI_NOISE_BASE_DIR\n",
        "                        local_file_path = os.path.join(MBARI_NOISE_BASE_DIR, os.path.basename(key))\n",
        "\n",
        "                        # Check if the file already exists locally to avoid re-downloading\n",
        "                        if os.path.exists(local_file_path):\n",
        "                            # print(f\"    파일이 이미 존재합니다. 건너뜁니다: {os.path.basename(key)}\") # Too verbose\n",
        "                            pass # Skip if file already exists\n",
        "                        else:\n",
        "                            print(f\"    다운로드 중: {os.path.basename(key)}...\")\n",
        "                            try:\n",
        "                                s3_client.download_file(bucket, key, local_file_path)\n",
        "                                downloaded_count += 1\n",
        "                                print(f\"      다운로드 완료 ({downloaded_count}/{MAX_NOISE_FILES_TO_DOWNLOAD})\")\n",
        "                            except Exception as download_e:\n",
        "                                 print(f\"    오류: 파일 다운로드 실패 ({os.path.basename(key)}): {download_e}\")\n",
        "\n",
        "                        # Stop downloading once the limit is reached\n",
        "                        if downloaded_count >= MAX_NOISE_FILES_TO_DOWNLOAD:\n",
        "                            print(f\"\\n  최대 다운로드 파일 수({MAX_NOISE_FILES_TO_DOWNLOAD})에 도달했습니다. 다운로드를 중지합니다.\")\n",
        "                            break # Break from the inner loop (files in this page)\n",
        "\n",
        "                if downloaded_count >= MAX_NOISE_FILES_TO_DOWNLOAD:\n",
        "                     break # Break from the outer loop (pages)\n",
        "\n",
        "\n",
        "        if not found_any_objects:\n",
        "            print(f\"  경고: 지정된 Prefix '{prefix}'에서 파일을 찾을 수 없습니다.\")\n",
        "        elif downloaded_count == 0:\n",
        "             # response might not be defined if no objects were found at all\n",
        "             num_total_objects = 0\n",
        "             try:\n",
        "                  initial_response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=1) # Check if any object exists\n",
        "                  if 'Contents' in initial_response:\n",
        "                       num_total_objects = len(initial_response['Contents']) # This is just the first page count if MaxKeys > 1, or just 1 if MaxKeys=1\n",
        "             except Exception:\n",
        "                  pass # Ignore error if listing fails\n",
        "\n",
        "             if num_total_objects > 0:\n",
        "                  print(f\"\\n  지정된 Prefix '{prefix}'에 파일이 존재하지만, 다운로드 가능한 .wav 파일을 찾지 못했거나 모두 건너뛰었습니다.\")\n",
        "             else:\n",
        "                  print(f\"\\n  지정된 Prefix '{prefix}'에 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n총 {downloaded_count}개의 노이즈 .wav 파일을 다운로드했습니다.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: MBARI 노이즈 데이터 다운로드 중 오류 발생: {e}\")\n",
        "        print(\"S3 버킷 접근 권한, Prefix 설정, 또는 Boto3 설정/설치를 확인해주세요.\")\n",
        "\n",
        "\n",
        "# Note: To get sufficient noise data for meaningful training, you may need to adjust the 'prefix'\n",
        "# or 'MAX_NOISE_FILES_TO_DOWNLOAD', or implement more complex logic to gather data from multiple\n",
        "# prefixes/months, depending on your data needs and the S3 bucket structure.\n",
        "# Ensure that the downloaded data includes enough samples from the 'noise' category.\n",
        "\n",
        "\n",
        "print(\"\\n2. 데이터 확보 단계 완료.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 중...\n",
            "DeepShip 데이터셋이 이미 존재합니다: /content/DeepShip\n",
            "MBARI 노이즈 데이터 디렉토리 확인/생성 완료: /content/MBARI_noise_data\n",
            "\n",
            "MBARI 노이즈 데이터가 지정된 디렉토리('/content/MBARI_noise_data')에 이미 존재합니다. 다운로드를 건너뜁니다. (발견된 .wav 파일 수: 10)\n",
            "\n",
            "2. 데이터 확보 단계 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6181734b"
      },
      "source": [
        "## 3. 데이터 로드 및 준비 함수 정의\n",
        "\n",
        "DeepShip 데이터와 노이즈 데이터를 수집하고, 'ship' 및 'noise' 레이블을 할당하며, 훈련 및 테스트 세트로 분할하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9386cf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming DEEPSHIP_BASE_PATH, MBARI_NOISE_BASE_DIR, DEEPSHIP_CLASSES are defined in previous cells.\n",
        "\n",
        "def load_and_prepare_dataset(deepship_path, noise_data_dir, deepship_classes, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    DeepShip 데이터셋과 노이즈 데이터를 로드하고 이진 분류(ship vs noise)를 위해 준비합니다.\n",
        "\n",
        "    Args:\n",
        "        deepship_path (str): DeepShip 데이터셋의 기본 경로.\n",
        "        noise_data_dir (str): 노이즈 오디오 파일이 있는 디렉토리 경로.\n",
        "        deepship_classes (list): DeepShip 데이터셋의 선박 클래스 이름 목록.\n",
        "        test_size (float): 테스트 세트의 비율.\n",
        "        random_state (int): 데이터 분할을 위한 랜덤 시드.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths)\n",
        "               데이터 로드 및 준비 상태에 따라 결과가 달라질 수 있습니다.\n",
        "               데이터 부족 시 X_train/test_paths, y_train/test_encoded는 빈 리스트/NumPy 배열이 됩니다.\n",
        "               noise_audio_paths는 수집된 노이즈 파일 경로 목록입니다.\n",
        "    \"\"\"\n",
        "    all_audio_paths = []\n",
        "    all_labels = []\n",
        "    noise_audio_paths = [] # List to store noise file paths for augmentation\n",
        "    is_data_prepared = False\n",
        "    label_encoder = None\n",
        "    num_classes = 0\n",
        "\n",
        "    print(\"\\n데이터셋 로드 및 준비 시작: Ship vs Noise\")\n",
        "    print(f\"DeepShip Base Path: {deepship_path}\")\n",
        "    print(f\"MBARI Noise Data Directory: {noise_data_dir}\")\n",
        "\n",
        "    # --- 1. Integrate DeepShip Data ('ship') ---\n",
        "    is_deepship_available = os.path.exists(deepship_path)\n",
        "    if is_deepship_available:\n",
        "        print(f\"DeepShip 데이터셋에서 'ship' 오디오 파일 수집 중: {deepship_path}\")\n",
        "        found_ship_files = False\n",
        "        # CORRECTED: Iterate directly through the class subdirectories at the top level of DeepShip\n",
        "        for class_name in deepship_classes: # Use the provided deepship_classes list\n",
        "            class_path = os.path.join(deepship_path, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                print(f\"  클래스 폴더 발견: {class_path} -> Class: {class_name}\")\n",
        "                for file_name in os.listdir(class_path):\n",
        "                    if file_name.endswith('.wav'):\n",
        "                        audio_path = os.path.join(class_path, file_name)\n",
        "                        all_audio_paths.append(audio_path)\n",
        "                        all_labels.append('ship') # Label all DeepShip ship types as 'ship'\n",
        "                        found_ship_files = True\n",
        "            else:\n",
        "                 print(f\"  경고: 예상 클래스 폴더 '{class_name}'를 '{deepship_path}'에서 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "        if not found_ship_files:\n",
        "            print(f\"경고: '{deepship_path}' 내의 예상 클래스 폴더에서 'ship'으로 사용할 .wav 파일을 찾지 못했습니다. DeepShip 데이터셋 구조를 확인하세요.\")\n",
        "    else:\n",
        "        print(f\"경고: DeepShip 데이터셋을 찾을 수 없어 'ship' 데이터 수집을 건너뜁니다: {deepship_path}\")\n",
        "\n",
        "\n",
        "    # --- 2. Integrate Noise Data ('noise') ---\n",
        "    is_noise_data_available_dir = os.path.exists(noise_data_dir)\n",
        "    if is_noise_data_available_dir:\n",
        "        print(f\"노이즈 데이터 수집 중: {noise_data_dir}\")\n",
        "        found_noise_files = False\n",
        "        # Collect all .wav files under the noise data directory\n",
        "        for root, _, files in os.walk(noise_data_dir):\n",
        "             # Exclude the DeepShip directory itself if it was downloaded into the noise dir by mistake\n",
        "             if root.startswith(deepship_path):\n",
        "                  continue\n",
        "             for file_name in files:\n",
        "                 if file_name.endswith('.wav'):\n",
        "                     audio_path = os.path.join(root, file_name)\n",
        "                     # Ensure we don't duplicate paths if DeepShip and downloaded DeepShip point to the same files\n",
        "                     if audio_path not in all_audio_paths: # Avoid adding DeepShip files if they somehow ended up here\n",
        "                         all_audio_paths.append(audio_path)\n",
        "                         all_labels.append('noise') # 모든 노이즈 데이터를 'noise'로 레이블링\n",
        "                         noise_audio_paths.append(audio_path) # Also add to noise_audio_paths for augmentation\n",
        "                         found_noise_files = True\n",
        "\n",
        "        if not found_noise_files:\n",
        "            print(f\"경고: '{noise_data_dir}'에서 'noise'로 사용할 .wav 파일을 찾지 못했습니다.\")\n",
        "    else:\n",
        "        print(f\"경고: 노이즈 데이터 디렉토리 '{noise_data_dir}'를 찾을 수 없어 'noise' 데이터 수집을 건너뜁니다.\")\n",
        "        print(\"실제 노이즈 데이터를 다운로드하여 이 디렉토리에 위치시켜주세요.\")\n",
        "\n",
        "\n",
        "    # --- 3. Data Preparation and Split ---\n",
        "    unique_labels = np.unique(all_labels)\n",
        "\n",
        "    # Check if data for both 'ship' and 'noise' classes is available and sufficient\n",
        "    # We need at least 2 classes and some data for each class to perform a stratified split\n",
        "    if len(all_audio_paths) > 0 and len(unique_labels) >= 2:\n",
        "        # Check if each unique label has at least 2 samples for stratified split\n",
        "        label_counts = pd.Series(all_labels).value_counts()\n",
        "        if all(count >= 2 for count in label_counts):\n",
        "            print(f\"\\n데이터 수집 완료. 총 샘플 수: {len(all_audio_paths)}\")\n",
        "            print(f\"클래스 분포: {label_counts.to_dict()}\")\n",
        "\n",
        "            # 레이블 인코딩 ('ship', 'noise' 등 -> 0, 1 등)\n",
        "            label_encoder = LabelEncoder()\n",
        "            encoded_labels = label_encoder.fit_transform(all_labels)\n",
        "            num_classes = len(label_encoder.classes_)\n",
        "            print(f\"레이블 인코딩 완료. 클래스: {label_encoder.classes_}, 총 {num_classes}개\")\n",
        "\n",
        "            # 데이터셋 분할 (훈련 및 테스트) - Stratified split으로 클래스 비율 유지\n",
        "            X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = train_test_split(\n",
        "                all_audio_paths, encoded_labels, test_size=test_size, random_state=random_state, stratify=encoded_labels\n",
        "            )\n",
        "\n",
        "            print(f\"데이터 분할 완료.\")\n",
        "            print(f\"훈련 데이터 샘플 수: {len(X_train_paths)}\")\n",
        "            print(f\"테스트 데이터 샘플 수: {len(X_test_paths)}\")\n",
        "            is_data_prepared = True # 데이터 준비 성공 플래그\n",
        "\n",
        "        else:\n",
        "             print(\"\\n오류: 각 클래스별 샘플 수가 부족하여 데이터 분할(stratified split)을 수행할 수 없습니다.\")\n",
        "             print(f\"클래스별 샘플 수: {label_counts.to_dict()}\")\n",
        "             is_data_prepared = False\n",
        "             X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = [], [], np.array([]), np.array([])\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"\\n오류: 'ship'과 'noise' 이진 분류를 위한 데이터가 충분하지 않습니다.\")\n",
        "        print(f\"수집된 총 샘플 수: {len(all_audio_paths)}, 확인된 클래스: {unique_labels}\")\n",
        "        print(\"DeepShip 데이터셋이 올바르게 클론되었는지, 노이즈 데이터가 '{noise_data_dir}'에 충분히 있는지 확인해주세요.\")\n",
        "        is_data_prepared = False\n",
        "        X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = [], [], np.array([]), np.array([])\n",
        "\n",
        "\n",
        "    print(\"\\n데이터셋 로드 및 준비 함수 정의 완료.\")\n",
        "\n",
        "    # Return values regardless of success, check is_data_prepared flag later\n",
        "    # Also return noise_audio_paths for potential augmentation\n",
        "    return X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7be3e41"
      },
      "source": [
        "## 4. 오디오 전처리 및 임베딩 추출 함수 정의\n",
        "\n",
        "각 오디오 모델(YAMNet, PANNs, VGGish)에 대한 오디오 전처리 및 임베딩 추출 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "617c87ca",
        "outputId": "87ff7d6a-d722-4c74-9f93-6adad316ea58"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import os\n",
        "import time # 시간 측정을 위해 임포트\n",
        "import sys # traceback 출력을 위해 임포트\n",
        "import random # 노이즈 증강에 사용\n",
        "\n",
        "\n",
        "# 오디오 파일을 로드하고 지정된 샘플링 속도로 리샘플링하는 함수 (Step 3에도 동일하게 정의됨)\n",
        "# 이 함수는 이제 세그먼트 로딩 로직을 포함하도록 수정될 수 있습니다.\n",
        "# 하지만 여기서는 단순 파일 로드 및 리샘플링 기능만 유지하고, 세그먼트 처리는 추출 함수 내부나 데이터 로드 단계에서 수행하도록 합니다.\n",
        "# load_and_resample_audio 함수는 Step 3(셀 ID 5d281826)에서 정의된 최신 버전을 사용해야 합니다.\n",
        "# 여기서는 함수 정의를 반복하지 않습니다. (동일 함수 중복 정의 방지)\n",
        "# 만약 Step 3 셀 실행 전에 이 셀이 실행된다면 NameError가 발생할 수 있습니다.\n",
        "# 따라서 Step 3 셀을 먼저 실행해야 합니다.\n",
        "\n",
        "# Step 3 셀에서 정의된 load_and_resample_audio 함수가 사용 가능하도록 합니다.\n",
        "# try-except 블록을 사용하여 함수 존재 여부 확인\n",
        "try:\n",
        "    load_and_resample_audio = load_and_resample_audio # Step 3에서 정의된 함수를 사용\n",
        "    print(\"Step 3에서 load_and_resample_audio 함수를 성공적으로 가져왔습니다.\")\n",
        "except NameError:\n",
        "    print(\"오류: Step 3 셀(load_and_prepare_dataset 함수 정의 셀)이 실행되지 않았거나 load_and_resample_audio 함수가 정의되지 않았습니다.\")\n",
        "    print(\"Step 3 셀을 먼저 실행해주세요.\")\n",
        "    # 함수가 없을 경우 더미 함수 정의 (오류 방지)\n",
        "    def load_and_resample_audio(file_path, target_sample_rate):\n",
        "        print(f\"경고: load_and_resample_audio 함수가 정의되지 않아 파일 로드/리샘플링을 건너뜁니다: {file_path}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# --- 1. YAMNet 임베딩 추출 함수 (세그먼트 처리 가능하도록 수정) ---\n",
        "# YAMNet 모델 로드 (TensorFlow Hub 사용)\n",
        "# 모델 로드는 한 번만 수행하도록 함수 외부에 정의\n",
        "try:\n",
        "    yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "    print(\"YAMNet 모델 로드 완료.\")\n",
        "except Exception as e:\n",
        "    yamnet_model = None\n",
        "    print(f\"YAMNet 모델 로드 실패: {e}\")\n",
        "    print(\"YAMNet 임베딩 추출 기능을 사용할 수 없습니다.\")\n",
        "\n",
        "\n",
        "# YAMNet 임베딩 차원 정의 (모델 출력 차원에 맞춰야 함)\n",
        "YAMNET_EMBEDDING_DIM = 1024 # YAMNet 모델의 임베딩 차원\n",
        "\n",
        "# YAMNet 임베딩 추출 함수 수정: 파일 경로와 세그먼트 시작 시간을 인자로 받음\n",
        "def extract_yamnet_embedding(audio_info: tuple, model, augment_with_noise: bool = False, noise_audio_paths: list = None, noise_level: float = 0.1, segment_duration_sec: int = 5, target_sample_rate: int = 16000):\n",
        "    \"\"\"\n",
        "    오디오 세그먼트 정보(원본 파일 경로, 시작 시간)를 받아 YAMNet 임베딩을 추출합니다.\n",
        "    필요 시 노이즈 증강을 적용합니다.\n",
        "\n",
        "    Args:\n",
        "        audio_info (tuple): (원본 파일 경로, 세그먼트 시작 시간(초)) 튜플.\n",
        "        model: 로드된 YAMNet 모델 객체.\n",
        "        augment_with_noise (bool): 노이즈 증강 적용 여부.\n",
        "        noise_audio_paths (list): 노이즈 오디오 파일 경로 목록 (증강 시 사용).\n",
        "        noise_level (float): 노이즈 레벨 (0.0 ~ 1.0).\n",
        "        segment_duration_sec (int): 세그먼트 길이 (초).\n",
        "        target_sample_rate (int): 임베딩 모델이 기대하는 샘플링 속도.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 추출된 임베딩 벡터. 임베딩 추출 실패 시 None 반환.\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        # print(\"경고: YAMNet 모델이 로드되지 않았습니다. 임베딩 추출을 건너뜁니다.\") # 너무 자세하면 생략\n",
        "        return None\n",
        "\n",
        "    file_path, start_time_sec = audio_info # 세그먼트 정보 언팩\n",
        "\n",
        "    try:\n",
        "        # 원본 오디오 파일 로드 및 리샘플링 (load_and_resample_audio 함수 사용)\n",
        "        # 전체 파일을 로드하고, 필요한 세그먼트만 잘라냅니다.\n",
        "        audio, sr = load_and_resample_audio(file_path, target_sample_rate)\n",
        "\n",
        "        if audio is None or sr is None:\n",
        "            # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 로드/리샘플링 실패.\") # 너무 자세하면 생략\n",
        "            return None\n",
        "\n",
        "        # 세그먼트 시작 및 종료 샘플 인덱스 계산\n",
        "        start_sample = int(start_time_sec * sr)\n",
        "        end_sample = start_sample + int(segment_duration_sec * sr)\n",
        "\n",
        "        # 세그먼트 오디오 데이터 추출\n",
        "        # 오디오 길이가 세그먼트 종료 인덱스보다 짧을 경우, 가능한 만큼만 추출\n",
        "        segment_audio = audio[start_sample:min(end_sample, len(audio))]\n",
        "\n",
        "        # 세그먼트 길이가 임베딩 모델이 요구하는 최소 길이보다 짧을 경우 패딩 또는 건너뛰기\n",
        "        # YAMNet은 약 0.96초 길이의 프레임을 처리하므로, 5초 세그먼트면 충분히 깁니다.\n",
        "        # 하지만 마지막 세그먼트 길이가 짧을 수 있으므로 패딩 로직 추가 (필요 시)\n",
        "        min_model_input_samples = int(0.96 * sr) # YAMNet 프레임 길이 (대략)\n",
        "        if len(segment_audio) < min_model_input_samples:\n",
        "            # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 길이가 짧습니다 ({len(segment_audio)} 샘플). 패딩 또는 건너뜁니다.\")\n",
        "            # 간단하게 패딩 (필요 시)\n",
        "            # padded_segment = np.pad(segment_audio, (0, max(0, min_model_input_samples - len(segment_audio))), mode='constant')\n",
        "            # segment_audio = padded_segment\n",
        "            # 또는 건너뛰기\n",
        "            return None # 길이가 너무 짧으면 건너뛰기\n",
        "\n",
        "\n",
        "        # 노이즈 증강 적용 (훈련 데이터에만 적용)\n",
        "        if augment_with_noise and noise_audio_paths and len(noise_audio_paths) > 0:\n",
        "            try:\n",
        "                 # 랜덤 노이즈 파일 선택\n",
        "                 random_noise_file = random.choice(noise_audio_paths)\n",
        "                 # 노이즈 오디오 로드 및 리샘플링\n",
        "                 noise_audio, noise_sr = load_and_resample_audio(random_noise_file, target_sample_rate)\n",
        "\n",
        "                 if noise_audio is not None and noise_sr is not None:\n",
        "                      # 노이즈 세그먼트 추출 (랜덤 위치)\n",
        "                      noise_segment_length = len(segment_audio)\n",
        "                      if len(noise_audio) >= noise_segment_length:\n",
        "                           noise_start_sample = random.randint(0, len(noise_audio) - noise_segment_length)\n",
        "                           noise_segment = noise_audio[noise_start_sample:noise_start_sample + noise_segment_length]\n",
        "                           # 원본 세그먼트와 노이즈 세그먼트 혼합\n",
        "                           # 혼합 비율 계산 (예: noise_level에 따라)\n",
        "                           alpha = 1.0 # 원본 오디오 비율\n",
        "                           beta = noise_level # 노이즈 오디오 비율\n",
        "                           # 두 오디오의 피크 레벨을 정규화하고 혼합 (간단한 혼합 예시)\n",
        "                           mixed_segment = segment_audio + beta * noise_segment * (np.max(segment_audio) / (np.max(noise_segment) + 1e-8))\n",
        "                           # 혼합된 오디오 클리핑 방지 및 정규화\n",
        "                           mixed_segment = np.clip(mixed_segment, -1.0, 1.0)\n",
        "                           segment_audio = mixed_segment # 증강된 세그먼트로 교체\n",
        "                       else:\n",
        "                           # print(f\"경고: 노이즈 파일 '{os.path.basename(random_noise_file)}' 길이가 세그먼트 길이보다 짧습니다. 증강 건너뜁니다.\") # 너무 자세하면 생략\n",
        "                           pass # 노이즈 파일 길이가 짧으면 증강 건너뛰기\n",
        "                 else:\n",
        "                      # print(f\"경고: 노이즈 파일 '{os.path.basename(random_noise_file)}' 로드 실패. 증강 건너뜁니다.\") # 너무 자세하면 생략\n",
        "                      pass # 노이즈 로드 실패 시 증강 건너뛰기\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"오류: 노이즈 증강 중 예외 발생 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc(limit=2)\n",
        "                # 오류 발생 시 증강 없이 원본 세그먼트로 진행\n",
        "\n",
        "\n",
        "        # YAMNet 모델은 1초 길이의 오디오를 입력으로 받음. 5초 세그먼트에서 여러 프레임 추출 가능.\n",
        "        # YAMNet 모델은 (num_samples,) 형태의 텐서를 기대.\n",
        "        # 모델 추론을 위해 입력 형태 맞추기\n",
        "        input_tensor = tf.constant(segment_audio, dtype=tf.float32)\n",
        "\n",
        "        # YAMNet 모델 실행\n",
        "        # model(input_tensor)는 (scores, embeddings, spectrogram) 튜플을 반환\n",
        "        scores, embeddings, spectrogram = model(input_tensor)\n",
        "\n",
        "        # YAMNet은 여러 프레임에 대한 임베딩을 반환하므로 평균 또는 최대 풀링하여 단일 벡터로 만듦\n",
        "        # 여기서는 간단하게 시간 축(axis=0)에 대해 평균 풀링하여 단일 임베딩 벡터 생성\n",
        "        if tf.shape(embeddings)[0] > 0:\n",
        "             mean_embedding = tf.reduce_mean(embeddings, axis=0)\n",
        "             return mean_embedding.numpy() # NumPy 배열로 변환하여 반환\n",
        "        else:\n",
        "             # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점에서 유효한 YAMNet 임베딩 추출 실패 (프레임 없음).\") # 너무 자세하면 생략\n",
        "             return None # 유효한 임베딩이 없으면 None 반환\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: YAMNet 임베딩 추출 중 예외 발생 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc(limit=2)\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- 2. PANNs 임베딩 추출 함수 (세그먼트 처리 가능하도록 수정) ---\n",
        "# PANNs 모델 로드는 복잡하므로, 로드 함수가 Step 5에 정의되어 있다고 가정합니다.\n",
        "# 여기서는 모델 객체를 인자로 받습니다.\n",
        "\n",
        "# PANNs 임베딩 차원 정의 (모델 출력 차원에 맞춰야 함)\n",
        "PANNS_EMBEDDING_DIM = 2048 # PANNs 모델의 임베딩 차원 (예시)\n",
        "\n",
        "# PANNs 임베딩 추출 함수 수정: 파일 경로와 세그먼트 시작 시간을 인자로 받음\n",
        "def extract_panns_embedding(audio_info: tuple, model, augment_with_noise: bool = False, noise_audio_paths: list = None, noise_level: float = 0.1, segment_duration_sec: int = 5, target_sample_rate: int = 16000):\n",
        "    \"\"\"\n",
        "    오디오 세그먼트 정보(원본 파일 경로, 시작 시간)를 받아 PANNs 임베딩을 추출합니다.\n",
        "    필요 시 노이즈 증강을 적용합니다.\n",
        "\n",
        "    Args:\n",
        "        audio_info (tuple): (원본 파일 경로, 세그먼트 시작 시간(초)) 튜플.\n",
        "        model: 로드된 PANNs 모델 객체.\n",
        "        augment_with_noise (bool): 노이즈 증강 적용 여부.\n",
        "        noise_audio_paths (list): 노이즈 오디오 파일 경로 목록 (증강 시 사용).\n",
        "        noise_level (float): 노이즈 레벨 (0.0 ~ 1.0).\n",
        "        segment_duration_sec (int): 세그먼트 길이 (초). PANNs 입력 길이에 맞추거나 조정 필요.\n",
        "        target_sample_rate (int): 임베딩 모델이 기대하는 샘플링 속도.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 추출된 임베딩 벡터. 임베딩 추출 실패 시 None 반환.\n",
        "    \"\"\"\n",
        "    if model is None:\n",
        "        # print(\"경고: PANNs 모델이 로드되지 않았습니다. 임베딩 추출을 건너뜁니다.\") # 너무 자세하면 생략\n",
        "        return None\n",
        "\n",
        "    file_path, start_time_sec = audio_info # 세그먼트 정보 언팩\n",
        "\n",
        "    try:\n",
        "        # 원본 오디오 파일 로드 및 리샘플링 (load_and_resample_audio 함수 사용)\n",
        "        audio, sr = load_and_resample_audio(file_path, target_sample_rate)\n",
        "\n",
        "        if audio is None or sr is None:\n",
        "            # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 로드/리샘플링 실패.\") # 너무 자세하면 생략\n",
        "            return None\n",
        "\n",
        "        # 세그먼트 시작 및 종료 샘플 인덱스 계산\n",
        "        start_sample = int(start_time_sec * sr)\n",
        "        end_sample = start_sample + int(segment_duration_sec * sr) # 세그먼트 길이\n",
        "\n",
        "        # 세그먼트 오디오 데이터 추출\n",
        "        segment_audio = audio[start_sample:min(end_sample, len(audio))]\n",
        "\n",
        "        # PANNs 모델은 보통 고정된 길이의 입력을 기대합니다 (예: 10초).\n",
        "        # 현재 세그먼트 길이(5초)는 PANNs 모델이 기대하는 길이와 다를 수 있습니다.\n",
        "        # PANNs 모델의 입력 길이에 맞춰 패딩 또는 잘라내기 로직이 필요할 수 있습니다.\n",
        "        # 여기서는 간단하게 5초 세그먼트를 사용하되, PANNs 모델의 입력 요구사항에 따라 수정이 필요합니다.\n",
        "        # PANNs 입력 길이에 대한 정보가 필요합니다. (예: 10초 = 160000 샘플)\n",
        "        panns_input_length_samples = int(10 * sr) # PANNs 예시 입력 길이 (10초)\n",
        "\n",
        "        if len(segment_audio) < panns_input_length_samples:\n",
        "             # PANNs 입력 길이보다 짧으면 패딩\n",
        "             # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 길이가 PANNs 입력 길이보다 짧습니다 ({len(segment_audio)} 샘플). 패딩합니다.\")\n",
        "             padded_segment = np.pad(segment_audio, (0, max(0, panns_input_length_samples - len(segment_audio))), mode='constant')\n",
        "             segment_audio = padded_segment\n",
        "        elif len(segment_audio) > panns_input_length_samples:\n",
        "             # PANNs 입력 길이보다 길면 잘라내기 (앞부분 사용)\n",
        "             # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 길이가 깁니다 ({len(segment_audio)} 샘플). PANNs 입력 길이에 맞춰 잘라냅니다.\")\n",
        "             segment_audio = segment_audio[:panns_input_length_samples]\n",
        "\n",
        "\n",
        "        # 노이즈 증강 적용 (훈련 데이터에만 적용) - YAMNet과 동일한 로직 사용 가능\n",
        "        if augment_with_noise and noise_audio_paths and len(noise_audio_paths) > 0:\n",
        "             try:\n",
        "                  random_noise_file = random.choice(noise_audio_paths)\n",
        "                  noise_audio, noise_sr = load_and_resample_audio(random_noise_file, target_sample_rate)\n",
        "\n",
        "                  if noise_audio is not None and noise_sr is not None:\n",
        "                       noise_segment_length = len(segment_audio) # 증강할 세그먼트 길이와 동일하게 노이즈 자름\n",
        "                       if len(noise_audio) >= noise_segment_length:\n",
        "                            noise_start_sample = random.randint(0, len(noise_audio) - noise_segment_length)\n",
        "                            noise_segment = noise_audio[noise_start_sample:noise_start_sample + noise_segment_length]\n",
        "\n",
        "                            alpha = 1.0\n",
        "                            beta = noise_level\n",
        "                            mixed_segment = segment_audio + beta * noise_segment * (np.max(segment_audio) / (np.max(noise_segment) + 1e-8))\n",
        "                            mixed_segment = np.clip(mixed_segment, -1.0, 1.0)\n",
        "                            segment_audio = mixed_segment\n",
        "                       else:\n",
        "                            pass # 노이즈 파일 길이 짧으면 증강 건너뛰기\n",
        "                  else:\n",
        "                       pass # 노이즈 로드 실패 시 증강 건너뛰기\n",
        "\n",
        "             except Exception as e:\n",
        "                 print(f\"오류: PANNs 노이즈 증강 중 예외 발생 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "                 import traceback\n",
        "                 traceback.print_exc(limit=2)\n",
        "                 # 오류 발생 시 증강 없이 원본 세그먼트로 진행\n",
        "\n",
        "\n",
        "        # PANNs 모델은 (batch_size, num_samples) 형태의 입력을 기대\n",
        "        # 단일 세그먼트이므로 배치 차원 추가 ((num_samples,) -> (1, num_samples))\n",
        "        input_tensor = tf.constant(segment_audio[np.newaxis, :], dtype=tf.float32) # 배치 차원 추가\n",
        "\n",
        "        # PANNs 모델 실행 및 임베딩 추출\n",
        "        # PANNs 모델의 출력 형태에 따라 임베딩 추출 로직 수정 필요\n",
        "        # 예: model(input_tensor)['embedding'] 또는 model(input_tensor)[0] 등\n",
        "        # PANNs 모델 객체의 정확한 사용법 확인 필요\n",
        "        # 여기서는 예시로 'embedding' 키를 사용한다고 가정\n",
        "        try:\n",
        "            # PANNs 모델 추론 (모델 구조에 따라 호출 방식 다를 수 있음)\n",
        "            # 예시: model(input_tensor)가 딕셔너리를 반환하고 'embedding' 키가 있다고 가정\n",
        "            model_output = model(input_tensor)\n",
        "            if isinstance(model_output, dict) and 'embedding' in model_output:\n",
        "                 embedding = model_output['embedding']\n",
        "                 # 결과는 (1, embedding_dim) 형태일 것이므로 배치 차원 제거\n",
        "                 return embedding.numpy().squeeze(axis=0) # (embedding_dim,) 형태로 반환\n",
        "            elif isinstance(model_output, (list, tuple)):\n",
        "                 # 예시: model(input_tensor)가 (output, embedding) 튜플을 반환한다고 가정\n",
        "                 if len(model_output) > 1:\n",
        "                      embedding = model_output[1] # 두 번째 요소가 임베딩이라고 가정\n",
        "                      return embedding.numpy().squeeze(axis=0)\n",
        "                 else:\n",
        "                      print(f\"경고: PANNs 모델 출력 형태 예상과 다름 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초.\")\n",
        "                      return None\n",
        "            else:\n",
        "                print(f\"경고: PANNs 모델 출력 형태 예상과 다름 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초.\")\n",
        "                return None\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"오류: PANNs 모델 추론 중 예외 발생 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc(limit=2)\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: PANNs 임베딩 추출 중 예외 발생 (로드/전처리 단계) for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc(limit=2)\n",
        "        return None\n",
        "\n",
        "\n",
        "# --- 3. VGGish 임베딩 추출 함수 (세그먼트 처리 가능하도록 수정) ---\n",
        "# VGGish 모델 로드 (TensorFlow Hub 사용)\n",
        "# 모델 로드는 한 번만 수행하도록 함수 외부에 정의\n",
        "# try:\n",
        "#     # VGGish 모델 및 관련 프리프로세싱 모델 로드\n",
        "#     vggish_model = hub.load('https://tfhub.dev/google/vggish/1')\n",
        "#     vggish_preprocess_model = hub.load('https://tfhub.dev/google/vggish-input/1')\n",
        "#     print(\"VGGish 모델 및 프리프로세싱 모델 로드 완료.\")\n",
        "# except Exception as e:\n",
        "#     vggish_model = None\n",
        "#     vggish_preprocess_model = None\n",
        "#     print(f\"VGGish 모델 로드 실패: {e}\")\n",
        "#     print(\"VGGish 임베딩 추출 기능을 사용할 수 없습니다.\")\n",
        "\n",
        "# VGGish 임베딩 차원 정의\n",
        "# VGGISH_EMBEDDING_DIM = 128 # VGGish 모델의 임베딩 차원\n",
        "\n",
        "# VGGish 임베딩 추출 함수 수정: 파일 경로와 세그먼트 시작 시간을 인자로 받음\n",
        "# def extract_vggish_embedding(audio_info: tuple, model, augment_with_noise: bool = False, noise_audio_paths: list = None, noise_level: float = 0.1, segment_duration_sec: int = 5, target_sample_rate: int = 16000):\n",
        "#     \"\"\"\n",
        "#     오디오 세그먼트 정보(원본 파일 경로, 시작 시간)를 받아 VGGish 임베딩을 추출합니다.\n",
        "#     필요 시 노이즈 증강을 적용합니다.\n",
        "\n",
        "#     Args:\n",
        "#         audio_info (tuple): (원본 파일 경로, 세그먼트 시작 시간(초)) 튜플.\n",
        "#         model: 로드된 VGGish 모델 객체.\n",
        "#         augment_with_noise (bool): 노이즈 증강 적용 여부.\n",
        "#         noise_audio_paths (list): 노이즈 오디오 파일 경로 목록 (증강 시 사용).\n",
        "#         noise_level (float): 노이즈 레벨 (0.0 ~ 1.0).\n",
        "#         segment_duration_sec (int): 세그먼트 길이 (초). VGGish 입력 길이에 맞춰야 함.\n",
        "#         target_sample_rate (int): 임베딩 모델이 기대하는 샘플링 속도.\n",
        "\n",
        "#     Returns:\n",
        "#         np.ndarray: 추출된 임베딩 벡터. 임베딩 추출 실패 시 None 반환.\n",
        "#     \"\"\"\n",
        "#     if model is None or vggish_preprocess_model is None:\n",
        "#         # print(\"경고: VGGish 모델 또는 프리프로세싱 모델이 로드되지 않았습니다. 임베딩 추출을 건너뜁니다.\") # 너무 자세하면 생략\n",
        "#         return None\n",
        "\n",
        "#     file_path, start_time_sec = audio_info # 세그먼트 정보 언팩\n",
        "\n",
        "#     try:\n",
        "#         # 원본 오디오 파일 로드 및 리샘플링 (load_and_resample_audio 함수 사용)\n",
        "#         audio, sr = load_and_resample_audio(file_path, target_sample_rate)\n",
        "\n",
        "#         if audio is None or sr is None:\n",
        "#             # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 로드/리샘플링 실패.\") # 너무 자세하면 생략\n",
        "#             return None\n",
        "\n",
        "#         # 세그먼트 시작 및 종료 샘플 인덱스 계산\n",
        "#         start_sample = int(start_time_sec * sr)\n",
        "#         end_sample = start_sample + int(segment_duration_sec * sr) # 세그먼트 길이\n",
        "\n",
        "#         # 세그먼트 오디오 데이터 추출\n",
        "#         segment_audio = audio[start_sample:min(end_sample, len(audio))]\n",
        "\n",
        "#         # VGGish 모델은 16kHz에서 0.96초 길이의 입력(15360 샘플)을 기대합니다.\n",
        "#         # 현재 세그먼트 길이(5초)는 VGGish 입력 길이보다 깁니다.\n",
        "#         # VGGish 프리프로세싱 모델은 긴 오디오를 받아서 0.96초 프레임으로 자동 분할하고 처리합니다.\n",
        "#         # 따라서 5초 세그먼트를 그대로 프리프로세싱 모델에 전달합니다.\n",
        "\n",
        "#         # 노이즈 증강 적용 (훈련 데이터에만 적용) - YAMNet과 동일한 로직 사용 가능\n",
        "#         if augment_with_noise and noise_audio_paths and len(noise_audio_paths) > 0:\n",
        "#              try:\n",
        "#                   random_noise_file = random.choice(noise_audio_paths)\n",
        "#                   noise_audio, noise_sr = load_and_resample_audio(random_noise_file, target_sample_rate)\n",
        "\n",
        "#                   if noise_audio is not None and noise_sr is not None:\n",
        "#                        noise_segment_length = len(segment_audio) # 증강할 세그먼트 길이와 동일하게 노이즈 자름\n",
        "#                        if len(noise_audio) >= noise_segment_length:\n",
        "#                             noise_start_sample = random.randint(0, len(noise_audio) - noise_segment_length)\n",
        "#                             noise_segment = noise_audio[noise_start_sample:noise_start_sample + noise_segment_length]\n",
        "\n",
        "#                             alpha = 1.0\n",
        "#                             beta = noise_level\n",
        "#                             mixed_segment = segment_audio + beta * noise_segment * (np.max(segment_audio) / (np.max(noise_segment) + 1e-8))\n",
        "#                             mixed_segment = np.clip(mixed_segment, -1.0, 1.0)\n",
        "#                             segment_audio = mixed_segment\n",
        "#                        else:\n",
        "#                             pass # 노이즈 파일 길이 짧으면 증강 건너뛰기\n",
        "#                   else:\n",
        "#                        pass # 노이즈 로드 실패 시 증강 건너뛰기\n",
        "\n",
        "#              except Exception as e:\n",
        "#                  print(f\"오류: VGGish 노이즈 증강 중 예외 발생 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "#                  import traceback\n",
        "#                  traceback.print_exc(limit=2)\n",
        "#                  # 오류 발생 시 증강 없이 원본 세그먼트로 진행\n",
        "\n",
        "#         # VGGish 프리프로세싱 모델 실행\n",
        "#         # 입력은 (num_samples,) 형태의 텐서\n",
        "#         input_tensor = tf.constant(segment_audio, dtype=tf.float32)\n",
        "#         # VGGish 프리프로세싱 모델은 (num_frames, num_bands) 형태의 텐서를 반환\n",
        "#         preprocess_output = vggish_preprocess_model(input_tensor)\n",
        "\n",
        "#         # VGGish 모델 실행\n",
        "#         # 입력은 (num_frames, num_bands) 형태의 텐서\n",
        "#         # VGGish 모델은 (num_frames, embedding_dim) 형태의 임베딩을 반환\n",
        "#         embeddings = model(preprocess_output)\n",
        "\n",
        "#         # VGGish도 여러 프레임에 대한 임베딩을 반환하므로 평균 풀링하여 단일 벡터로 만듦\n",
        "#         if tf.shape(embeddings)[0] > 0:\n",
        "#              mean_embedding = tf.reduce_mean(embeddings, axis=0)\n",
        "#              return mean_embedding.numpy() # NumPy 배열로 변환하여 반환\n",
        "#         else:\n",
        "#              # print(f\"경고: '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점에서 유효한 VGGish 임베딩 추출 실패 (프레임 없음).\") # 너무 자세하면 생략\n",
        "#              return None # 유효한 임베딩이 없으면 None 반환\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"오류: VGGish 임베딩 추출 중 예외 발생 for '{os.path.basename(file_path)}' 세그먼트 시작 {start_time_sec:.2f}초: {e}\")\n",
        "#         import traceback\n",
        "#         traceback.print_exc(limit=2)\n",
        "#         return None\n",
        "\n",
        "\n",
        "print(\"\\n오디오 임베딩 추출 함수 정의 완료 (VGGish 관련 코드 삭제).\")\n",
        "\n",
        "# 이 셀 실행 후, Step 5 모델 로드 셀, 그리고 Step 6/10 파이프라인 실행 셀을 순서대로 실행해야 합니다.\n",
        "# 특히 Step 3 셀(load_and_prepare_dataset 정의)이 먼저 실행되어 load_and_resample_audio 함수가 정의되어 있어야 합니다."
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 127)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m127\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82bd8653"
      },
      "source": [
        "## 5. 오디오 모델 로드 함수 정의\n",
        "\n",
        "전이 학습에 사용할 YAMNet, PANNs, VGGish 사전 학습 모델을 TensorFlow Hub에서 로드하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "646d6907"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf # Ensure tensorflow is imported for model loading\n",
        "\n",
        "print(\"\\n5. 오디오 모델 로드 함수 정의 중...\")\n",
        "\n",
        "# Define the TensorFlow Hub handles for the models.\n",
        "# Using the global constants defined in Step 1\n",
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "vggish_model_handle = 'https://tfhub.dev/google/vggish/1'\n",
        "# Using the YAMNet handle as a placeholder for PANNs as per previous discussion.\n",
        "panns_model_handle = 'https://tfhub.dev/google/yamnet/1' # Using YAMNet as placeholder for PANNs\n",
        "\n",
        "def load_audio_models():\n",
        "    \"\"\"\n",
        "    TensorFlow Hub에서 YAMNet, PANNs, VGGish 모델을 로드합니다.\n",
        "\n",
        "    Returns:\n",
        "        dict: 로드된 모델 객체를 담고 있는 딕셔너리.\n",
        "              모델 로드 실패 시 해당 모델 이름에 대해 값은 None이 됩니다.\n",
        "    \"\"\"\n",
        "    models = {}\n",
        "    are_models_loaded_successfully = True\n",
        "\n",
        "    print(\"\\n오디오 모델 로드 중...\")\n",
        "\n",
        "    # Load YAMNet\n",
        "    try:\n",
        "        print(\"  YAMNet 모델 로드 중...\")\n",
        "        models['YAMNet'] = hub.load(yamnet_model_handle)\n",
        "        print(\"  YAMNet 모델 로드 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: YAMNet 모델 로드 중 오류 발생: {e}\")\n",
        "        models['YAMNet'] = None # Set to None if loading fails\n",
        "        are_models_loaded_successfully = False\n",
        "\n",
        "    # Load PANNs (Placeholder)\n",
        "    try:\n",
        "        print(\"  PANNs 모델 로드 중 (YAMNet 플레이스홀더 사용)...\")\n",
        "        models['PANNs'] = hub.load(panns_model_handle)\n",
        "        print(\"  PANNs 모델 로드 완료 (YAMNet 플레이스홀더).\")\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: PANNs 모델 로드 중 오류 발생: {e}\")\n",
        "        models['PANNs'] = None # Set to None if loading fails\n",
        "        are_models_loaded_successfully = False\n",
        "\n",
        "\n",
        "    # Load VGGish\n",
        "    try:\n",
        "        print(\"  VGGish 모델 로드 중...\")\n",
        "        models['VGGish'] = hub.load(vggish_model_handle)\n",
        "        print(\"  VGGish 모델 로드 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: VGGish 모델 로드 중 오류 발생: {e}\")\n",
        "        models['VGGish'] = None # Set to None if loading fails\n",
        "        are_models_loaded_successfully = False\n",
        "\n",
        "    # Check if at least one model loaded successfully\n",
        "    if all(model is None for model in models.values()):\n",
        "        print(\"오류: 모든 오디오 모델 로드에 실패했습니다.\")\n",
        "        are_models_loaded_successfully = False # Ensure this is False if all failed\n",
        "    else:\n",
        "         print(\"모델 로드 상태:\")\n",
        "         for name, model in models.items():\n",
        "             status = \"Loaded\" if model else \"Failed\"\n",
        "             print(f\"  {name}: {status}\")\n",
        "\n",
        "\n",
        "    print(\"\\n오디오 모델 로드 함수 정의 완료.\")\n",
        "\n",
        "    # Return the dictionary of models. The caller must check for None values.\n",
        "    return models, are_models_loaded_successfully\n",
        "\n",
        "# Example usage (will be called in a later cell):\n",
        "# loaded_models, are_models_loaded = load_audio_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98da7922"
      },
      "source": [
        "## 6. 데이터 로드, 임베딩 추출 및 데이터 준비 실행\n",
        "\n",
        "정의된 함수들을 사용하여 데이터셋을 로드하고, 각 모델별로 임베딩을 추출하며, 훈련 및 테스트를 위한 최종 데이터셋(임베딩 및 레이블)을 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62888c74"
      },
      "source": [
        "# Here is the current query...ㅇㅋ\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os # 파일 시스템 경로 작업을 위한 라이브러리\n",
        "import matplotlib.pyplot as plt # 데이터 시각화를 위한 라이브러리\n",
        "import seaborn as sns # 데이터 시각화를 위한 라이브러리 (matplotlib 기반)\n",
        "from sklearn.metrics import classification_report, confusion_matrix # 모델 평가 지표를 위한 라이브러리\n",
        "import random # 데이터 증강에 사용될 수 있는 랜덤 모듈 (현재 코드에서는 직접 사용되지는 않음)\n",
        "import tempfile # 임시 파일/디렉토리 생성을 위한 라이브러리\n",
        "import shutil # 파일/디렉토리 복사, 삭제 등을 위한 라이브러리\n",
        "import sys # 파이썬 런타임 정보 및 제어 (예: traceback 출력)\n",
        "import gc # 가비지 컬렉터 인터페이스 (메모리 해제에 도움)\n",
        "import soundfile as sf # 오디오 파일 로드/저장을 위한 라이브러리\n",
        "import librosa # 오디오 분석 라이브러리 (리샘플링 등)\n",
        "\n",
        "# 콜백 함수를 사용하기 위해 임포트 (모델 학습 단계에서 사용)\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "print(\"\\n10. 모델별 전체 파이프라인 실행 및 결과 비교 시작...\")\n",
        "\n",
        "# --- 중요: 필수 선행 작업 안내 ---\n",
        "# 이 셀을 실행하기 전에 반드시 완료해야 하는 작업들을 안내합니다.\n",
        "# 특히 Step 4 셀 실행과 충분한 데이터 확보가 중요합니다.\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\">>>         >>>  필수 작업 안내  <<<         <<<\")\n",
        "print(\">>>                                           <<<\")\n",
        "print(\">>>   오디오 전처리 및 임베딩 추출 함수가 정의된 Step 4 셀을 먼저 실행했는지 확인하세요! <<<\")\n",
        "print(\">>>   (예: 셀 ID 617c87ca) 그렇지 않으면 'Quality must be one of...' 오류가 발생합니다. <<<\")\n",
        "print(\">>>                                           <<<\")\n",
        "print(\">>>   DeepShip('/content/DeepShip') 및 노이즈('/content/MBARI_noise_data') 디렉토리에 <<<\")\n",
        "print(\">>>   훈련/테스트에 필요한 오디오 파일이 충분히 있는지 확인하세요!                     <<<\")\n",
        "print(\">>>   (각 클래스 최소 2개 파일 필요) 데이터 부족 시 '데이터 부족' 오류가 발생합니다. <<<\")\n",
        "print(\">>>                                           <<<\")\n",
        "print(\">>>         >>>  필수 작업 완료 후 이 셀을 실행하세요.  <<<         <<<\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- 1. 데이터 로드 및 준비 ---\n",
        "# Step 3에서 정의된 load_and_prepare_dataset 함수를 호출합니다.\n",
        "# 이 함수가 정의되어 있는지 먼저 확인합니다.\n",
        "# load_and_prepare_dataset 함수는 이제 세그먼트 정보(원본 파일 경로, 시작 시간)를 반환합니다.\n",
        "if 'load_and_prepare_dataset' not in locals():\n",
        "    print(\"오류: 'load_and_prepare_dataset' 함수가 정의되지 않았습니다. 파이프라인 실행을 중단합니다.\")\n",
        "    is_data_prepared = False # 데이터 준비 상태 플래그\n",
        "    # 필요한 변수들을 빈 값으로 초기화합니다.\n",
        "    # X_train_segment_info, X_test_segment_info는 이제 세그먼트 정보 리스트입니다.\n",
        "    X_train_segment_info, X_test_segment_info, y_train_encoded, y_test_encoded, label_encoder, num_classes, noise_audio_paths = [], [], np.array([]), np.array([]), None, 0, [] # Initialize noise_audio_paths\n",
        "else:\n",
        "    # 함수가 정의되어 있으면 호출하여 데이터를 로드하고 나눕니다.\n",
        "    # load_and_prepare_dataset 함수는 이제 세그먼트 정보 목록을 반환합니다.\n",
        "    # (X_train_segment_info, X_test_segment_info, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths)\n",
        "    X_train_segment_info, X_test_segment_info, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths = load_and_prepare_dataset(\n",
        "        deepship_path=DEEPSHIP_BASE_PATH, # DeepShip 데이터 경로 (전역 변수 사용)\n",
        "        noise_data_dir=MBARI_NOISE_BASE_DIR, # 노이즈 데이터 경로 (전역 변수 사용)\n",
        "        deepship_classes=DEEPSHIP_CLASSES # 분류할 클래스 목록 (전역 변수 사용)\n",
        "    )\n",
        "\n",
        "# --- 2. 오디오 모델 로드 ---\n",
        "# Step 5에서 정의된 load_audio_models 함수를 호출합니다.\n",
        "# 이 함수가 정의되어 있는지 먼저 확인합니다. VGGish는 이 함수에서 제외되었습니다.\n",
        "if 'load_audio_models' not in locals():\n",
        "     print(\"오류: 'load_audio_models' 함수가 정의되지 않았습니다. 파이프라인 실행을 건너뜁니다.\")\n",
        "     are_models_loaded = False # 모델 로드 상태 플래그\n",
        "     loaded_models = {} # 로드된 모델 저장 딕셔너리\n",
        "else:\n",
        "    # 함수가 정의되어 있으면 호출하여 오디오 임베딩 모델들(YAMNet, PANNs)을 로드합니다.\n",
        "    loaded_models, are_models_loaded = load_audio_models()\n",
        "\n",
        "\n",
        "# --- 3. Model-wise Embedding Extraction and Data Preparation (Batch Processing & Saving) ---\n",
        "# 이 단계에서 각 오디오 세그먼트의 임베딩을 추출하고, 배치 단위로 처리하여 임시 파일에 저장합니다.\n",
        "# 세그멘테이션 로직 적용으로 인해 이 부분의 루프 처리가 세그먼트 정보 목록을 사용하도록 변경됩니다.\n",
        "\n",
        "temp_embedding_dir = None # 임시 임베딩 저장 디렉토리 경로\n",
        "are_embeddings_extracted_successfully_any_model = False # 하나 이상의 모델에서 임베딩 추출 및 데이터 준비 성공 여부 플래그\n",
        "embedding_dims = {} # 각 모델의 임베딩 차원을 저장할 딕셔너리\n",
        "\n",
        "# 필요한 임베딩 추출 함수들(extract_yamnet_embedding, extract_panns_embedding)이\n",
        "# Step 4 셀에서 정의되었는지 확인합니다. VGGish 함수는 제외되었습니다.\n",
        "are_extraction_functions_defined = (\n",
        "    'extract_yamnet_embedding' in locals() and\n",
        "    'extract_panns_embedding' in locals() # VGGish 함수는 확인 대상에서 제외\n",
        ")\n",
        "\n",
        "# 임베딩 추출 함수 중 하나라도 정의되지 않았으면 이 단계를 건너뜠다는 메시지를 출력합니다.\n",
        "if not are_extraction_functions_defined:\n",
        "    print(\"오류: 필요한 임베딩 추출 함수 중 하나 이상이 정의되지 않았습니다 (YAMNet, PANNs). 임베딩 추출 단계를 건너뜁니다.\")\n",
        "    # 이 if 블록의 대응되는 else 블록(실제 임베딩 추출 로직 포함)을 건너뛰기 위해 pass 사용\n",
        "    pass # 명시적인 pass 구문\n",
        "# --- 여기서부터 SyntaxError가 보고되는 else 블록 시작 (이전 문제 지점) ---\n",
        "# 임베딩 추출 함수들이 모두 정의되어 있을 때만 이 else 블록 내부 코드가 실행됩니다.\n",
        "else: # 임베딩 추출 함수들이 정의된 경우\n",
        "    # 임베딩 추출 및 데이터 준비의 메인 로직이 여기에 포함됩니다.\n",
        "\n",
        "    # 데이터 로드 및 모델 로드가 성공적으로 완료되었는지 추가로 확인합니다.\n",
        "    if is_data_prepared and are_models_loaded:\n",
        "        print(\"\\n모델별 임베딩 추출 및 데이터 준비 시작 (배치 처리 및 파일 저장 - 시간이 오래 걸릴 수 있습니다)...\")\n",
        "\n",
        "        # 임베딩을 저장할 임시 디렉토리를 생성합니다.\n",
        "        temp_embedding_dir = tempfile.mkdtemp()\n",
        "        print(f\"임시 임베딩 저장 디렉토리: {temp_embedding_dir}\")\n",
        "\n",
        "        # 각 모델별 정보 (로드된 모델 객체, 임베딩 차원, 추출 함수)를 저장할 딕셔너리\n",
        "        # VGGish 관련 정보는 여기서 제외합니다.\n",
        "        models_info = {}\n",
        "        # YAMNet 모델 정보 추가\n",
        "        if loaded_models.get('YAMNet') is not None and 'YAMNET_EMBEDDING_DIM' in locals():\n",
        "             models_info['YAMNet'] = {'model': loaded_models['YAMNet'], 'extract_func': extract_yamnet_embedding, 'dim': YAMNET_EMBEDDING_DIM}\n",
        "        else:\n",
        "             # YAMNet이 로드되지 않았거나 차원 정의 누락 시 경고\n",
        "             print(\"경고: YAMNet 모델 정보 또는 함수가 누락되었습니다. YAMNet 처리를 건너뜁니다.\")\n",
        "        # PANNs 모델 정보 추가 (PANNs_EMBEDDING_DIM이 정의되어 있다고 가정)\n",
        "        if loaded_models.get('PANNs') is not None and 'PANNS_EMBEDDING_DIM' in locals():\n",
        "             models_info['PANNs'] = {'model': loaded_models['PANNs'], 'extract_func': extract_panns_embedding, 'dim': PANNS_EMBEDDING_DIM}\n",
        "        else:\n",
        "              # PANNs가 로드되지 않았거나 차원 정의 누락 시 경고\n",
        "              print(\"경고: PANNs 모델 정보 또는 함수가 누락되었습니다. PANNs 처리를 건너뜁니다.\")\n",
        "        # VGGish 관련 코드는 삭제되었습니다.\n",
        "\n",
        "\n",
        "        # 임베딩 추출을 위한 배치 크기를 정의합니다. 메모리 사용 최소화를 위해 1로 설정되었습니다.\n",
        "        EMBEDDING_EXTRACTION_BATCH_SIZE = 1\n",
        "\n",
        "        # 각 모델별로 저장된 배치 파일 목록과 필터링된 레이블을 저장할 딕셔너리\n",
        "        # 이 딕셔너리들은 모델 학습/평가 단계에서 사용됩니다.\n",
        "        X_train_embeddings = {} # 훈련 임베딩 배치 파일 경로 목록 (모델별)\n",
        "        X_test_embeddings = {} # 테스트 임베딩 배치 파일 경로 목록 (모델별)\n",
        "        y_train_filtered = {} # 훈련 필터링 레이블 (np.array, 모델별)\n",
        "        y_test_filtered = {}  # 테스트 필터링 레이블 (np.array, 모델별)\n",
        "        y_test_encoded_filtered = {} # 테스트 필터링 레이블 (평가 보고서용, 모델별)\n",
        "\n",
        "\n",
        "        # 처리할 모델 정보가 하나라도 있는지 확인\n",
        "        if models_info:\n",
        "            all_models_extracted_at_least_one_sample = False # 하나 이상의 모델이 훈련/테스트 가능한 데이터를 추출했는지 추적하는 플래그\n",
        "\n",
        "            # models_info에 있는 각 모델에 대해 임베딩 추출 및 데이터 준비 수행\n",
        "            for model_name, info in models_info.items():\n",
        "                model = info['model'] # 현재 모델 객체\n",
        "                extract_func = info['extract_func'] # 현재 모델의 임베딩 추출 함수\n",
        "                # 임베딩 차원 정보가 models_info에 있는지 확인 후 추가 (안전 장치)\n",
        "                if 'dim' in info:\n",
        "                    embedding_dims[model_name] = info['dim'] # 현재 모델의 임베딩 차원 저장\n",
        "                else:\n",
        "                    print(f\"경고: {model_name}의 임베딩 차원 정보가 models_info에 없습니다. 임베딩 차원 딕셔너리에 추가하지 않습니다.\")\n",
        "                    # 임베딩 차원 없이는 모델 구축이 불가능하므로, 이 모델은 이후 단계에서 건너뛸 수 있습니다.\n",
        "\n",
        "\n",
        "                print(f\"\\n--- {model_name} 임베딩 추출 중 (배치 크기: {EMBEDDING_EXTRACTION_BATCH_SIZE}) ---\")\n",
        "                train_batch_files = [] # 현재 모델의 훈련 임베딩 배치 파일 경로 목록\n",
        "                test_batch_files = []  # 현재 모델의 테스트 임베딩 배치 파일 경로 목록\n",
        "\n",
        "                # 훈련 데이터 세그먼트 정보 목록을 배치 처리\n",
        "                print(\"  훈련 데이터 세그먼트 처리 중...\")\n",
        "                train_embeddings_batch = [] # 현재 훈련 배치에 포함될 임베딩 목록\n",
        "                train_labels_batch = []     # 현재 훈련 배치에 포함될 레이블 목록\n",
        "\n",
        "                # Step 1에서 반환된 훈련 세그먼트 정보 목록(X_train_segment_info) 사용\n",
        "                # X_train_segment_info는 [(원본 파일 경로, 시작 시간), ...] 형태의 리스트\n",
        "                # y_train_encoded는 세그먼트 수와 일치하는 인코딩된 레이블 배열\n",
        "                for i, segment_info_tuple in enumerate(X_train_segment_info):\n",
        "                    # 세그먼트 정보 튜플에서 원본 파일 경로와 시작 시간 언팩\n",
        "                    original_file_path, start_time_sec = segment_info_tuple\n",
        "                    # 해당 세그먼트의 레이블은 y_train_encoded 배열에서 인덱스로 가져옴\n",
        "                    original_label_encoded = y_train_encoded[i]\n",
        "                    # 레이블 인코더가 유효한 경우 레이블 문자열 가져오기\n",
        "                    original_label_str = label_encoder.inverse_transform([original_label_encoded])[0] if label_encoder is not None and hasattr(label_encoder, 'inverse_transform') else str(original_label_encoded)\n",
        "\n",
        "                    # 현재 처리 중인 세그먼트 정보 출력\n",
        "                    # print(f\"    처리 세그먼트 {i+1}/{len(X_train_segment_info)}: 파일 '{os.path.basename(original_file_path)}' 시작 {start_time_sec:.2f}초\")\n",
        "                    embedding = None # 임베딩 초기화 (오류 확인용)\n",
        "\n",
        "                    # --- 임베딩 추출 시도 ---\n",
        "                    try:\n",
        "                         # extract_func 함수 호출하여 임베딩 추출\n",
        "                         # extract_func는 세그먼트 정보 튜플을 인자로 받도록 수정되었습니다.\n",
        "                         # 노이즈 증강은 'ship' 클래스 세그먼트에만 적용\n",
        "                         augment = (original_label_str == 'ship') # 'ship' 클래스일 때만 증강 플래그 True\n",
        "                         embedding = extract_func(\n",
        "                              segment_info_tuple, # 세그먼트 정보 튜플 전달\n",
        "                              model, # 현재 모델 객체\n",
        "                              augment_with_noise=augment, # 증강 적용 여부\n",
        "                              noise_audio_paths=noise_audio_paths, # 노이즈 파일 경로 목록\n",
        "                              noise_level=0.1 # 노이즈 레벨\n",
        "                              # segment_duration_sec, target_sample_rate 인자는 extract_func 내부에서 상수로 사용될 수 있음\n",
        "                         )\n",
        "\n",
        "                         # 임베딩 추출 성공 시 배치 목록에 추가\n",
        "                         if embedding is not None:\n",
        "                              train_embeddings_batch.append(embedding)\n",
        "                              train_labels_batch.append(original_label_encoded)\n",
        "                         else:\n",
        "                              # 임베딩 추출 실패 시 경고 메시지 출력\n",
        "                              print(f\"      경고: 파일 '{os.path.basename(original_file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 임베딩 추출 실패 (결과 None).\")\n",
        "\n",
        "                    # 임베딩 추출 중 예외 발생 시 오류 메시지 출력 및 다음 세그먼트로 이동\n",
        "                    except Exception as e:\n",
        "                         print(f\"    오류: 파일 '{os.path.basename(original_file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 임베딩 추출 중 예외 발생: {e}\")\n",
        "                         import traceback\n",
        "                         traceback.print_exc(limit=2)\n",
        "                         # 오류가 발생해도 루프를 중단하지 않고 다음 세그먼트로 계속 진행\n",
        "\n",
        "\n",
        "                    # 배치 사이즈에 도달했거나 마지막 세그먼트인 경우 현재 배치 저장\n",
        "                    if (len(train_embeddings_batch) >= EMBEDDING_EXTRACTION_BATCH_SIZE) or (i == len(X_train_segment_info) - 1 and train_embeddings_batch):\n",
        "                        print(f\"    저장 중: 訓練 배치 {len(train_batch_files) + 1}, 현재 배치 세그먼트 수: {len(train_embeddings_batch)}\")\n",
        "                        try:\n",
        "                             # 배치 목록을 numpy 배열로 변환\n",
        "                             batch_embeddings_array = np.array(train_embeddings_batch)\n",
        "                             batch_labels_array = np.array(train_labels_batch)\n",
        "\n",
        "                             # 배치 데이터를 임시 파일에 .npz 형식으로 저장\n",
        "                             batch_file_path = os.path.join(temp_embedding_dir, f'{model_name}_train_batch_{len(train_batch_files)}.npz')\n",
        "                             np.savez(batch_file_path, embeddings=batch_embeddings_array, labels=batch_labels_array)\n",
        "                             train_batch_files.append(batch_file_path) # 저장된 파일 경로 목록에 추가\n",
        "\n",
        "                             # 현재 배치 목록을 비우고 메모리 해제 시도\n",
        "                             train_embeddings_batch = []\n",
        "                             train_labels_batch = []\n",
        "                             print(f\"    訓練 배치 {len(train_batch_files)} 저장 완료. 메모리 해제.\")\n",
        "                             gc.collect() # 가비지 컬렉션 강제 실행\n",
        "\n",
        "\n",
        "                        # 배치 저장 중 오류 발생 시 처리\n",
        "                        except Exception as e:\n",
        "                            print(f\"    오류: 訓練 배치 저장 실패 - 배치 {len(train_batch_files) + 1}, 오류: {e}\")\n",
        "                            # 오류 발생 시에도 메모리 확보를 위해 배치 목록 비우기 시도\n",
        "                            train_embeddings_batch = []\n",
        "                            train_labels_batch = []\n",
        "\n",
        "\n",
        "                    # 일정 간격으로 처리 현황 출력\n",
        "                    if (i + 1) % 100 == 0: # 세그먼트 수가 많을 수 있으므로 간격 조정\n",
        "                         print(f\"    {i+1}/{len(X_train_segment_info)} 훈련 세그먼트 처리 완료 (증강 포함).\")\n",
        "\n",
        "\n",
        "            # 테스트 데이터 세그먼트 정보 목록을 배치 처리 (훈련 데이터와 동일한 로직)\n",
        "            print(\"  테스트 데이터 세그먼트 처리 중...\")\n",
        "            test_embeddings_batch = []\n",
        "            test_labels_batch = []\n",
        "            # Step 1에서 반환된 테스트 세그먼트 정보 목록(X_test_segment_info) 사용\n",
        "            for i, segment_info_tuple in enumerate(X_test_segment_info):\n",
        "                original_file_path, start_time_sec = segment_info_tuple\n",
        "                original_label_encoded = y_test_encoded[i]\n",
        "\n",
        "                # print(f\"    처리 세그먼트 {i+1}/{len(X_test_segment_info)}: 파일 '{os.path.basename(original_file_path)}' 시작 {start_time_sec:.2f}초\")\n",
        "                embedding = None # 임베딩 초기화\n",
        "\n",
        "                # 테스트 세그먼트는 증강하지 않음 (augment_with_noise=False)\n",
        "                try:\n",
        "                     embedding = extract_func(\n",
        "                          segment_info_tuple, # 세그먼트 정보 튜플 전달\n",
        "                          model,\n",
        "                          augment_with_noise=False, # 증강 적용 안함\n",
        "                          noise_audio_paths=noise_audio_paths,\n",
        "                          noise_level=0.1\n",
        "                     )\n",
        "\n",
        "                     # 임베딩 추출 성공 시 배치 목록에 추가\n",
        "                     if embedding is not None:\n",
        "                         test_embeddings_batch.append(embedding)\n",
        "                         test_labels_batch.append(original_label_encoded)\n",
        "                     else:\n",
        "                         # 임베딩 추출 실패 시 경고 메시지 출력\n",
        "                         print(f\"      경고: 파일 '{os.path.basename(original_file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 임베딩 추출 실패 (결과 None).\")\n",
        "\n",
        "                # 임베딩 추출 중 예외 발생 시 오류 메시지 출력 및 다음 세그먼트로 이동\n",
        "                except Exception as e:\n",
        "                     print(f\"    오류: 파일 '{os.path.basename(original_file_path)}' 세그먼트 시작 {start_time_sec:.2f}초 지점 임베딩 추출 중 예외 발생: {e}\")\n",
        "                     import traceback\n",
        "                     traceback.print_exc(limit=2)\n",
        "                     # 오류가 발생해도 루프를 중단하지 않고 다음 세그먼트로 계속 진행\n",
        "\n",
        "\n",
        "                # 배치 사이즈에 도달했거나 마지막 세그먼트인 경우 현재 배치 저장\n",
        "                if (len(test_embeddings_batch) >= EMBEDDING_EXTRACTION_BATCH_SIZE) or (i == len(X_test_segment_info) - 1 and test_embeddings_batch):\n",
        "                    print(f\"    저장 중: 테스트 배치 {len(test_batch_files) + 1}, 현재 배치 세그먼트 수: {len(test_embeddings_batch)}\")\n",
        "                    try:\n",
        "                         # 배치 목록을 numpy 배열로 변환\n",
        "                         batch_embeddings_array = np.array(test_embeddings_batch)\n",
        "                         batch_labels_array = np.array(test_labels_batch)\n",
        "\n",
        "                         # 배치 데이터를 임시 파일에 .npz 형식으로 저장\n",
        "                         batch_file_path = os.path.join(temp_embedding_dir, f'{model_name}_test_batch_{len(test_batch_files)}.npz')\n",
        "                         np.savez(batch_file_path, embeddings=batch_embeddings_array, labels=batch_labels_array)\n",
        "                         test_batch_files.append(batch_file_path) # 저장된 파일 경로 목록에 추가\n",
        "\n",
        "                         # 현재 배치 목록을 비우고 메모리 해제 시도\n",
        "                         test_embeddings_batch = []\n",
        "                         test_labels_batch = []\n",
        "                         print(f\"    테스트 배치 {len(test_batch_files)} 저장 완료. 메모리 해제.\")\n",
        "                         gc.collect() # 가비지 컬렉션 강제 실행\n",
        "\n",
        "                    # 배치 저장 중 오류 발생 시 처리\n",
        "                    except Exception as e:\n",
        "                         print(f\"    오류: 테스트 배치 저장 실패 - 배치 {len(test_batch_files) + 1}, 오류: {e}\")\n",
        "                         # 오류 발생 시에도 메모리 확보를 위해 배치 목록 비우기 시도\n",
        "                         test_embeddings_batch = []\n",
        "                         test_labels_batch = []\n",
        "\n",
        "\n",
        "                # 일정 간격으로 처리 현황 출력\n",
        "                if (i + 1) % 50 == 0: # 세그먼트 수가 많을 수 있으므로 간격 조정\n",
        "                    print(f\"    {i+1}/{len(X_test_segment_info)} 테스트 세그먼트 처리 완료.\")\n",
        "\n",
        "\n",
        "            # 현재 모델에 대해 저장된 훈련/테스트 배치 파일 경로 목록 저장\n",
        "            X_train_embeddings[model_name] = train_batch_files\n",
        "            X_test_embeddings[model_name] = test_batch_files\n",
        "\n",
        "            # --- 데이터 충분성 확인 (세그먼트 기준) ---\n",
        "            # 이 모델에 대해 훈련 및 테스트에 충분한 데이터(각 클래스 최소 2개)가 추출되었는지 확인합니다.\n",
        "            # 이를 위해 저장된 배치 파일에서 레이블만 다시 로드하여 확인합니다.\n",
        "            current_model_train_labels = []\n",
        "            print(f\"\\n  {model_name} 訓練 배치 파일에서 레이블 수집 중 (데이터 충분성 확인용)...\")\n",
        "            # 저장된 훈련 배치 파일 목록을 반복\n",
        "            for batch_file in train_batch_files:\n",
        "                 try:\n",
        "                      # .npz 파일 로드하여 레이블만 가져오기\n",
        "                      with np.load(batch_file) as data:\n",
        "                           current_model_train_labels.extend(data['labels']) # 레이블 목록에 추가\n",
        "                 except Exception as e:\n",
        "                      # 배치 파일 로드 중 오류 발생 시 처리\n",
        "                      print(f\"오류: {model_name} 訓練 배치 파일 로드 실패 (수집된 레이블 수 확인 중) - {batch_file}, 오류: {e}\")\n",
        "\n",
        "            current_model_test_labels = []\n",
        "            print(f\"  {model_name} 테스트 배치 파일에서 레이블 수집 중 (데이터 충분성 확인용)...\")\n",
        "            # 저장된 테스트 배치 파일 목록을 반복\n",
        "            for batch_file in test_batch_files:\n",
        "                 try:\n",
        "                      # .npz 파일 로드하여 레이블만 가져오기\n",
        "                      with np.load(batch_file) as data:\n",
        "                           current_model_test_labels.extend(data['labels']) # 레이블 목록에 추가\n",
        "                 except Exception as e:\n",
        "                      # 배치 파일 로드 중 오류 발생 시 처리\n",
        "                      print(f\"오류: {model_name} 테스트 배치 파일 로드 실패 (수집된 레이블 수 확인 중) - {batch_file}, 오류: {e}\")\n",
        "\n",
        "\n",
        "            # 현재 모델에 대한 데이터 충분성 최종 확인\n",
        "            # 훈련/테스트 모두 충분한 샘플 수와 클래스 개수(2개 이상)를 가져야 함\n",
        "            if len(current_model_train_labels) >= MIN_SAMPLES_PER_CLASS_TRAIN and len(np.unique(current_model_train_labels)) >= 2 and \\\n",
        "               len(current_model_test_labels) >= MIN_SAMPLES_PER_CLASS_TEST and len(np.unique(current_model_test_labels)) >= 2: # 훈련/테스트 모두 각 클래스 최소 샘플 수 이상인지 확인\n",
        "                 print(f\"\\n  {model_name} 모델에 대한 충분한 훈련 및 테스트 데이터가 추출되었습니다.\")\n",
        "                 # 하나 이상의 모델이 훈련 가능한 데이터를 추출했으므로 전체 플래그를 True로 설정\n",
        "                 are_embeddings_extracted_successfully_any_model = True\n",
        "\n",
        "                 # 학습/평가를 위해 이 모델의 필터링된 레이블 저장 (NumPy 배열 형태)\n",
        "                 y_train_filtered[model_name] = np.array(current_model_train_labels)\n",
        "                 y_test_filtered[model_name] = np.array(current_model_test_labels)\n",
        "                 y_test_encoded_filtered[model_name] = y_test_filtered[model_name] # 평가 보고서용으로도 저장\n",
        "\n",
        "                 # 임베딩 추출 및 파일 저장 완료 메시지\n",
        "                 print(f\"  {model_name} 임베딩 추출 및 파일 저장 완료.\")\n",
        "                 print(f\"  훈련 임베딩 배치 파일 수: {len(X_train_embeddings[model_name])}\")\n",
        "                 print(f\"  훈련 세그먼트 수 (총): {y_train_filtered[model_name].shape[0]}\") # 세그먼트 수로 변경\n",
        "                 print(f\"  테스트 임베딩 배치 파일 수: {len(X_test_embeddings[model_name])}\")\n",
        "                 print(f\"  테스트 세그먼트 수 (총): {y_test_filtered[model_name].shape[0]}\") # 세그먼트 수로 변경\n",
        "\n",
        "\n",
        "            else:\n",
        "                 # 데이터 부족 시 경고 메시지 출력\n",
        "                 print(f\"\\n경고: {model_name} 모델에 대한 충분한 훈련 및 테스트 데이터가 추출되지 않았습니다 (훈련/테스트 각 클래스 최소 {MIN_SAMPLES_PER_CLASS_TRAIN}/{MIN_SAMPLES_PER_CLASS_TEST}개 필요).\")\n",
        "                 # 해당 모델의 데이터 관련 변수들을 빈 값으로 초기화하여 이후 단계에서 사용되지 않도록 함\n",
        "                 X_train_embeddings[model_name] = []\n",
        "                 X_test_embeddings[model_name] = []\n",
        "                 y_train_filtered[model_name] = np.array([])\n",
        "                 y_test_filtered[model_name] = np.array([])\n",
        "                 y_test_encoded_filtered[model_name] = np.array([])\n",
        "                 # 전체 플래그(are_embeddings_extracted_successfully_any_model)는 다른 모델이 준비될 경우 True가 될 수 있음\n",
        "\n",
        "\n",
        "        # 모든 모델 처리가 끝난 후 전체 임베딩 추출 단계 성공 여부 최종 판단\n",
        "        if are_embeddings_extracted_successfully_any_model:\n",
        "             print(\"\\n하나 이상의 모델에 대해 임베딩 추출 및 데이터 준비 단계 성공.\")\n",
        "        else:\n",
        "             print(\"\\n경고: 모든 모델에서 훈련 가능한 임베딩 샘플이 부족합니다 (각 클래스 최소 2개 필요). 임베딩 추출 단계는 완료되었으나 학습/평가할 데이터가 없습니다.\")\n",
        "\n",
        "\n",
        "    print(\"\\n모델별 임베딩 추출 단계 완료.\")\n",
        "\n",
        "# 임베딩 추출 함수 정의 누락 시 실행되는 else 블록\n",
        "else: # 임베딩 추출 함수 정의가 누락된 경우\n",
        "    print(\"\\n임베딩 추출 함수 정의 누락으로 임베딩 추출 단계를 건너뜁니다.\")\n",
        "    # 이 경우, 이후 단계에서 데이터가 없으므로 관련 변수들을 빈 값으로 초기화해야 합니다.\n",
        "    X_train_embeddings = {}\n",
        "    X_test_embeddings = {}\n",
        "    y_train_filtered = {}\n",
        "    y_test_filtered = {}\n",
        "    y_test_encoded_filtered = {}\n",
        "    are_embeddings_extracted_successfully_any_model = False\n",
        "    embedding_dims = {}\n",
        "    temp_embedding_dir = None # 임시 디렉토리가 생성되지 않았으므로 cleanup 시도하지 않도록 None 설정\n",
        "\n",
        "\n",
        "# --- Helper function to load batches from saved files ---\n",
        "# 저장된 .npz 배치 파일에서 임베딩과 레이블을 불러오는 제너레이터 함수\n",
        "# 이 함수는 임베딩 추출 블록 외부에 정의되어야 다른 단계(모델 학습/평가)에서 사용 가능합니다.\n",
        "# (이 함수 정의는 이 셀 또는 별도 셀에 있어야 합니다. 여기서는 이 셀에 포함합니다.)\n",
        "# 이전에 정의되지 않았다면 여기서 정의합니다.\n",
        "if 'batch_generator' not in locals():\n",
        "    def batch_generator(batch_file_paths):\n",
        "        \"\"\"Generates batches of embeddings and labels from saved .npz files.\"\"\"\n",
        "        # print(f\"Debug: batch_generator called with {len(batch_file_paths)} files.\") # 디버그 출력 (필요 시 활성화)\n",
        "        if not batch_file_paths:\n",
        "             # print(\"Debug: batch_file_paths is empty.\") # 디버그 출력\n",
        "             return # 파일 경로 목록이 비어 있으면 빈 제너레이터 반환\n",
        "\n",
        "        # 각 배치 파일 경로를 반복\n",
        "        for file_path in batch_file_paths:\n",
        "            # print(f\"Debug: Loading batch from file: {file_path}\") # 디버그 출력\n",
        "            try:\n",
        "                # .npz 파일 로드\n",
        "                with np.load(file_path) as data:\n",
        "                    embeddings = data['embeddings'] # 임베딩 데이터 로드\n",
        "                    labels = data['labels']       # 레이블 데이터 로드\n",
        "                    # 로드된 데이터를 배치로 yield (파일 하나가 하나의 배치)\n",
        "                    # print(f\"Debug: Yielding batch with shape {embeddings.shape}, {labels.shape}\") # 디버그 출력\n",
        "                    yield embeddings, labels # 제너레이터로 데이터 반환\n",
        "            # 파일 로드 중 오류 발생 시 처리\n",
        "            except Exception as e:\n",
        "                print(f\"오류: 임베딩 배치 파일 로드 실패 - {file_path}, 오류: {e}\")\n",
        "                continue # 오류 발생 파일은 건너뛰고 다음 파일로 진행\n",
        "\n",
        "\n",
        "# --- 4. 모델 학습을 위한 레이블 준비 (One-Hot 인코딩) ---\n",
        "# 모델 학습에 사용될 레이블을 One-Hot 인코딩 형식으로 변환합니다.\n",
        "y_train_one_hot = {} # 훈련 레이블 (One-Hot)\n",
        "y_test_one_hot = {}  # 테스트 레이블 (One-Hot)\n",
        "\n",
        "# 충분한 필터링된 데이터가 있는 모델들을 식별합니다.\n",
        "models_ready_for_one_hot = [name for name, data in y_train_filtered.items() if data.size > 0 and len(np.unique(data)) >= 2]\n",
        "\n",
        "is_data_ready_for_training = False # 학습을 위한 데이터 준비 완료 여부 플래그 (최종 결과)\n",
        "\n",
        "# 하나 이상의 모델이 One-Hot 인코딩을 진행할 준비가 되었는지, 그리고 label_encoder와 num_classes가 유효한지 확인\n",
        "if models_ready_for_one_hot and 'label_encoder' in locals() and label_encoder is not None and 'num_classes' in locals() and num_classes >= 2:\n",
        "    print(\"\\n모델별 레이블 One-Hot 인코딩 시작...\")\n",
        "\n",
        "    # One-Hot 인코딩 준비가 된 각 모델에 대해 처리\n",
        "    for model_name in models_ready_for_one_hot:\n",
        "        # 필터링된 레이블이 존재하고 클래스가 2개 이상인지 다시 한번 확인 (안전 장치)\n",
        "        if model_name in y_train_filtered and y_train_filtered[model_name].size > 0 and len(np.unique(y_train_filtered[model_name])) >= 2 and \\\n",
        "           model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and len(np.unique(y_test_filtered[model_name])) >= 2:\n",
        "\n",
        "             print(f\"--- {model_name} 레이블 인코딩 중 ---\")\n",
        "             try:\n",
        "                 # 공유된 label_encoder와 전체 클래스 수를 사용하여 필터링된 레이블을 One-Hot 인코딩\n",
        "                 y_train_one_hot[model_name] = tf.keras.utils.to_categorical(y_train_filtered[model_name], num_classes=num_classes)\n",
        "                 y_test_one_hot[model_name] = tf.keras.utils.to_categorical(y_test_filtered[model_name], num_classes=num_classes)\n",
        "                 print(f\"  {model_name} 훈련 레이블 형태 (One-Hot): {y_train_one_hot[model_name].shape}\")\n",
        "                 print(f\"  {model_name} 테스트 레이블 형태 (One-Hot): {y_test_one_hot[model_name].shape}\")\n",
        "                 is_data_ready_for_training = True # 하나 이상의 모델이 성공적으로 인코딩되면 전체 플래그를 True로 설정\n",
        "\n",
        "             # One-Hot 인코딩 중 오류 발생 시 처리\n",
        "             except Exception as e:\n",
        "                 print(f\"  오 오류: {model_name} 레이블 One-Hot 인코딩 중 오류 발생: {e}\")\n",
        "                 # 오류 발생 시 해당 모델의 One-Hot 레이블을 빈 배열로 초기화\n",
        "                 y_train_one_hot[model_name] = np.array([])\n",
        "                 y_test_one_hot[model_name] = np.array([])\n",
        "\n",
        "\n",
        "        else: # 이 경우는 models_ready_for_one_hot 목록에 잘못 포함된 경우 (안전 장치)\n",
        "            print(f\"  경고: {model_name}에 대한 필터링된 레이블이 부족하거나 클래스가 2개 미만이어서 One-Hot 인코딩을 건너뜁니다 (재확인 실패).\")\n",
        "            # 해당 모델의 One-Hot 레이블을 빈 배열로 초기화\n",
        "            y_train_one_hot[model_name] = np.array([])\n",
        "            y_test_one_hot[model_name] = np.array([])\n",
        "\n",
        "\n",
        "    # 모든 모델 처리가 끝난 후, 최종적으로 학습 가능한 데이터가 있는지 확인 (하나라도 성공했으면 True)\n",
        "    if not any(arr.size > 0 for arr in y_train_one_hot.values()):\n",
        "         print(\"\\n일부 모델의 레이블 One-Hot 인코딩 실패 또는 데이터 부족.\")\n",
        "         is_data_ready_for_training = False # 학습 가능한 데이터가 전혀 없으면 최종 플래그 False\n",
        "\n",
        "\n",
        "    if is_data_ready_for_training:\n",
        "         print(\"\\n모델별 레이블 One-Hot 인코딩 단계 완료: 학습/평가 진행 준비 완료.\")\n",
        "\n",
        "\n",
        "# 데이터 부족, 클래스 수 부족, 또는 label_encoder/num_classes 누락으로 One-Hot 인코딩 건너뛰는 경우\n",
        "else:\n",
        "    print(\"\\n임베딩 추출 단계에서 충분한 데이터가 없거나, 클래스 수 부족, 또는 label_encoder 누락으로 레이블 One-Hot 인코딩을 건너뜠습니다.\")\n",
        "    is_data_ready_for_training = False # 학습 가능한 데이터 없음\n",
        "\n",
        "\n",
        "if is_data_ready_for_training:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 성공: 학습/평가 진행 가능.\")\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 실패: 훈련에 필요한 데이터가 부족합니다.\")\n",
        "\n",
        "\n",
        "# --- 5. 모델 구축, 학습 및 평가 실행 ---\n",
        "# 분류 모델을 구축하고, 학습시키고, 평가하는 단계입니다.\n",
        "# 필요한 함수들(build_classifier_model, train_model, evaluate_and_visualize_model)이 정의되어 있는지 확인합니다.\n",
        "if 'build_classifier_model' not in locals() or 'train_model' not in locals() or 'evaluate_and_visualize_model' not in locals():\n",
        "     print(\"오류: 필요한 모델 구축, 학습 또는 평가 함수가 정의되지 않았습니다. 모델 학습/평가를 건너뜁니다.\")\n",
        "     are_models_trained = False # 모델 학습 완료 여부 플래그\n",
        "     trained_models = {} # 학습된 모델 저장 딕셔너리\n",
        "     training_histories = {} # 학습 기록 저장 딕셔너리\n",
        "     evaluation_results = {} # 평가 결과 저장 딕셔너리\n",
        "\n",
        "# 필요한 함수들이 정의되어 있고, 학습을 위한 데이터 준비가 완료된 경우 이 else 블록 실행\n",
        "else: # 함수 정의 및 데이터 준비 완료\n",
        "    print(\"\\n모델 구축, 학습 및 평가 실행 시작...\")\n",
        "\n",
        "    # 학습된 모델, 기록, 평가 결과를 저장할 딕셔너리 초기화\n",
        "    trained_models = {}\n",
        "    training_histories = {}\n",
        "    evaluation_results = {} # 모델별 평가 지표 (손실, 정확도 등) 저장\n",
        "\n",
        "    # 임베딩 차원 정보(embedding_dims)가 임베딩 추출 단계에서 채워졌는지 확인\n",
        "    if not embedding_dims:\n",
        "         print(\"오류: 임베딩 차원 정보가 누락되었습니다 (embedding_dims). 모델 구축/학습을 건너뜁니다.\")\n",
        "         are_models_trained = False # 모델 학습 플래그 False\n",
        "    else: # 임베딩 차원 정보 존재\n",
        "        are_models_trained = False # 모델 학습 플래그 초기화\n",
        "\n",
        "        # 학습을 위한 데이터 준비가 완료된 경우 모델 학습 및 평가 진행\n",
        "        if is_data_ready_for_training:\n",
        "            print(\"\\n모델별 분류기 구축, 학습 및 평가 진행 중...\")\n",
        "\n",
        "            # One-Hot 인코딩이 성공적으로 완료되어 학습 가능한 데이터가 있는 모델 목록\n",
        "            models_to_process_keys = [name for name, data in y_train_one_hot.items() if data.size > 0]\n",
        "\n",
        "            # 학습할 모델이 없는 경우 경고 메시지 (is_data_ready_for_training이 True면 이 경우는 발생하면 안됨)\n",
        "            if not models_to_process_keys:\n",
        "                print(\"경고: 훈련 데이터가 준비된 모델이 없습니다. 학습/평가를 건너뜁니다.\")\n",
        "\n",
        "\n",
        "            # 학습 가능한 각 모델에 대해 루프 실행\n",
        "            for model_name in models_to_process_keys:\n",
        "                print(f\"\\n--- {model_name} 모델 처리 중 ---\")\n",
        "\n",
        "                # 학습 및 평가에 필요한 모든 데이터와 변수가 현재 모델에 대해 유효한지 최종 확인\n",
        "                # (is_data_ready_for_training이 True이고 models_to_process_keys에 포함되었다면 유효해야 함)\n",
        "                if model_name in X_train_embeddings and X_train_embeddings[model_name] and \\\n",
        "                   model_name in y_train_one_hot and y_train_one_hot[model_name].size > 0 and \\\n",
        "                   model_name in X_test_embeddings and X_test_embeddings[model_name] and \\\n",
        "                   model_name in y_test_one_hot and y_test_one_hot[model_name].size > 0 and \\\n",
        "                   model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and \\\n",
        "                   model_name in y_test_encoded_filtered and y_test_encoded_filtered[model_name].size > 0 and \\\n",
        "                   model_name in embedding_dims and 'num_classes' in locals() and num_classes >= 2 and \\\n",
        "                   'label_encoder' in locals() and label_encoder is not None:\n",
        "\n",
        "                    # Get embedding dimension for the current model\n",
        "                    # 임베딩 차원 딕셔너리에서 현재 모델의 차원 가져오기\n",
        "                    embedding_dim = embedding_dims.get(model_name) # .get() 메서드 사용 (없으면 None 반환)\n",
        "\n",
        "                    # 임베딩 차원이 유효한지 다시 확인 (안전 장치)\n",
        "                    if embedding_dim is None:\n",
        "                        print(f\"경고: {model_name}의 임베딩 차원 정보가 유효하지 않습니다. 모델 구축/학습을 건너뜁니다.\")\n",
        "                        trained_models[model_name] = None\n",
        "                        training_histories[model_name] = None\n",
        "                        evaluation_results[model_name] = {'loss': None, 'accuracy': None}\n",
        "                        continue # 현재 모델 처리를 건너뛰고 다음 모델로 이동\n",
        "\n",
        "\n",
        "                    print(f\"  {model_name} 임베딩 차원: {embedding_dim}\")\n",
        "\n",
        "                    # 분류기 모델 구축\n",
        "                    # build_classifier_model 함수 사용\n",
        "                    classifier_model = build_classifier_model(\n",
        "                         input_shape=embedding_dim, # 모델 입력 형태 (임베딩 차원)\n",
        "                         num_classes=num_classes, # 분류할 클래스 수\n",
        "                         learning_rate=0.001 # 학습률 정의\n",
        "                    )\n",
        "\n",
        "                    # 학습 및 평가를 위한 배치 제너레이터 생성\n",
        "                    # batch_generator 함수 사용 (임시 파일 경로 목록 전달)\n",
        "                    train_data_generator = batch_generator(X_train_embeddings[model_name])\n",
        "                    test_data_generator = batch_generator(X_test_embeddings[model_name])\n",
        "\n",
        "                    # Calculate steps per epoch for training and validation\n",
        "                    # 총 샘플 수 / 임베딩 추출 시의 배치 사이즈 (모델 학습 배치 사이즈와 같다고 가정)\n",
        "                    # NOTE: This assumes the batch size used in training (train_model) is the same as EMBEDDING_EXTRACTION_BATCH_SIZE\n",
        "                    # If not, this calculation needs adjustment.\n",
        "                    # A simpler approach is to pass the generator directly without steps_per_epoch if the generator handles epochs.\n",
        "                    # However, Keras fit with generator often requires steps_per_epoch.\n",
        "                    # Let's assume training batch size is EMBEDDING_EXTRACTION_BATCH_SIZE for now for simplicity.\n",
        "                    total_train_samples = y_train_filtered[model_name].shape[0] # 총 훈련 샘플 수\n",
        "                    total_test_samples = y_test_filtered[model_name].shape[0]   # 총 테스트 샘플 수\n",
        "\n",
        "                    # Ensure steps are at least 1 if there are samples\n",
        "                    # 훈련 스텝 수 계산 (0이 되지 않도록 최소 1 보장)\n",
        "                    train_steps_per_epoch = max(1, total_train_samples // EMBEDDING_EXTRACTION_BATCH_SIZE)\n",
        "                    # 평가 스텝 수 계산 (0이 되지 않도록 최소 1 보장)\n",
        "                    test_steps = max(1, total_test_samples // EMBEDDING_EXTRACTION_BATCH_SIZE)\n",
        "\n",
        "                    # 총 샘플 수가 배치 사이즈보다 작을 경우 스텝 수가 0이 되는 것 방지 (재확인)\n",
        "                    if total_train_samples > 0 and train_steps_per_epoch == 0:\n",
        "                         train_steps_per_epoch = 1\n",
        "                    if total_test_samples > 0 and test_steps == 0:\n",
        "                         test_steps = 1\n",
        "\n",
        "\n",
        "                    # --- 모델 학습 (배치 제너레이터 사용) ---\n",
        "                    print(f\"\\n  --- {model_name} 모델 학습 시작 (배치 제너레이터 사용) ---\")\n",
        "                    # 조기 종료(EarlyStopping) 및 학습률 감소(ReduceLROnPlateau) 콜백 설정\n",
        "                    # 필요한 콜백 클래스가 정의되어 있는지 확인 (안전 장치)\n",
        "                    try:\n",
        "                        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "                        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.000001)\n",
        "                        callbacks = [early_stopping, reduce_lr]\n",
        "                    except NameError:\n",
        "                         print(\"경고: EarlyStopping 또는 ReduceLROnPlateau 콜백 클래스가 정의되지 않았습니다 (Step 7). 콜백 없이 학습을 진행합니다.\")\n",
        "                         callbacks = [] # 콜백이 없으면 빈 리스트 사용\n",
        "\n",
        "                    try:\n",
        "                         # 총 훈련/테스트 샘플 수가 0보다 큰 경우에만 fit 실행\n",
        "                         if total_train_samples > 0 and total_test_samples > 0:\n",
        "                             # model.fit 메서드를 배치 제너레이터와 함께 사용\n",
        "                             # train_model 함수 대신 직접 fit 호출 (이전 버전을 고려)\n",
        "                             history = classifier_model.fit(\n",
        "                                 train_data_generator, # 訓練 데이터 제너레이터\n",
        "                                 steps_per_epoch=train_steps_per_epoch, # epoch당 訓練 스텝 수\n",
        "                                 epochs=50, # 학습할 epoch 수 (상수 정의 가능)\n",
        "                                 validation_data=test_data_generator, # 검증 데이터 제너레이터\n",
        "                                 validation_steps=test_steps, # 검증 스텝 수\n",
        "                                 callbacks=callbacks, # 콜백 목록\n",
        "                                 verbose=1 # 학습 과정 출력 상세도\n",
        "                             )\n",
        "                             print(f\"  {model_name} 모델 학습 완료.\")\n",
        "                             # 학습된 모델과 기록 저장\n",
        "                             trained_models[model_name] = classifier_model\n",
        "                             training_histories[model_name] = history\n",
        "                             are_models_trained = True # 하나 이상의 모델이 학습되었음을 표시\n",
        "\n",
        "                             # --- 모델 평가 (배치 제너레이터 사용) ---\n",
        "                             print(f\"\\n  --- {model_name} 모델 평가 시작 (배치 제너레이터 사용) ---\")\n",
        "                             # evaluate_and_visualize_model 함수가 NumPy 배열을 기대하므로,\n",
        "                             # 여기서는 제너레이터를 사용하여 예측 및 평가 지표를 직접 계산합니다.\n",
        "\n",
        "                             print(\"\\n  예측 수행 및 리포트 생성 중...\")\n",
        "                             try:\n",
        "                                 # 예측을 위한 새로운 테스트 데이터 제너레이터 생성\n",
        "                                 # 동일한 제너레이터를 재사용하면 상태 문제가 발생할 수 있으므로 새로 생성\n",
        "                                 test_generator_for_predict = batch_generator(X_test_embeddings[model_name])\n",
        "                                 # 총 테스트 샘플 수가 0보다 큰 경우에만 예측 실행\n",
        "                                 if total_test_samples > 0:\n",
        "                                      # 모델 예측 수행 (제너레이터 사용)\n",
        "                                      y_pred_probs = classifier_model.predict(test_generator_for_predict, steps=test_steps)\n",
        "                                      y_pred = np.argmax(y_pred_probs, axis=1) # 예측된 클래스 인덱스 (NumPy 배열)\n",
        "\n",
        "                                      # 실제 레이블 (필터링된 인코딩 레이블 사용)\n",
        "                                      y_true_filtered = y_test_encoded_filtered[model_name] # NumPy 배열\n",
        "\n",
        "                                      # Ensure the number of predictions matches the number of true labels\n",
        "                                      # 예측 결과 수와 실제 레이블 수가 일치하는지 확인 (중요!)\n",
        "                                      if len(y_pred) != len(y_true_filtered):\n",
        "                                           print(f\"경고: {model_name} 예측 결과 수({len(y_pred)})와 실제 레이블 수({len(y_true_filtered)})가 일치하지 않습니다. 평가 리포트/혼동 행렬 생략.\")\n",
        "                                           evaluation_metrics = {'loss': None, 'accuracy': None} # 신뢰할 수 없으므로 평가 결과 N/A 처리\n",
        "                                      else:\n",
        "                                           # --- 분류 리포트 생성 ---\n",
        "                                           print(\"\\n  분류 리포트:\")\n",
        "                                           # target_names를 label_encoder에서 가져와 사용 (클래스 수 일치 확인)\n",
        "                                           if label_encoder is not None and len(np.unique(y_true_filtered)) == num_classes:\n",
        "                                                # classification_report 함수 사용\n",
        "                                                print(classification_report(y_true_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "                                           else:\n",
        "                                                # label_encoder 사용 불가 시 target_names 없이 리포트 출력\n",
        "                                                print(classification_report(y_true_filtered, y_pred))\n",
        "                                                print(\"  경고: 레이블 인코더 또는 클래스 불일치로 인해 target_names를 사용할 수 없습니다.\")\n",
        "\n",
        "\n",
        "                                           # --- 혼동 행렬 시각화 ---\n",
        "                                           print(\"\\n  혼동 행렬 시각화:\")\n",
        "                                           # 필터링된 테스트 데이터의 고유 클래스 수가 전체 클래스 수와 일치하는지 확인\n",
        "                                           unique_test_labels_filtered = np.unique(y_true_filtered)\n",
        "                                           if len(unique_test_labels_filtered) == num_classes:\n",
        "                                                # 혼동 행렬 계산을 위해 실제/예측 레이블에 나타나는 모든 고유 레이블 사용\n",
        "                                                all_possible_labels = np.unique(np.concatenate((y_true_filtered, y_pred)))\n",
        "                                                # If label_encoder is available, use its classes order for consistent matrix\n",
        "                                                if label_encoder is not None and hasattr(label_encoder, 'classes_'):\n",
        "                                                    labels_for_matrix = np.arange(len(label_encoder.classes_))\n",
        "                                                    # 실제 데이터에 나타나는 레이블만 포함하도록 필터링\n",
        "                                                    present_labels_in_data = np.unique(np.concatenate((y_true_filtered, y_pred))).tolist()\n",
        "                                                    labels_for_matrix = [l for l in labels_for_matrix if l in present_labels_in_data]\n",
        "\n",
        "                                                    cm = confusion_matrix(y_true_filtered, y_pred, labels=labels_for_matrix) # 혼동 행렬 계산\n",
        "\n",
        "                                                    # 혼동 행렬 크기 조정\n",
        "                                                    plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix))))\n",
        "                                                    # 눈금 레이블을 label_encoder 클래스 이름으로 설정 (필터링된 레이블 사용)\n",
        "                                                    tick_labels = [label_encoder.classes_[i] for i in labels_for_matrix]\n",
        "                                                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                                                               xticklabels=tick_labels, yticklabels=tick_labels)\n",
        "                                                else:\n",
        "                                                     # label_encoder 사용 불가 시 레이블 없이 혼동 행렬 생성\n",
        "                                                     labels_for_matrix = np.unique(np.concatenate((y_true_filtered, y_pred)))\n",
        "                                                     cm = confusion_matrix(y_true_filtered, y_pred, labels=labels_for_matrix)\n",
        "                                                     plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix))))\n",
        "                                                     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "                                                plt.xlabel('예측 레이블')\n",
        "                                                plt.ylabel('실제 레이블')\n",
        "                                                plt.title(f'{model_name} 혼동 행렬')\n",
        "                                                plt.show() # 혼동 행렬 그래프 출력\n",
        "                                           else:\n",
        "                                                # 필터링된 데이터에 모든 클래스가 포함되지 않아 혼동 행렬 생성 불가 시 경고\n",
        "                                                print(\"  경고: 필터링된 테스트 데이터에 모든 클래스가 포함되지 않아 혼동 행렬을 생성할 수 없습니다.\")\n",
        "\n",
        "                                           # --- 모델 평가 (손실 및 정확도) ---\n",
        "                                           # classifier_model.evaluate 메서드를 사용하여 손실 및 정확도 계산 (제너레이터 사용)\n",
        "                                           loss, accuracy = classifier_model.evaluate(test_data_generator, steps=test_steps, verbose=0)\n",
        "                                           evaluation_metrics = {'loss': loss, 'accuracy': accuracy} # 평가 지표 저장\n",
        "                                           print(f\"  테스트 세트 손실: {loss:.4f}\")\n",
        "                                           print(f\"  테스트 세트 정확도: {accuracy:.4f}\")\n",
        "                                 else:\n",
        "                                      # 테스트 샘플이 부족하여 예측/평가 건너뛰는 경우\n",
        "                                      print(\"경고: 테스트 샘플이 부족하여 예측/평가를 건너뜁니다.\")\n",
        "                                      evaluation_metrics = {'loss': None, 'accuracy': None} # 결과 N/A 처리\n",
        "\n",
        "\n",
        "                             # 예측 또는 리포트 생성 중 오류 발생 시 처리\n",
        "                             except Exception as e:\n",
        "                                 print(f\"  오류: {model_name} 모델 예측 또는 리포트 생성 중 오류 발생: {e}\")\n",
        "                                 evaluation_metrics = {'loss': None, 'accuracy': None} # 평가 결과 N/A 처리\n",
        "\n",
        "\n",
        "                             evaluation_results[model_name] = evaluation_metrics # 모델별 평가 결과 저장\n",
        "\n",
        "                             # --- 학습 과정 시각화 ---\n",
        "                             print(\"\\n  학습 과정 시각화:\")\n",
        "                             if history is not None and hasattr(history, 'history'): # 학습 기록이 있는지 확인\n",
        "                                 plt.figure(figsize=(12, 5))\n",
        "\n",
        "                                 # 정확도 그래프\n",
        "                                 plt.subplot(1, 2, 1)\n",
        "                                 plt.plot(history.history.get('accuracy', []), label='훈련 정확도') # 훈련 정확도 (없으면 빈 리스트)\n",
        "                                 if 'val_accuracy' in history.history: # 검증 정확도가 있으면 추가\n",
        "                                      plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "                                 plt.xlabel('에폭')\n",
        "                                 plt.ylabel('정확도')\n",
        "                                 plt.title(f'{model_name} 훈련 및 검증 정확도') # 그래프 제목\n",
        "                                 plt.legend() # 범례 표시\n",
        "\n",
        "                                 # 손실 그래프\n",
        "                                 plt.subplot(1, 2, 2)\n",
        "                                 plt.plot(history.history.get('loss', []), label='훈련 손실') # 훈련 손실 (없으면 빈 리스트)\n",
        "                                 if 'val_loss' in history.history: # 검증 손실이 있으면 추가\n",
        "                                      plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "                                 plt.xlabel('에폭')\n",
        "                                 plt.ylabel('손실')\n",
        "                                 plt.title(f'{model_name} 훈련 및 검증 손실') # 그래프 제목\n",
        "                                 plt.legend() # 범례 표시\n",
        "\n",
        "                                 plt.show() # 그래프 출력\n",
        "                             else:\n",
        "                                 print(\"  경고: 학습 기록(history)이 없어 그래프를 그릴 수 없습니다.\")\n",
        "\n",
        "                         # 훈련 또는 테스트 샘플이 부족하여 fit 실행을 건너뛴 경우\n",
        "                         else:\n",
        "                              print(\"경고: 훈련 또는 테스트 샘플이 부족하여 모델 학습/평가를 건너뜁니다.\")\n",
        "                              # 해당 모델의 학습/평가 결과를 None 또는 N/A로 표시\n",
        "                              trained_models[model_name] = None\n",
        "                              training_histories[model_name] = None\n",
        "                              evaluation_results[model_name] = {'loss': None, 'accuracy': None}\n",
        "\n",
        "\n",
        "                    # 모델 학습 중 오류 발생 시 처리\n",
        "                    except Exception as e:\n",
        "                         print(f\"  오류: {model_name} 모델 학습 중 오류 발생: {e}\")\n",
        "                         # 해당 모델의 학습/평가 결과를 None 또는 N/A로 표시\n",
        "                         trained_models[model_name] = None\n",
        "                         training_histories[model_name] = None\n",
        "                         evaluation_results[model_name] = {'loss': None, 'accuracy': None}\n",
        "\n",
        "\n",
        "                # 학습/평가를 위한 데이터 또는 변수가 부족하여 현재 모델 처리를 건너뛰는 경우 (안전 장치)\n",
        "                else:\n",
        "                    print(f\"경고: {model_name} 모델 학습/평가를 위한 데이터 또는 필수 변수가 부족합니다 (재확인 실패). 건너뜁니다.\")\n",
        "                    # 해당 모델의 학습/평가 결과를 None 또는 N/A로 표시\n",
        "                    trained_models[model_name] = None\n",
        "                    training_histories[model_name] = None\n",
        "                    evaluation_results[model_name] = {'loss': None, 'accuracy': None}\n",
        "\n",
        "\n",
        "            print(\"\\n모델 구축, 학습 및 평가 실행 단계 완료.\")\n",
        "\n",
        "        # 데이터 준비 실패로 모델 학습 및 평가를 건너뛰는 경우\n",
        "        else:\n",
        "            print(\"\\n데이터 준비 실패로 모델 학습 및 평가를 건너뜁니다.\")\n",
        "            are_models_trained = False # 모델 학습 플래그 False\n",
        "\n",
        "\n",
        "# --- 임시 임베딩 디렉토리 정리 ---\n",
        "# 임베딩 배치 파일이 저장되었던 임시 디렉토리를 삭제합니다.\n",
        "# temp_embedding_dir이 유효하고 디렉토리가 실제로 존재하는 경우에만 삭제 시도\n",
        "if temp_embedding_dir and os.path.exists(temp_embedding_dir):\n",
        "    print(f\"\\n임시 임베딩 디렉토리 삭제 중: {temp_embedding_dir}\")\n",
        "    try:\n",
        "        shutil.rmtree(temp_embedding_dir) # 디렉토리 및 내용물 모두 삭제\n",
        "        print(\"임시 디렉토리 삭제 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 임시 디렉토리 삭제 실패: {e}\")\n",
        "\n",
        "\n",
        "# --- 6. 모델 성능 비교 (요약) ---\n",
        "print(\"\\n6. 모델 성능 비교 (요약) 중...\")\n",
        "print(\"\\n--- 모델별 최종 성능 비교 ---\")\n",
        "# 평가 결과가 있고, 하나 이상의 모델이 정확도 값이 있는 경우에만 요약 출력\n",
        "if evaluation_results and any(metrics.get('accuracy') is not None for metrics in evaluation_results.values()):\n",
        "    # 정확도 기준으로 결과 정렬 (선택 사항)\n",
        "    # 정확도 값이 None인 경우는 -1로 처리하여 뒤로 보내도록 함\n",
        "    sorted_results = sorted(evaluation_results.items(), key=lambda item: item[1].get('accuracy') if item[1].get('accuracy') is not None else -1, reverse=True)\n",
        "\n",
        "    # 정렬된 결과 출력\n",
        "    for model_name, metrics in sorted_results:\n",
        "        print(f\"  {model_name}:\")\n",
        "        print(f\"    테스트 손실: {metrics.get('loss'):.4f}\" if metrics.get('loss') is not None else \"    테스트 손실: N/A\") # 손실 값 출력 (없으면 N/A)\n",
        "        print(f\"    테스트 정확도: {metrics.get('accuracy'):.4f}\" if metrics.get('accuracy') is not None else \"    테스트 정확도: N/A\") # 정확도 값 출력 (없으면 N/A)\n",
        "else:\n",
        "    print(\"평가 결과가 없어 모델 성능 비교를 수행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "# --- 7. 새로운 오디오 파일에 대한 예측 (예시) ---\n",
        "print(\"\\n7. 새로운 오디오 파일 예측 예시 중...\")\n",
        "print(\"\\n--- 새로운 오디오 파일 예측 예시 ---\")\n",
        "\n",
        "# 학습된 모델이 하나라도 있는 경우에만 예측 예시 진행\n",
        "if any(model is not None for model in trained_models.values()):\n",
        "    # 예측에 사용할 학습된 모델 선택 (예: 첫 번째 학습된 모델)\n",
        "    model_to_predict_name = None\n",
        "    for name, model in trained_models.items():\n",
        "         if model is not None:\n",
        "              model_to_predict_name = name # 학습된 모델 이름을 찾으면 저장\n",
        "              break # 첫 번째 학습된 모델만 사용 (예시 목적)\n",
        "    model_to_predict = trained_models.get(model_to_predict_name) # 해당 이름으로 학습된 모델 객체 가져오기\n",
        "\n",
        "\n",
        "    # 예측에 사용할 모델이 유효한 경우 예측 진행\n",
        "    # 예측에는 YAMNet 임베딩 함수와 YAMNet 모델 객체가 필요합니다.\n",
        "    if model_to_predict is not None and \\\n",
        "       'extract_yamnet_embedding' in locals() and callable(extract_yamnet_embedding) and \\\n",
        "       'loaded_models' in locals() and loaded_models.get('YAMNet') is not None and \\\n",
        "       'label_encoder' in locals() and label_encoder is not None: # label_encoder가 정의되어 있어야 함\n",
        "\n",
        "        print(f\"\\n예측에 사용할 모델: {model_to_predict_name}\")\n",
        "\n",
        "        # 예측할 샘플 오디오 파일 경로 지정\n",
        "        # Step 1에서 로드된 원본 데이터 경로 목록(all_audio_paths) 사용 시도\n",
        "        predict_audio_path = None\n",
        "\n",
        "        # 원본 데이터 경로 목록(all_audio_paths)이 있고 비어있지 않으면 첫 번째 경로 사용\n",
        "        if 'all_audio_paths' in locals() and all_audio_paths:\n",
        "            predict_audio_path = all_audio_paths[0]\n",
        "            print(f\"예측을 위해 데이터셋에서 샘플 파일 선택: {predict_audio_path}\")\n",
        "        # DeepShip 기본 경로가 정의되어 있고, 해당 경로에 예시 파일(103.wav)이 존재하면 사용\n",
        "        elif 'DEEPSHIP_BASE_PATH' in locals() and os.path.exists(os.path.join(DEEPSHIP_BASE_PATH, 'Cargo', '103.wav')):\n",
        "            predict_audio_path = os.path.join(DEEPSHIP_BASE_PATH, 'Cargo', '103.wav')\n",
        "            print(f\"예측을 위해 DeepShip에서 샘플 파일 선택: {predict_audio_path}\")\n",
        "        # 다른 폴백 경로나 더미 파일 생성 로직을 여기에 추가 가능\n",
        "\n",
        "        # predict_on_new_audio 함수가 정의되어 있는지 확인하고 예측 실행\n",
        "        if predict_audio_path and os.path.exists(predict_audio_path):\n",
        "             if 'predict_on_new_audio' not in locals() or not callable(predict_on_new_audio):\n",
        "                  print(\"오류: 'predict_on_new_audio' 함수가 정의되지 않았습니다 (Step 8). 예측을 건너뜁니다.\")\n",
        "             else:\n",
        "                 try:\n",
        "                      # predict_on_new_audio 함수 호출\n",
        "                      # 학습된 분류기 모델, 전처리 및 임베딩 추출 함수(YAMNet 사용), 원본 YAMNet 모델 객체, label_encoder, 예측 파일 경로 전달\n",
        "                      # predict_on_new_audio 함수는 내부적으로 YAMNet 임베딩 추출 함수를 호출합니다.\n",
        "                      # 이 함수는 파일 경로를 받도록 설계되어 있다고 가정합니다. (세그먼트 처리와 분리)\n",
        "                      # 만약 predict_on_new_audio 함수도 세그먼트 기반으로 변경해야 한다면 수정이 필요합니다.\n",
        "                      # 현재는 파일 기반 예측 함수가 Step 8에 정의되어 있다고 가정합니다.\n",
        "                      predicted_label = predict_on_new_audio(\n",
        "                           classifier_model=model_to_predict, # 학습된 분류기 모델\n",
        "                           embedding_extractor_func=extract_yamnet_embedding, # 사용할 임베딩 추출 함수 (YAMNet)\n",
        "                           embedding_model=loaded_models.get('YAMNet'), # 임베딩 모델 객체 (YAMNet)\n",
        "                           label_encoder=label_encoder, # LabelEncoder 객체\n",
        "                           audio_path=predict_audio_path, # 예측 파일 경로\n",
        "                           # extract_yamnet_embedding 함수가 필요로 하는 다른 인자들 (e.g., target_sample_rate)도 predict_on_new_audio 함수를 통해 전달되어야 함\n",
        "                           # 현재 predict_on_new_audio 함수가 이러한 인자를 어떻게 처리하는지 불분명하므로 기본값 사용 또는 수정 필요\n",
        "                           target_sample_rate=TARGET_SAMPLE_RATE # 전역 상수를 사용하거나 predict_on_new_audio 인자로 전달\n",
        "                      )\n",
        "                      # 예측 결과는 함수 내부에서 출력됩니다.\n",
        "                 except Exception as e:\n",
        "                      print(f\"오류: 새로운 오디오 파일 예측 중 예외 발생: {e}\")\n",
        "                      import traceback\n",
        "                      traceback.print_exc(limit=2)\n",
        "\n",
        "        else:\n",
        "            print(\"\\n예측을 수행할 수 없습니다: 예측할 오디오 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"\\n예측을 수행할 수 없습니다:\")\n",
        "        if any(model is None for model in trained_models.values()):\n",
        "             print(\"  학습된 모델이 없어 예측을 수행할 수 없습니다.\")\n",
        "        if 'extract_yamnet_embedding' not in locals() or not callable(extract_yamnet_embedding):\n",
        "             print(\"  YAMNet 임베딩 추출 함수가 정의되지 않았습니다.\")\n",
        "        if 'loaded_models' not in locals() or loaded_models.get('YAMNet') is None:\n",
        "             print(\"  YAMNet 임베딩 모델이 로드되지 않았습니다.\")\n",
        "        if 'label_encoder' not in locals() or label_encoder is None:\n",
        "             print(\"  LabelEncoder가 없습니다.\")\n",
        "\n",
        "\n",
        "# 학습된 모델이 전혀 없는 경우 예측 예시 건너뛰기\n",
        "else:\n",
        "    print(\"\\n학습된 모델이 없어 예측을 수행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\n모델별 전체 파이프라인 실행 및 결과 비교 단계 완료.\")\n",
        "\n",
        "# 이 셀의 모든 코드가 성공적으로 실행되었음을 나타냅니다.\n",
        "# 하지만 실제 파이프라인의 성공 여부는 중간 로그 및 최종 평가 결과를 확인해야 합니다.\n",
        "# 특히 \"데이터 부족\" 메시지나 다른 오류가 없었는지 확인하세요."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e9acd0b"
      },
      "source": [
        "## 7. 모델 구축 및 학습 함수 정의\n",
        "\n",
        "각 모델에서 추출된 임베딩을 입력으로 받아 최종 분류를 수행하는 Keras 모델(분류 헤드)을 구축하고 학습시키는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "385c3e80"
      },
      "source": [
        "import tensorflow as tf # Ensure tf is imported\n",
        "from tensorflow.keras.models import Model # Ensure Model is imported\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout # Ensure layers are imported\n",
        "from tensorflow.keras.optimizers import Adam # Ensure Adam is imported\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Ensure callbacks are imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n7. 분류기 모델 구축 및 학습 함수 정의 중...\")\n",
        "\n",
        "def build_classifier_model(input_shape, num_classes, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    임베딩 입력을 위한 분류 헤드 Keras 모델을 구축하고 컴파일합니다.\n",
        "\n",
        "    Args:\n",
        "        input_shape (int): 입력 임베딩의 차원.\n",
        "        num_classes (int): 출력 클래스의 수 (이진 분류의 경우 2).\n",
        "        learning_rate (float): Adam 옵티마이저의 학습률.\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.keras.models.Model: 컴파일된 Keras 모델 객체.\n",
        "    \"\"\"\n",
        "    embedding_input = Input(shape=(input_shape,), name='embedding_input')\n",
        "\n",
        "    x = Dense(128, activation='relu')(embedding_input)\n",
        "    x = Dropout(0.4)(x) # Increased dropout for regularization\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x) # Increased dropout for regularization\n",
        "    # Output layer for binary classification (num_classes=2) or multi-class\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=embedding_input, outputs=output)\n",
        "\n",
        "    # Model compilation\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Use categorical_crossentropy loss for multi-class (including binary with 2 classes)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"  분류 헤드 모델 구축 및 컴파일 완료.\")\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train_one_hot, X_test, y_test_one_hot,\n",
        "                               epochs=50, batch_size=16):\n",
        "    \"\"\"\n",
        "    주어진 데이터로 Keras 모델을 학습시킵니다.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.models.Model): 학습할 컴파일된 Keras 모델.\n",
        "        X_train (np.ndarray): 訓練 임베딩 데이터.\n",
        "        y_train_one_hot (np.ndarray): One-Hot 인코딩된 訓練 레이블.\n",
        "        X_test (np.ndarray): 테스트 임베딩 데이터 (검증에 사용).\n",
        "        y_test_one_hot (np.ndarray): One-Hot 인코딩된 테스트 레이블 (검증에 사용).\n",
        "        epochs (int): 학습 에폭 수.\n",
        "        batch_size (int): 배치 크기.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (trained_model, history) 학습된 모델 객체와 학습 기록.\n",
        "               データ不足またはエラー発生時 (None, None) 返還。\n",
        "    \"\"\"\n",
        "    print(\"\\n  모델 학습 시작...\")\n",
        "\n",
        "    # Data validation and sufficiency checks\n",
        "    if X_train.size == 0 or y_train_one_hot.size == 0 or X_test.size == 0 or y_test_one_hot.size == 0:\n",
        "        print(\"  경고: 분류기 학습을 위한 훈련 또는 테스트 데이터가 부족합니다. 학습을 건너뜁니다.\")\n",
        "        return None, None\n",
        "\n",
        "    if X_train.shape[0] < 2 or X_test.shape[0] < 2:\n",
        "        print(\"  경고: 분류기 학습을 위한 훈련 또는 테스트 데이터 샘플 수가 2개 미만입니다. 학습을 건너뜁니다.\")\n",
        "        return None, None\n",
        "\n",
        "    # Ensure there are at least 2 unique classes in the training labels\n",
        "    # np.unique(np.argmax(y_train_one_hot, axis=1)) gets the unique original encoded labels\n",
        "    if y_train_one_hot.ndim > 1 and len(np.unique(np.argmax(y_train_one_hot, axis=1))) < 2:\n",
        "         print(\"  경고: 분류기 학습을 위한 훈련 레이블에 클래스가 2개 미만입니다. 학습을 건너뜁니다.\")\n",
        "         return None, None\n",
        "    elif y_train_one_hot.ndim == 1 and len(np.unique(y_train_one_hot)) < 2: # Handle case where labels might not be one-hot yet (should be one-hot here)\n",
        "         print(\"  경고: 분류기 학습을 위한 훈련 레이블에 클래스가 2개 미만입니다 (One-Hot 인코딩 전 상태 확인). 학습을 건너뜁니다.\")\n",
        "         return None, None\n",
        "\n",
        "\n",
        "    # EarlyStopping 및 ReduceLROnPlateau 콜백 설정\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.000001)\n",
        "    callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "    # Model training\n",
        "    try:\n",
        "        history = model.fit(\n",
        "            X_train, y_train_one_hot,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_test, y_test_one_hot), # Use validation_data for test set evaluation during training\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        print(\"  모델 학습 완료.\")\n",
        "        return model, history\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: 모델 학습 중 오류 발생: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "print(\"\\n모델 구축 및 학습 함수 정의 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23bdbafd"
      },
      "source": [
        "## 8. 모델 평가 및 결과 시각화 함수 정의\n",
        "\n",
        "학습된 모델의 성능을 테스트 데이터에 대해 평가하고, 분류 리포트, 혼동 행렬, 학습 곡선 등을 시각화하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf25291a"
      },
      "source": [
        "import matplotlib.pyplot as plt # Ensure matplotlib is imported\n",
        "import seaborn as sns # Ensure seaborn is imported\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Ensure sklearn metrics are imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n8. 모델 평가 및 결과 시각화 함수 정의 중...\")\n",
        "\n",
        "# Assuming necessary libraries (matplotlib, seaborn, sklearn.metrics, numpy) are imported.\n",
        "# Assuming label_encoder is available if evaluation is attempted.\n",
        "\n",
        "def evaluate_and_visualize_model(model_name, trained_model, X_test, y_test_one_hot, y_test_encoded_filtered,\n",
        "                                 label_encoder, history):\n",
        "    \"\"\"\n",
        "    학습된 모델의 성능을 평가하고 결과를 시각화합니다.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): 모델 이름 (예: 'YAMNet', 'VGGish').\n",
        "        trained_model (tf.keras.Model): 학습된 모델 객체.\n",
        "        X_test (np.ndarray): 테스트 임베딩 데이터.\n",
        "        y_test_one_hot (np.ndarray): One-Hot 인코딩된 테스트 레이블.\n",
        "        y_test_encoded_filtered (np.ndarray): 필터링된 실제 인코딩 레이블 (혼동 행렬, 리포트용).\n",
        "        label_encoder (sklearn.preprocessing.LabelEncoder): 레이블 인코더 객체.\n",
        "        history (tf.keras.callbacks.History): 모델 학습 기록.\n",
        "\n",
        "    Returns:\n",
        "        dict: 평가 결과를 담고 있는 딕셔너리 (loss, accuracy).\n",
        "              평가 실패 시 None 값을 가질 수 있습니다.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- {model_name} 모델 성능 평가 및 시각화 시작 ---\")\n",
        "    evaluation_metrics = {'loss': None, 'accuracy': None} # Initialize metrics dictionary\n",
        "\n",
        "    # --- 1. 데이터 및 모델 유효성 확인 ---\n",
        "    # Check if the model and data are valid and not empty\n",
        "    if trained_model is None:\n",
        "        print(f\"  경고: {model_name} 모델이 학습되지 않았습니다. 평가를 건너뜁니다.\")\n",
        "        return evaluation_metrics\n",
        "\n",
        "    if not isinstance(X_test, np.ndarray) or X_test.size == 0:\n",
        "        print(f\"  경고: {model_name} 모델의 테스트 임베딩 데이터가 유효하지 않거나 비어 있습니다. 평가를 건너뜁니다.\")\n",
        "        return evaluation_metrics\n",
        "\n",
        "    if not isinstance(y_test_one_hot, np.ndarray) or y_test_one_hot.size == 0:\n",
        "         print(f\"  경고: {model_name} 모델의 One-Hot 테스트 레이블이 유효하지 않거나 비어 있습니다. 평가를 건너뜁니다.\")\n",
        "         return evaluation_metrics\n",
        "\n",
        "    if not isinstance(y_test_encoded_filtered, np.ndarray) or y_test_encoded_filtered.size == 0:\n",
        "         print(f\"  경고: {model_name} 모델의 필터링된 실제 인코딩 레이블이 유효하지 않거나 비어 있습니다. 평가를 건너뜁니다.\")\n",
        "         return evaluation_metrics\n",
        "\n",
        "    if label_encoder is None:\n",
        "        print(f\"  경고: 레이블 인코더가 None입니다. 평가 리포트 및 혼동 행렬 레이블이 정확하지 않을 수 있습니다.\")\n",
        "        # Proceed with evaluation but without accurate labels\n",
        "\n",
        "    # Ensure there are at least 2 unique classes in the filtered test labels for meaningful evaluation\n",
        "    unique_test_labels = np.unique(y_test_encoded_filtered)\n",
        "    if len(unique_test_labels) < 2:\n",
        "         print(f\"  경고: 필터링된 테스트 데이터에 클래스가 2개 미만입니다 ({len(unique_test_labels)}개). 평가를 건너뜁니다.\")\n",
        "         return evaluation_metrics\n",
        "\n",
        "    # Determine the number of classes from the one-hot labels shape or label_encoder\n",
        "    num_classes = y_test_one_hot.shape[1] if y_test_one_hot.ndim > 1 else 1\n",
        "    if label_encoder is not None:\n",
        "        num_classes_from_encoder = len(label_encoder.classes_)\n",
        "        if num_classes != num_classes_from_encoder:\n",
        "             print(f\"  경고: One-Hot 레이블 형태와 LabelEncoder의 클래스 수가 일치하지 않습니다 ({num_classes} vs {num_classes_from_encoder}).\")\n",
        "             # Use the number from one-hot labels for consistency with model output\n",
        "             pass # Continue, using num_classes from one-hot shape\n",
        "\n",
        "\n",
        "    print(\"  데이터 및 모델 유효성 확인 완료. 평가 진행.\")\n",
        "\n",
        "    # --- 2. 모델 평가 ---\n",
        "    print(\"  테스트 데이터로 모델 평가...\")\n",
        "    try:\n",
        "        loss, accuracy = trained_model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "        print(f\"  테스트 세트 손실: {loss:.4f}\")\n",
        "        print(f\"  테스트 세트 정확도: {accuracy:.4f}\")\n",
        "        evaluation_metrics['loss'] = loss\n",
        "        evaluation_metrics['accuracy'] = accuracy\n",
        "    except Exception as e:\n",
        "         print(f\"  오류: {model_name} 모델 평가 중 오류 발생: {e}\")\n",
        "         # Continue to prediction and reporting if evaluation fails but prediction might work\n",
        "\n",
        "\n",
        "    # --- 3. 예측 및 리포트 생성 ---\n",
        "    print(\"\\n  예측 수행 및 리포트 생성...\")\n",
        "    try:\n",
        "        y_pred_probs = trained_model.predict(X_test)\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "        print(\"\\n  분류 리포트:\")\n",
        "        # Use target_names from label_encoder if available and matches unique test labels\n",
        "        if label_encoder is not None and len(unique_test_labels) == num_classes:\n",
        "             print(classification_report(y_test_encoded_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "        else:\n",
        "             # Fallback without target names\n",
        "             print(classification_report(y_test_encoded_filtered, y_pred))\n",
        "             print(\"  경고: 레이블 인코더 또는 클래스 불일치로 인해 target_names를 사용할 수 없습니다.\")\n",
        "\n",
        "\n",
        "        # --- 4. 혼동 행렬 시각화 ---\n",
        "        print(\"\\n  혼동 행렬 시각화:\")\n",
        "        # Ensure the unique classes in the filtered test data match the number of classes for the matrix size\n",
        "        if len(unique_test_labels) == num_classes:\n",
        "             # Ensure labels for confusion matrix calculation cover all unique predicted and true labels\n",
        "             all_possible_labels = np.unique(np.concatenate((y_test_encoded_filtered, y_pred)))\n",
        "             # If label_encoder is available, use its classes order for consistent matrix\n",
        "             if label_encoder is not None and hasattr(label_encoder, 'classes_'):\n",
        "                 labels_for_matrix = np.arange(len(label_encoder.classes_))\n",
        "                 # Filter labels_for_matrix to only include those present in y_test_encoded_filtered or y_pred for smaller datasets\n",
        "                 # This avoids plotting empty rows/columns if not all classes are in the test set (post-filtering)\n",
        "                 present_labels_in_data = np.unique(np.concatenate((y_test_encoded_filtered, y_pred))).tolist()\n",
        "                 labels_for_matrix = [l for l in labels_for_matrix if l in present_labels_in_data]\n",
        "\n",
        "                 cm = confusion_matrix(y_test_encoded_filtered, y_pred, labels=labels_for_matrix)\n",
        "\n",
        "                 plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix)))) # Adjust figure size based on num classes\n",
        "                 # Use label_encoder classes for tick labels if available, filtered to present labels\n",
        "                 tick_labels = [label_encoder.classes_[i] for i in labels_for_matrix]\n",
        "                 sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                            xticklabels=tick_labels, yticklabels=tick_labels)\n",
        "             else:\n",
        "                  # Fallback without labels if label_encoder or classes don't match\n",
        "                  # Use unique labels from the data for matrix labels if label_encoder is not fully usable\n",
        "                  labels_for_matrix = np.unique(np.concatenate((y_test_encoded_filtered, y_pred)))\n",
        "                  cm = confusion_matrix(y_test_encoded_filtered, y_pred, labels=labels_for_matrix)\n",
        "                  plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix)))) # Adjust figure size\n",
        "                  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') # Fallback without labels\n",
        "             plt.xlabel('예측 레이블')\n",
        "             plt.ylabel('실제 레이블')\n",
        "             plt.title(f'{model_name} 혼동 행렬')\n",
        "             plt.show()\n",
        "        else:\n",
        "             print(\"  경고: 필터링된 테스트 데이터에 모든 클래스가 포함되지 않아 혼동 행렬을 생성할 수 없습니다.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: {model_name} 모델 예측 또는 리포트 생성 중 오류 발생: {e}\")\n",
        "\n",
        "\n",
        "    # --- 5. 학습 과정 시각화 ---\n",
        "    print(\"\\n  학습 과정 시각화:\")\n",
        "    # Check if history object is valid and has the 'history' attribute\n",
        "    if history is not None and hasattr(history, 'history'):\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Accuracy plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history.get('accuracy', []), label='훈련 정확도') # Use .get() for safety\n",
        "        if 'val_accuracy' in history.history: # Check if validation accuracy exists\n",
        "             plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "        plt.xlabel('에폭')\n",
        "        plt.ylabel('정확도')\n",
        "        plt.title(f'{model_name} 훈련 및 검증 정확도')\n",
        "        plt.legend()\n",
        "\n",
        "        # Loss plot\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history.get('loss', []), label='훈련 손실') # Use .get() for safety\n",
        "        if 'val_loss' in history.history: # Check if validation loss exists\n",
        "             plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "        plt.xlabel('에폭')\n",
        "        plt.ylabel('손실')\n",
        "        plt.title(f'{model_name} 훈련 및 검증 손실')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"  경고: 학습 기록(history)이 없어 그래프를 그릴 수 없습니다.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- {model_name} 모델 성능 평가 및 시각화 완료 ---\")\n",
        "    return evaluation_metrics # Return evaluation results\n",
        "\n",
        "\n",
        "print(\"\\n모델 평가 및 결과 시각화 함수 정의 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9868cc6"
      },
      "source": [
        "## 9. 예측 함수 정의\n",
        "\n",
        "학습된 모델을 사용하여 새로운 오디오 파일에 대한 예측을 수행하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bfd471f"
      },
      "source": [
        "import os # Ensure os is imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n9. 예측 함수 정의 중...\")\n",
        "\n",
        "def predict_on_new_audio(model, yamnet_model, label_encoder, audio_path):\n",
        "    \"\"\"\n",
        "    새로운 오디오 파일에 대해 학습된 모델로 예측을 수행합니다.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.models.Model): 예측에 사용할 학습된 Keras 모델.\n",
        "        yamnet_model: YAMNet 모델 객체 (오디오 전처리 및 임베딩 추출에 사용).\n",
        "        label_encoder (sklearn.preprocessing.LabelEncoder): 레이블 인코더 객체.\n",
        "        audio_path (str): 예측할 오디오 파일 경로.\n",
        "\n",
        "    Returns:\n",
        "        str: 예측된 레이블 문자열, 또는 예측 실패 시 None.\n",
        "    \"\"\"\n",
        "    print(f\"\\n새 오디오 파일('{os.path.basename(audio_path)}') 예측 시작...\")\n",
        "\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"오류: 예측할 오디오 파일을 찾을 수 없습니다: {audio_path}\")\n",
        "        return None\n",
        "\n",
        "    # Use the defined YAMNet embedding extraction function for preprocessing\n",
        "    # Ensure extract_yamnet_embedding is defined and available\n",
        "    if 'extract_yamnet_embedding' not in locals():\n",
        "        print(\"오류: 'extract_yamnet_embedding' 함수가 정의되지 않았습니다. 예측을 건너뜁니다.\")\n",
        "        return None\n",
        "\n",
        "    new_audio_embedding = extract_yamnet_embedding(audio_path, yamnet_model)\n",
        "\n",
        "    if new_audio_embedding is None:\n",
        "        print(\"새 오디오 파일 임베딩 추출에 실패했습니다.\")\n",
        "        return None\n",
        "\n",
        "    # Reshape the embedding to match the model's expected input shape (add batch dimension)\n",
        "    new_audio_embedding = np.expand_dims(new_audio_embedding, axis=0)\n",
        "\n",
        "    # Perform prediction\n",
        "    try:\n",
        "        prediction_probs = model.predict(new_audio_embedding)[0]\n",
        "        predicted_class_idx = np.argmax(prediction_probs)\n",
        "\n",
        "        # Convert predicted index back to label using the label encoder\n",
        "        if label_encoder is not None and hasattr(label_encoder, 'inverse_transform'):\n",
        "            predicted_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
        "        else:\n",
        "            print(\"경고: label_encoder가 없거나 inverse_transform 메서드를 사용할 수 없습니다. 예측된 인덱스만 반환합니다.\")\n",
        "            predicted_label = predicted_class_idx # Return index if label_encoder is not usable\n",
        "\n",
        "\n",
        "        print(f\"\\n예측 결과 for '{os.path.basename(audio_path)}':\")\n",
        "        if label_encoder is not None and hasattr(label_encoder, 'classes_'):\n",
        "            # Print probabilities for each class\n",
        "            for i, class_name in enumerate(label_encoder.classes_):\n",
        "                print(f\"  {class_name}: {prediction_probs[i]*100:.2f}%\")\n",
        "        else:\n",
        "             # Print probabilities by index if class names are not available\n",
        "             for i in range(len(prediction_probs)):\n",
        "                  print(f\"  Class {i} (Index {i}): {prediction_probs[i]*100:.2f}%\")\n",
        "\n",
        "        print(f\"최종 예측: {predicted_label}\")\n",
        "        return predicted_label\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 예측 수행 중 오류 발생: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"예측 함수 정의 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28d37bbf"
      },
      "source": [
        "## 10. 모델별 전체 파이프라인 실행 및 결과 비교\n",
        "\n",
        "정의된 함수들을 사용하여 각 모델(YAMNet, PANNs, VGGish)에 대해 데이터 준비(임베딩 추출 포함), 학습, 평가 과정을 순차적으로 실행하고, 최종 성능을 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e95caffe"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os # Ensure os is imported\n",
        "import matplotlib.pyplot as plt # Ensure matplotlib is imported\n",
        "import seaborn as sns # Ensure seaborn is imported\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Ensure sklearn metrics are imported\n",
        "import random # Ensure random is imported for augmentation\n",
        "import tempfile # Import tempfile for creating temporary directories\n",
        "import shutil # Import shutil for removing directories\n",
        "import sys # Import sys for checking memory usage (approximate)\n",
        "import gc # Import garbage collector\n",
        "\n",
        "\n",
        "print(\"\\n10. 모델별 전체 파이프라인 실행 및 결과 비교 시작...\")\n",
        "\n",
        "# --- IMPORTANT: Ensure Step 4 (cell defining extract_... functions) is executed first! ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\">>>         >>>  필수 작업 안내  <<<         <<<\")\n",
        "print(\">>>                                           <<<\")\n",
        "print(\">>>   오디오 전처리 및 임베딩 추출 함수가 정의된 Step 4 셀을 먼저 실행했는지 확인하세요! <<<\")\n",
        "print(\">>>   (예: 셀 ID 617c87ca) 그렇지 않으면 'Quality must be one of...' 오류가 발생합니다. <<<\")\n",
        "print(\">>>                                           <<<\")\n",
        "print(\">>>   DeepShip('/content/DeepShip') 및 노이즈('/content/MBARI_noise_data') 디렉토리에 <<<\")\n",
        "print(\">>>   훈련/테스트에 필요한 오디오 파일이 충분히 있는지 확인하세요!                     <<<\")\n",
        "print(\">>>   (각 클래스 최소 2개 파일 필요) 데이터 부족 시 '데이터 부족' 오류가 발생합니다. <<<\")\n",
        "print(\">>>                                           <<<\")\n",
        "print(\">>>         >>>  필수 작업 완료 후 이 셀을 실행하세요.  <<<         <<<\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "\n",
        "# --- 1. 데이터 로드 및 준비 ---\n",
        "# Calls the function defined in Step 3 (corrected version)\n",
        "# Ensure load_and_prepare_dataset is defined and available\n",
        "if 'load_and_prepare_dataset' not in locals():\n",
        "    print(\"오류: 'load_and_prepare_dataset' 함수가 정의되지 않았습니다. 파이프라인 실행을 중단합니다.\")\n",
        "    is_data_prepared = False\n",
        "    X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, num_classes, noise_audio_paths = [], [], np.array([]), np.array([]), None, 0, [] # Initialize noise_audio_paths\n",
        "else:\n",
        "    # Modified to also return noise_audio_paths\n",
        "    X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths = load_and_prepare_dataset(\n",
        "        deepship_path=DEEPSHIP_BASE_PATH,\n",
        "        noise_data_dir=MBARI_NOISE_BASE_DIR,\n",
        "        deepship_classes=DEEPSHIP_CLASSES # Pass the global constant\n",
        "    )\n",
        "\n",
        "# --- 2. 오디오 모델 로드 ---\n",
        "# Calls the function defined in Step 5\n",
        "# Ensure load_audio_models is defined and available\n",
        "if 'load_audio_models' not in locals():\n",
        "     print(\"오류: 'load_audio_models' 함수가 정의되지 않았습니다. 파이프라인 실행을 중단합니다.\")\n",
        "     are_models_loaded = False\n",
        "     loaded_models = {}\n",
        "else:\n",
        "    loaded_models, are_models_loaded = load_audio_models()\n",
        "\n",
        "\n",
        "# --- 3. Model-wise Embedding Extraction and Data Preparation (Batch Processing & Saving) ---\n",
        "# Instead of storing all embeddings in memory, we'll save them to temporary files.\n",
        "temp_embedding_dir = None\n",
        "are_embeddings_extracted_successfully = False\n",
        "embedding_dims = {} # Dictionary to store embedding dimensions\n",
        "\n",
        "# Ensure extract_yamnet_embedding, extract_panns_embedding, extract_vggish_embedding are defined\n",
        "if 'extract_yamnet_embedding' not in locals() or 'extract_panns_embedding' not in locals() or 'extract_vggish_embedding' not in locals():\n",
        "    print(\"오류: 임베딩 추출 함수 중 하나 이상이 정의되지 않았습니다. 임베딩 추출을 건너뜁니다.\")\n",
        "    # Skip the rest of the embedding extraction block\n",
        "    pass\n",
        "else: # All necessary functions are defined\n",
        "\n",
        "    if is_data_prepared and are_models_loaded:\n",
        "        print(\"\\n모델별 임베딩 추출 및 데이터 준비 시작 (배치 처리 및 파일 저장 - 시간이 오래 걸릴 수 있습니다)...\")\n",
        "\n",
        "        # Create a temporary directory to store embeddings\n",
        "        temp_embedding_dir = tempfile.mkdtemp()\n",
        "        print(f\"임시 임베딩 저장 디렉토리: {temp_embedding_dir}\")\n",
        "\n",
        "        # Dictionary mapping model names to their loaded model object, embedding dimension, and extraction function\n",
        "        # Ensure embedding dimension constants and loaded models are available\n",
        "        models_info = {}\n",
        "        if loaded_models.get('YAMNet') is not None and 'YAMNET_EMBEDDING_DIM' in locals():\n",
        "             models_info['YAMNet'] = {'model': loaded_models['YAMNet'], 'extract_func': extract_yamnet_embedding, 'dim': YAMNET_EMBEDDING_DIM}\n",
        "        else:\n",
        "             print(\"경고: YAMNet 모델 정보 또는 함수가 누락되었습니다. YAMNet 처리를 건너뜁니다.\")\n",
        "        if loaded_models.get('PANNs') is not None and 'PANNS_EMBEDDING_DIM' in locals():\n",
        "             models_info['PANNs'] = {'model': loaded_models['PANNs'], 'extract_func': extract_panns_embedding, 'dim': PANNS_EMBEDDING_DIM}\n",
        "        else:\n",
        "              print(\"경고: PANNs 모델 정보 또는 함수가 누락되었습니다. PANNs 처리를 건너뜁니다.\")\n",
        "        if loaded_models.get('VGGish') is not None and 'VGGISH_EMBEDDING_DIM' in locals():\n",
        "             models_info['VGGish'] = {'model': loaded_models['VGGish'], 'extract_func': extract_vggish_embedding, 'dim': VGGISH_EMBEDDING_DIM}\n",
        "        else:\n",
        "              print(\"경고: VGGish 모델 정보 또는 함수가 누락되었습니다. VGGish 처리를 건너뜁니다.\")\n",
        "\n",
        "\n",
        "        # Define batch size for embedding extraction (further reduced)\n",
        "        EMBEDDING_EXTRACTION_BATCH_SIZE = 1 # Further reduced batch size for lower memory usage\n",
        "\n",
        "        if models_info: # Proceed only if at least one model info is available\n",
        "            all_models_extracted_at_least_one_sample = False # Track if any model extracted any sample\n",
        "\n",
        "            for model_name, info in models_info.items():\n",
        "                model = info['model']\n",
        "                extract_func = info['extract_func']\n",
        "                embedding_dims[model_name] = info['dim'] # Store embedding dimension\n",
        "\n",
        "                print(f\"\\n--- {model_name} 임베딩 추출 중 (배치 크기: {EMBEDDING_EXTRACTION_BATCH_SIZE}) ---\")\n",
        "                train_batch_files = [] # List to store paths of saved train embedding batches\n",
        "                test_batch_files = []  # List to store paths of saved test embedding batches\n",
        "\n",
        "                # Process training data paths in batches\n",
        "                print(\"  훈련 데이터 처리 중...\")\n",
        "                train_embeddings_batch = []\n",
        "                train_labels_batch = []\n",
        "                # Added index tracking for original samples\n",
        "                original_train_indices = []\n",
        "\n",
        "\n",
        "                for i, path in enumerate(X_train_paths):\n",
        "                    original_label_encoded = y_train_encoded[i]\n",
        "                    original_label_str = label_encoder.inverse_transform([original_label_encoded])[0] if label_encoder is not None and hasattr(label_encoder, 'inverse_transform') else str(original_label_encoded)\n",
        "\n",
        "                    print(f\"    처리 파일 {i+1}/{len(X_train_paths)}: {os.path.basename(path)}\")\n",
        "\n",
        "                    # Extract original embedding (no augmentation for the base sample)\n",
        "                    # Ensure noise_audio_paths is passed even if augment_with_noise is False, as the function expects it.\n",
        "                    try:\n",
        "                         embedding = extract_func(path, model, augment_with_noise=False, noise_audio_paths=noise_audio_paths)\n",
        "                         if embedding is not None:\n",
        "                              train_embeddings_batch.append(embedding)\n",
        "                              train_labels_batch.append(original_label_encoded)\n",
        "                              original_train_indices.append(i) # Store original index\n",
        "                         else:\n",
        "                              print(f\"      경고: 파일 '{os.path.basename(path)}' 임베딩 추출 실패 (결과 None).\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                         print(f\"    오류: 파일 '{os.path.basename(path)}' 임베딩 추출 중 예외 발생: {e}\")\n",
        "                         import traceback\n",
        "                         traceback.print_exc(limit=2, file=sys.stdout) # Print limited traceback\n",
        "                         # Continue to next file even on error\n",
        "\n",
        "\n",
        "                    # Add augmented samples for 'ship' class if noise data is available and augmentation is desired\n",
        "                    # Augmentation is done here during extraction and saved as separate samples\n",
        "                    if original_label_str == 'ship' and noise_audio_paths:\n",
        "                         print(f\"      증강 적용 중 (노이즈 혼합) for '{os.path.basename(path)}'\")\n",
        "                         try:\n",
        "                              augmented_embedding = extract_func(\n",
        "                                   path,\n",
        "                                   model,\n",
        "                                   augment_with_noise=True, # Apply augmentation\n",
        "                                   noise_audio_paths=noise_audio_paths,\n",
        "                                   noise_level=0.1\n",
        "                              )\n",
        "                              if augmented_embedding is not None:\n",
        "                                   train_embeddings_batch.append(augmented_embedding)\n",
        "                                   train_labels_batch.append(original_label_encoded) # Augmented sample keeps original label\n",
        "                                   # No need to track augmented sample indices separately for now\n",
        "                              else:\n",
        "                                   print(f\"      경고: 파일 '{os.path.basename(path)}' 증강 임베딩 추출 실패 (결과 None).\")\n",
        "\n",
        "                         except Exception as e:\n",
        "                              print(f\"    오류: 파일 '{os.path.basename(path)}' 증강 임베딩 추출 중 예외 발생: {e}\")\n",
        "                              import traceback\n",
        "                              traceback.print_exc(limit=2, file=sys.stdout) # Print limited traceback\n",
        "                              # Continue to next file even on error\n",
        "\n",
        "\n",
        "                    # Save batch and clear lists if batch size is reached or it's the last sample\n",
        "                    if (len(train_embeddings_batch) >= EMBEDDING_EXTRACTION_BATCH_SIZE) or (i == len(X_train_paths) - 1 and train_embeddings_batch):\n",
        "                        print(f\"    저장 중: 훈련 배치 {len(train_batch_files) + 1}, 현재 배치 샘플 수: {len(train_embeddings_batch)}\")\n",
        "                        try:\n",
        "                             batch_embeddings_array = np.array(train_embeddings_batch)\n",
        "                             batch_labels_array = np.array(train_labels_batch)\n",
        "\n",
        "                             # Save batch to a temporary file\n",
        "                             batch_file_path = os.path.join(temp_embedding_dir, f'{model_name}_train_batch_{len(train_batch_files)}.npz')\n",
        "                             np.savez(batch_file_path, embeddings=batch_embeddings_array, labels=batch_labels_array)\n",
        "                             train_batch_files.append(batch_file_path)\n",
        "\n",
        "                             # Clear batch lists immediately after saving\n",
        "                             train_embeddings_batch = []\n",
        "                             train_labels_batch = []\n",
        "                             original_train_indices = [] # Clear indices too\n",
        "                             print(f\"    훈련 배치 {len(train_batch_files)} 저장 완료. 메모리 해제.\")\n",
        "                             # Optional: Force garbage collection (can sometimes help)\n",
        "                             gc.collect()\n",
        "\n",
        "\n",
        "                        except Exception as e:\n",
        "                            print(f\"    오류: 훈련 배치 저장 실패 - 배치 {len(train_batch_files) + 1}, 오류: {e}\")\n",
        "                            # Attempt to clear lists even on error to free memory\n",
        "                            train_embeddings_batch = []\n",
        "                            train_labels_batch = []\n",
        "                            original_train_indices = []\n",
        "\n",
        "\n",
        "                    if (i + 1) % 50 == 0:\n",
        "                         print(f\"    {i+1}/{len(X_train_paths)} 훈련 파일 처리 완료 (증강 포함).\")\n",
        "\n",
        "\n",
        "            # Process testing data paths in batches\n",
        "            print(\"  테스트 데이터 처리 중...\")\n",
        "            test_embeddings_batch = []\n",
        "            test_labels_batch = []\n",
        "            # Added index tracking for original samples\n",
        "            original_test_indices = []\n",
        "            for i, path in enumerate(X_test_paths):\n",
        "                original_label_encoded = y_test_encoded[i]\n",
        "                print(f\"    처리 파일 {i+1}/{len(X_test_paths)}: {os.path.basename(path)}\")\n",
        "                # No augmentation for test samples\n",
        "                 # Ensure noise_audio_paths is passed even if augment_with_noise is False, as the function expects it.\n",
        "                try:\n",
        "                     embedding = extract_func(path, model, augment_with_noise=False, noise_audio_paths=noise_audio_paths)\n",
        "\n",
        "                     if embedding is not None:\n",
        "                         test_embeddings_batch.append(embedding)\n",
        "                         test_labels_batch.append(original_label_encoded)\n",
        "                         original_test_indices.append(i) # Store original index\n",
        "                     else:\n",
        "                         print(f\"      경고: 파일 '{os.path.basename(path)}' 임베딩 추출 실패 (결과 None).\")\n",
        "\n",
        "                except Exception as e:\n",
        "                     print(f\"    오류: 파일 '{os.path.basename(path)}' 임베딩 추출 중 예외 발생: {e}\")\n",
        "                     import traceback\n",
        "                     traceback.print_exc(limit=2, file=sys.stdout) # Print limited traceback\n",
        "                     # Continue to next file even on error\n",
        "\n",
        "\n",
        "                # Save batch and clear lists if batch size is reached or it's the last sample\n",
        "                if (len(test_embeddings_batch) >= EMBEDDING_EXTRACTION_BATCH_SIZE) or (i == len(X_test_paths) - 1 and test_embeddings_batch):\n",
        "                    print(f\"    저장 중: 테스트 배치 {len(test_batch_files) + 1}, 현재 배치 샘플 수: {len(test_embeddings_batch)}\")\n",
        "                    try:\n",
        "                         batch_embeddings_array = np.array(test_embeddings_batch)\n",
        "                         batch_labels_array = np.array(test_labels_batch)\n",
        "\n",
        "                         # Save batch to a temporary file\n",
        "                         batch_file_path = os.path.join(temp_embedding_dir, f'{model_name}_test_batch_{len(test_batch_files)}.npz')\n",
        "                         np.savez(batch_file_path, embeddings=batch_embeddings_array, labels=batch_labels_array)\n",
        "                         test_batch_files.append(batch_file_path)\n",
        "\n",
        "                         # Clear batch lists immediately after saving\n",
        "                         test_embeddings_batch = []\n",
        "                         test_labels_batch = []\n",
        "                         original_test_indices = [] # Clear indices too\n",
        "                         print(f\"    테스트 배치 {len(test_batch_files)} 저장 완료. 메모리 해제.\")\n",
        "                         # Optional: Force garbage collection (can sometimes help)\n",
        "                         gc.collect()\n",
        "\n",
        "                    except Exception as e:\n",
        "                         print(f\"    오류: 테스트 배치 저장 실패 - 배치 {len(test_batch_files) + 1}, 오류: {e}\")\n",
        "                         # Attempt to clear lists even on error to free memory\n",
        "                         test_embeddings_batch = []\n",
        "                         test_labels_batch = []\n",
        "                         original_test_indices = []\n",
        "\n",
        "\n",
        "                if (i + 1) % 20 == 0:\n",
        "                    print(f\"    {i+1}/{len(X_test_paths)} 테스트 파일 처리 완료.\")\n",
        "\n",
        "\n",
        "            # Store the list of batch file paths for this model\n",
        "            X_train_embeddings[model_name] = train_batch_files\n",
        "            X_test_embeddings[model_name] = test_batch_files\n",
        "\n",
        "            # We need the total number of samples and labels for One-Hot encoding and evaluation reports\n",
        "            # This requires loading all labels again, but not the embeddings themselves\n",
        "            all_train_labels_filtered = []\n",
        "            print(f\"\\n  {model_name} 훈련 배치 파일에서 레이블 수집 중...\")\n",
        "            for batch_file in train_batch_files:\n",
        "                 try:\n",
        "                      with np.load(batch_file) as data:\n",
        "                           all_train_labels_filtered.extend(data['labels'])\n",
        "                 except Exception as e:\n",
        "                      print(f\"오류: 훈련 배치 파일 로드 실패 (레이블 수집 중) - {batch_file}, 오류: {e}\")\n",
        "\n",
        "            y_train_filtered[model_name] = np.array(all_train_labels_filtered)\n",
        "\n",
        "            all_test_labels_filtered = []\n",
        "            print(f\"  {model_name} 테스트 배치 파일에서 레이블 수집 중...\")\n",
        "            for batch_file in test_batch_files:\n",
        "                 try:\n",
        "                      with np.load(batch_file) as data:\n",
        "                           all_test_labels_filtered.extend(data['labels'])\n",
        "                 except Exception as e:\n",
        "                      print(f\"오류: 테스트 배치 파일 로드 실패 (레이블 수집 중) - {batch_file}, 오류: {e}\")\n",
        "            y_test_filtered[model_name] = np.array(all_test_labels_filtered)\n",
        "            y_test_encoded_filtered[model_name] = y_test_filtered[model_name] # Use filtered test labels for evaluation reports\n",
        "\n",
        "\n",
        "            print(f\"\\n  {model_name} 임베딩 추출 및 파일 저장 완료.\")\n",
        "            print(f\"  훈련 임베딩 배치 파일 수: {len(X_train_embeddings[model_name])}\")\n",
        "            print(f\"  훈련 샘플 수 (총): {y_train_filtered[model_name].shape[0]}\")\n",
        "            print(f\"  테스트 임베딩 배치 파일 수: {len(X_test_embeddings[model_name])}\")\n",
        "            print(f\"  테스트 샘플 수 (총): {y_test_filtered[model_name].shape[0]}\")\n",
        "\n",
        "\n",
        "            # Check if sufficient samples were extracted for this model (at least 2 samples per class in filtered train data)\n",
        "            if y_train_filtered[model_name].shape[0] >= 2 and model_name in y_train_filtered and len(np.unique(y_train_filtered[model_name])) >= 2:\n",
        "                 all_models_extracted_at_least_one_sample = True # At least one model has trainable data\n",
        "\n",
        "\n",
        "        if all_models_extracted_at_least_one_sample:\n",
        "             are_embeddings_extracted_successfully = True # Set flag if at least one model has data\n",
        "        else:\n",
        "             print(\"\\n경고: 모든 모델에서 훈련 가능한 임베딩 샘플이 부족합니다 (각 클래스 최소 2개 필요).\")\n",
        "\n",
        "\n",
        "    print(\"\\n모델별 임베딩 추출 단계 완료.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 모델 로드, 또는 모델 정보 누락으로 임베딩 추출을 건너뜁니다.\")\n",
        "\n",
        "\n",
        "# --- Helper function to load batches from saved files ---\n",
        "def batch_generator(batch_file_paths):\n",
        "    \"\"\"Generates batches of embeddings and labels from saved .npz files.\"\"\"\n",
        "    # print(f\"Debug: batch_generator called with {len(batch_file_paths)} files.\") # Debug print\n",
        "    if not batch_file_paths:\n",
        "         # print(\"Debug: batch_file_paths is empty.\") # Debug print\n",
        "         return # Return empty generator\n",
        "\n",
        "    for file_path in batch_file_paths:\n",
        "        # print(f\"Debug: Loading batch from file: {file_path}\") # Debug print\n",
        "        try:\n",
        "            with np.load(file_path) as data:\n",
        "                embeddings = data['embeddings']\n",
        "                labels = data['labels']\n",
        "                # Yield batches from the loaded data\n",
        "                # Since each file is already a batch, we yield the whole file content as one batch\n",
        "                # print(f\"Debug: Yielding batch with shape {embeddings.shape}, {labels.shape}\") # Debug print\n",
        "                yield embeddings, labels\n",
        "        except Exception as e:\n",
        "            print(f\"오류: 임베딩 배치 파일 로드 실패 - {file_path}, 오류: {e}\")\n",
        "            continue # Skip this file\n",
        "\n",
        "\n",
        "# --- 4. Prepare Labels for Training (One-Hot Encoding) ---\n",
        "y_train_one_hot = {}\n",
        "y_test_one_hot = {}\n",
        "\n",
        "# Perform one-hot encoding only if embeddings were extracted successfully for at least one model\n",
        "# and if label_encoder and num_classes are available and valid from data preparation\n",
        "is_data_ready_for_training = False # Reset and determine based on one-hot encoding success\n",
        "\n",
        "if are_embeddings_extracted_successfully and 'label_encoder' in locals() and label_encoder is not None and 'num_classes' in locals() and num_classes >= 2:\n",
        "    print(\"\\n모델별 레이블 One-Hot 인코딩 시작...\")\n",
        "    all_models_encoded_successfully = True # Track if all models that had embeddings are encoded\n",
        "\n",
        "    # Iterate through models that had successful embedding extraction\n",
        "    models_with_extracted_data = [name for name, data in y_train_filtered.items() if data.size > 0 and len(np.unique(data)) >= 2]\n",
        "\n",
        "    if not models_with_extracted_data:\n",
        "         print(\"경고: One-Hot 인코딩을 위한 필터링된 데이터가 있는 모델이 없습니다.\")\n",
        "         all_models_encoded_successfully = False\n",
        "\n",
        "\n",
        "    for model_name in models_with_extracted_data: # Use keys from models with sufficient filtered data\n",
        "        # Check if filtered labels exist and have at least 2 classes (redundant check, but safe)\n",
        "        if model_name in y_train_filtered and y_train_filtered[model_name].size > 0 and len(np.unique(y_train_filtered[model_name])) >= 2 and \\\n",
        "           model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and len(np.unique(y_test_filtered[model_name])) >= 2:\n",
        "\n",
        "             print(f\"--- {model_name} 레이블 인코딩 중 ---\")\n",
        "             try:\n",
        "                 # One-hot Encode the filtered labels using the shared label_encoder\n",
        "                 y_train_one_hot[model_name] = tf.keras.utils.to_categorical(y_train_filtered[model_name], num_classes=num_classes)\n",
        "                 y_test_one_hot[model_name] = tf.keras.utils.to_categorical(y_test_filtered[model_name], num_classes=num_classes)\n",
        "                 print(f\"  {model_name} 훈련 레이블 형태 (One-Hot): {y_train_one_hot[model_name].shape}\")\n",
        "                 print(f\"  {model_name} 테스트 레이블 형태 (One-Hot): {y_test_one_hot[model_name].shape}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"  오 오류: {model_name} 레이블 One-Hot 인코딩 중 오류 발생: {e}\")\n",
        "                 # Initialize empty arrays if encoding fails\n",
        "                 y_train_one_hot[model_name] = np.array([])\n",
        "                 y_test_one_hot[model_name] = np.array([])\n",
        "                 all_models_encoded_successfully = False # Mark failure\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"  경고: {model_name}에 대한 필터링된 레이블이 부족하거나 클래스가 2개 미만이어서 One-Hot 인코딩을 건너뜁니다.\")\n",
        "            # Initialize empty arrays if filtered labels are missing or empty or insufficient classes\n",
        "            y_train_one_hot[model_name] = np.array([])\n",
        "            y_test_one_hot[model_name] = np.array([])\n",
        "            all_models_encoded_successfully = False # Mark failure\n",
        "\n",
        "\n",
        "    if all_models_encoded_successfully and any(arr.size > 0 for arr in y_train_one_hot.values()):\n",
        "         print(\"\\n모델별 레이블 One-Hot 인코딩 단계 완료.\")\n",
        "         is_data_ready_for_training = True # Set the flag to True if at least one model was encoded successfully\n",
        "    else:\n",
        "         print(\"\\n일부 모델의 레이블 One-Hot 인코딩 실패 또는 데이터 부족.\")\n",
        "         is_data_ready_for_training = False # Set the flag to False if any intended model failed encoding\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\n임베딩 추출 실패, 클래스 수 부족, 또는 label_encoder 누락으로 레이블 One-Hot 인코딩을 건너뜠습니다.\")\n",
        "    is_data_ready_for_training = False # Set the flag to False\n",
        "\n",
        "\n",
        "if is_data_ready_for_training:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 성공.\")\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 실패: 훈련에 필요한 데이터가 부족합니다.\")\n",
        "\n",
        "\n",
        "# --- 5. 모델 구축, 학습 및 평가 실행 ---\n",
        "# Ensure build_classifier_model, train_model, evaluate_and_visualize_model are defined\n",
        "if 'build_classifier_model' not in locals() or 'train_model' not in locals() or 'evaluate_and_visualize_model' not in locals():\n",
        "     print(\"오류: 필요한 모델 구축, 학습 또는 평가 함수가 정의되지 않았습니다. 모델 학습/평가를 건너뜁니다.\")\n",
        "     are_models_trained = False\n",
        "     trained_models = {}\n",
        "     training_histories = {}\n",
        "     evaluation_results = {}\n",
        "\n",
        "else: # Functions are defined, proceed with training and evaluation if data is ready\n",
        "    print(\"\\n모델 구축, 학습 및 평가 실행 시작...\")\n",
        "\n",
        "    # Dictionaries to store trained models, histories, and evaluation results\n",
        "    trained_models = {}\n",
        "    training_histories = {}\n",
        "    evaluation_results = {} # To store metrics for comparison\n",
        "\n",
        "    # Ensure embedding_dims is populated from the extraction step\n",
        "    if not embedding_dims:\n",
        "         print(\"오류: 임베딩 차원 정보가 누락되었습니다 (embedding_dims). 모델 구축/학습을 건너뜁니다.\")\n",
        "         are_models_trained = False\n",
        "    else: # embedding_dims is defined\n",
        "        are_models_trained = False # Initialize flag\n",
        "\n",
        "        if is_data_ready_for_training:\n",
        "            print(\"\\n모델별 분류기 구축, 학습 및 평가 진행 중...\")\n",
        "\n",
        "            # Iterate through models that have prepared data (using one-hot encoded data availability)\n",
        "            models_to_process_keys = [name for name, data in y_train_one_hot.items() if data.size > 0]\n",
        "\n",
        "            if not models_to_process_keys:\n",
        "                print(\"경고: 훈련 데이터가 준비된 모델이 없습니다. 학습/평가를 건너뜁니다.\")\n",
        "\n",
        "            for model_name in models_to_process_keys:\n",
        "                print(f\"\\n--- {model_name} 모델 처리 중 ---\")\n",
        "\n",
        "                # Check if all necessary data for training and evaluation exists and is not empty for this specific model\n",
        "                # These checks should align with the validation in build_and_train_classifier and evaluate_and_visualize_model\n",
        "                if model_name in X_train_embeddings and X_train_embeddings[model_name] and \\\n",
        "                   model_name in y_train_one_hot and y_train_one_hot[model_name].size > 0 and \\\n",
        "                   model_name in X_test_embeddings and X_test_embeddings[model_name] and \\\n",
        "                   model_name in y_test_one_hot and y_test_one_hot[model_name].size > 0 and \\\n",
        "                   model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and \\\n",
        "                   model_name in y_test_encoded_filtered and y_test_encoded_filtered[model_name].size > 0 and \\\n",
        "                   model_name in embedding_dims and 'num_classes' in locals() and num_classes >= 2 and \\\n",
        "                   'label_encoder' in locals() and label_encoder is not None:\n",
        "\n",
        "                    # Get embedding dimension for the current model\n",
        "                    embedding_dim = embedding_dims[model_name]\n",
        "                    print(f\"  {model_name} 임베딩 차원: {embedding_dim}\")\n",
        "\n",
        "                    # Build the classifier model\n",
        "                    classifier_model = build_classifier_model(\n",
        "                         input_shape=embedding_dim,\n",
        "                         num_classes=num_classes,\n",
        "                         learning_rate=0.001 # Define learning rate\n",
        "                    )\n",
        "\n",
        "                    # Create batch generators for training and evaluation\n",
        "                    train_data_generator = batch_generator(X_train_embeddings[model_name])\n",
        "                    test_data_generator = batch_generator(X_test_embeddings[model_name])\n",
        "\n",
        "                    # Calculate steps per epoch for training and validation\n",
        "                    # Sum of samples in all batches / batch size used during training\n",
        "                    # NOTE: This assumes the batch size used in training (train_model) is the same as EMBEDDING_EXTRACTION_BATCH_SIZE\n",
        "                    # If not, this calculation needs adjustment.\n",
        "                    # A simpler approach is to pass the generator directly without steps_per_epoch if the generator handles epochs.\n",
        "                    # However, Keras fit with generator often requires steps_per_epoch.\n",
        "                    # Let's assume training batch size is EMBEDDING_EXTRACTION_BATCH_SIZE for now for simplicity.\n",
        "                    total_train_samples = y_train_filtered[model_name].shape[0]\n",
        "                    total_test_samples = y_test_filtered[model_name].shape[0]\n",
        "\n",
        "                    # Ensure steps are at least 1 if there are samples\n",
        "                    train_steps_per_epoch = max(1, total_train_samples // EMBEDDING_EXTRACTION_BATCH_SIZE)\n",
        "                    test_steps = max(1, total_test_samples // EMBEDDING_EXTRACTION_BATCH_SIZE) # For evaluation\n",
        "\n",
        "                    # If total samples are less than batch size, steps_per_epoch will be 0, need to handle this\n",
        "                    if total_train_samples > 0 and train_steps_per_epoch == 0:\n",
        "                         train_steps_per_epoch = 1\n",
        "                    if total_test_samples > 0 and test_steps == 0:\n",
        "                         test_steps = 1\n",
        "\n",
        "\n",
        "                    # Train the classifier model using the batch generator\n",
        "                    print(f\"\\n  --- {model_name} 모델 학습 (배치 제너레이터 사용) ---\")\n",
        "                    # EarlyStopping 및 ReduceLROnPlateau 콜백 설정 (from train_model function)\n",
        "                    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "                    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.000001)\n",
        "                    callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "                    try:\n",
        "                         # Use model.fit directly with the generator\n",
        "                         # Ensure generators are not empty before fitting\n",
        "                         if total_train_samples > 0 and total_test_samples > 0:\n",
        "                             history = classifier_model.fit(\n",
        "                                 train_data_generator,\n",
        "                                 steps_per_epoch=train_steps_per_epoch,\n",
        "                                 epochs=50, # Define epochs\n",
        "                                 validation_data=test_data_generator,\n",
        "                                 validation_steps=test_steps,\n",
        "                                 callbacks=callbacks,\n",
        "                                 verbose=1\n",
        "                             )\n",
        "                             print(f\"  {model_name} 모델 학습 완료.\")\n",
        "                             trained_models[model_name] = classifier_model\n",
        "                             training_histories[model_name] = history\n",
        "                             are_models_trained = True # Set flag to True if at least one model trained\n",
        "\n",
        "                             # Evaluate the model using the batch generator\n",
        "                             print(f\"\\n  --- {model_name} 모델 평가 (배치 제너레이터 사용) ---\")\n",
        "                             # The evaluate_and_visualize_model function currently expects NumPy arrays.\n",
        "                             # We need to modify evaluate_and_visualize_model or adapt the call here.\n",
        "                             # Adapting the call here is more consistent with applying changes *here*.\n",
        "\n",
        "                             # Re-implementing evaluation logic here to use generator\n",
        "                             print(\"\\n  예측 수행 및 리포트 생성...\")\n",
        "                             try:\n",
        "                                 # Predict in batches using the generator\n",
        "                                 # Create a new generator for predict\n",
        "                                 test_generator_for_predict = batch_generator(X_test_embeddings[model_name])\n",
        "                                 # Ensure generator is not empty\n",
        "                                 if total_test_samples > 0:\n",
        "                                      y_pred_probs = classifier_model.predict(test_generator_for_predict, steps=test_steps)\n",
        "                                      y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "                                      # Use the pre-loaded filtered test labels for the report and matrix\n",
        "                                      y_true_filtered = y_test_encoded_filtered[model_name] # Use the filtered encoded labels\n",
        "\n",
        "                                      # Ensure the number of predictions matches the number of true labels\n",
        "                                      if len(y_pred) != len(y_true_filtered):\n",
        "                                           print(f\"경고: {model_name} 예측 결과 수({len(y_pred)})와 실제 레이블 수({len(y_true_filtered)})가 일치하지 않습니다. 평가 리포트/혼동 행렬 생략.\")\n",
        "                                           evaluation_metrics = {'loss': None, 'accuracy': None} # Cannot evaluate reliably\n",
        "                                      else:\n",
        "                                           print(\"\\n  분류 리포트:\")\n",
        "                                           # Use target_names from label_encoder if available and matches unique test labels\n",
        "                                           if label_encoder is not None and len(np.unique(y_true_filtered)) == num_classes:\n",
        "                                                print(classification_report(y_true_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "                                           else:\n",
        "                                                # Fallback without target names\n",
        "                                                print(classification_report(y_true_filtered, y_pred))\n",
        "                                                print(\"  경고: 레이블 인코더 또는 클래스 불일치로 인해 target_names를 사용할 수 없습니다.\")\n",
        "\n",
        "\n",
        "                                           # --- 혼동 행렬 시각화 ---\n",
        "                                           print(\"\\n  혼동 행렬 시각화:\")\n",
        "                                           # Ensure the unique classes in the filtered test data match the number of classes for the matrix size\n",
        "                                           unique_test_labels_filtered = np.unique(y_true_filtered)\n",
        "                                           if len(unique_test_labels_filtered) == num_classes:\n",
        "                                                # Ensure labels for confusion matrix calculation cover all unique predicted and true labels\n",
        "                                                all_possible_labels = np.unique(np.concatenate((y_true_filtered, y_pred)))\n",
        "                                                # If label_encoder is available, use its classes order for consistent matrix\n",
        "                                                if label_encoder is not None and hasattr(label_encoder, 'classes_'):\n",
        "                                                    labels_for_matrix = np.arange(len(label_encoder.classes_))\n",
        "                                                    # Filter labels_for_matrix to only include those present in y_true_filtered or y_pred for smaller datasets\n",
        "                                                    present_labels_in_data = np.unique(np.concatenate((y_true_filtered, y_pred))).tolist()\n",
        "                                                    labels_for_matrix = [l for l in labels_for_matrix if l in present_labels_in_data]\n",
        "\n",
        "                                                    cm = confusion_matrix(y_true_filtered, y_pred, labels=labels_for_matrix)\n",
        "\n",
        "                                                    plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix)))) # Adjust figure size\n",
        "                                                    # Use label_encoder classes for tick labels if available, filtered to present labels\n",
        "                                                    tick_labels = [label_encoder.classes_[i] for i in labels_for_matrix]\n",
        "                                                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                                                               xticklabels=tick_labels, yticklabels=tick_labels)\n",
        "                                                else:\n",
        "                                                     # Fallback without labels if label_encoder or classes don't match\n",
        "                                                     # Use unique labels from the data for matrix labels if label_encoder is not fully usable\n",
        "                                                     labels_for_matrix = np.unique(np.concatenate((y_true_filtered, y_pred)))\n",
        "                                                     cm = confusion_matrix(y_true_filtered, y_pred, labels=labels_for_matrix)\n",
        "                                                     plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix)))) # Adjust figure size\n",
        "                                                     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') # Fallback without labels\n",
        "                                                plt.xlabel('예측 레이블')\n",
        "                                                plt.ylabel('실제 레이블')\n",
        "                                                plt.title(f'{model_name} 혼동 행렬')\n",
        "                                                plt.show()\n",
        "                                           else:\n",
        "                                                print(\"  경고: 필터링된 테스트 데이터에 모든 클래스가 포함되지 않아 혼동 행렬을 생성할 수 없습니다.\")\n",
        "\n",
        "                                           # Evaluate model to get loss and accuracy\n",
        "                                           loss, accuracy = classifier_model.evaluate(test_data_generator, steps=test_steps, verbose=0)\n",
        "                                           evaluation_metrics = {'loss': loss, 'accuracy': accuracy}\n",
        "                                           print(f\"  테스트 세트 손실: {loss:.4f}\")\n",
        "                                           print(f\"  테스트 세트 정확도: {accuracy:.4f}\")\n",
        "                                 else:\n",
        "                                      print(\"경고: 테스트 샘플이 부족하여 예측/평가를 건너뜁니다.\")\n",
        "                                      evaluation_metrics = {'loss': None, 'accuracy': None}\n",
        "\n",
        "\n",
        "                             except Exception as e:\n",
        "                                 print(f\"  오류: {model_name} 모델 예측 또는 리포트 생성 중 오류 발생: {e}\")\n",
        "                                 evaluation_metrics = {'loss': None, 'accuracy': None} # Mark evaluation as failed\n",
        "\n",
        "\n",
        "                             evaluation_results[model_name] = evaluation_metrics # Store evaluation metrics\n",
        "\n",
        "                             # --- 학습 과정 시각화 ---\n",
        "                             print(\"\\n  학습 과정 시각화:\")\n",
        "                             if history is not None and hasattr(history, 'history'):\n",
        "                                 plt.figure(figsize=(12, 5))\n",
        "\n",
        "                                 # Accuracy plot\n",
        "                                 plt.subplot(1, 2, 1)\n",
        "                                 plt.plot(history.history.get('accuracy', []), label='훈련 정확도')\n",
        "                                 if 'val_accuracy' in history.history:\n",
        "                                      plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "                                 plt.xlabel('에폭')\n",
        "                                 plt.ylabel('정확도')\n",
        "                                 plt.title(f'{model_name} 훈련 및 검증 정확도')\n",
        "                                 plt.legend()\n",
        "\n",
        "                                 # Loss plot\n",
        "                                 plt.subplot(1, 2, 2)\n",
        "                                 plt.plot(history.history.get('loss', []), label='훈련 손실')\n",
        "                                 if 'val_loss' in history.history:\n",
        "                                      plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "                                 plt.xlabel('에폭')\n",
        "                                 plt.ylabel('손실')\n",
        "                                 plt.title(f'{model_name} 훈련 및 검증 손실')\n",
        "                                 plt.legend()\n",
        "\n",
        "                                 plt.show()\n",
        "                             else:\n",
        "                                 print(\"  경고: 학습 기록(history)이 없어 그래프를 그릴 수 없습니다.\")\n",
        "\n",
        "                         else: # total_train_samples <= 0 or total_test_samples <= 0\n",
        "                              print(\"경고: 훈련 또는 테스트 샘플이 부족하여 모델 학습/평가를 건너뜁니다.\")\n",
        "                              trained_models[model_name] = None\n",
        "                              training_histories[model_name] = None\n",
        "                              evaluation_results[model_name] = {'loss': None, 'accuracy': None} # Store None for metrics if skipped\n",
        "\n",
        "\n",
        "                    except Exception as e:\n",
        "                         print(f\"  오류: {model_name} 모델 학습 중 오류 발생: {e}\")\n",
        "                         trained_models[model_name] = None\n",
        "                         training_histories[model_name] = None\n",
        "                         evaluation_results[model_name] = {'loss': None, 'accuracy': None} # Store None for metrics if skipped\n",
        "\n",
        "\n",
        "                else:\n",
        "                    print(f\"경고: {model_name} 모델 학습/평가를 위한 데이터 또는 필수 변수가 부족합니다. 건너뜁니다.\")\n",
        "                    trained_models[model_name] = None\n",
        "                    training_histories[model_name] = None\n",
        "                    evaluation_results[model_name] = {'loss': None, 'accuracy': None} # Store None for metrics if skipped\n",
        "\n",
        "\n",
        "            print(\"\\n모델 구축, 학습 및 평가 실행 단계 완료.\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\n데이터 준비 실패로 모델 학습 및 평가를 건너뜁니다.\")\n",
        "            are_models_trained = False # Ensure flag is False if data not ready\n",
        "\n",
        "\n",
        "# --- Cleanup temporary embedding directory ---\n",
        "if temp_embedding_dir and os.path.exists(temp_embedding_dir):\n",
        "    print(f\"\\n임시 임베딩 디렉토리 삭제 중: {temp_embedding_dir}\")\n",
        "    try:\n",
        "        # Check if directory is empty before attempting removal (optional)\n",
        "        # if not os.listdir(temp_embedding_dir):\n",
        "        #      print(\"Debug: 임시 디렉토리가 비어 있습니다.\")\n",
        "        shutil.rmtree(temp_embedding_dir)\n",
        "        print(\"임시 디렉토리 삭제 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 임시 디렉토리 삭제 실패: {e}\")\n",
        "\n",
        "\n",
        "# --- 6. 모델 성능 비교 (요약) ---\n",
        "print(\"\\n6. 모델 성능 비교 (요약) 중...\")\n",
        "print(\"\\n--- 모델별 최종 성능 비교 ---\")\n",
        "if evaluation_results and any(metrics.get('accuracy') is not None for metrics in evaluation_results.values()):\n",
        "    # Sort results by accuracy (optional, but helps in comparison)\n",
        "    sorted_results = sorted(evaluation_results.items(), key=lambda item: item[1].get('accuracy') if item[1].get('accuracy') is not None else -1, reverse=True)\n",
        "\n",
        "    for model_name, metrics in sorted_results:\n",
        "        print(f\"  {model_name}:\")\n",
        "        print(f\"    테스트 손실: {metrics.get('loss'):.4f}\" if metrics.get('loss') is not None else \"    테스트 손실: N/A\")\n",
        "        print(f\"    테스트 정확도: {metrics.get('accuracy'):.4f}\" if metrics.get('accuracy') is not None else \"    테스트 정확도: N/A\")\n",
        "else:\n",
        "    print(\"평가 결과가 없어 모델 성능 비교를 수행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "# --- 7. 새로운 오디오 파일에 대한 예측 (예시) ---\n",
        "print(\"\\n7. 새로운 오디오 파일 예측 예시 중...\")\n",
        "print(\"\\n--- 새로운 오디오 파일 예측 예시 ---\")\n",
        "\n",
        "# Choose one of the trained models for prediction, e.g., the best performing one or YAMNet\n",
        "# If trained_models and any(model is not None for model in trained_models.values()): # Keep this check\n",
        "if any(model is not None for model in trained_models.values()): # Simplified check if any model was trained\n",
        "    # Choose the first successfully trained model for prediction example\n",
        "    model_to_predict_name = None\n",
        "    for name, model in trained_models.items():\n",
        "         if model is not None:\n",
        "              model_to_predict_name = name\n",
        "              break\n",
        "    model_to_predict = trained_models.get(model_to_predict_name) # Get the model object\n",
        "\n",
        "\n",
        "    if model_to_predict is not None:\n",
        "        print(f\"\\n예측에 사용할 모델: {model_to_predict_name}\")\n",
        "\n",
        "        # Need a sample audio file path for prediction\n",
        "        # Use the first path from the original combined list if available, or a dummy file\n",
        "        predict_audio_path = None\n",
        "\n",
        "        # Attempt to use the first path from the original combined list if it was populated\n",
        "        if 'all_audio_paths' in locals() and all_audio_paths:\n",
        "            predict_audio_path = all_audio_paths[0]\n",
        "            print(f\"예측을 위해 데이터셋에서 샘플 파일 선택: {predict_audio_path}\")\n",
        "        elif 'DEEPSHIP_BASE_PATH' in locals() and os.path.exists(os.path.join(DEEPSHIP_BASE_PATH, 'Cargo', '103.wav')): # Fallback to a known DeepShip file\n",
        "            predict_audio_path = os.path.join(DEEPSHIP_BASE_PATH, 'Cargo', '103.wav')\n",
        "            print(f\"예측을 위해 DeepShip에서 샘플 파일 선택: {predict_audio_path}\")\n",
        "        # Add other fallbacks here if needed\n",
        "\n",
        "        # Ensure the chosen model, label_encoder, and yamnet_model are available for prediction\n",
        "        # Need the original YAMNet model for preprocessing in predict_on_new_audio\n",
        "        if predict_audio_path and os.path.exists(predict_audio_path) and \\\n",
        "           model_to_predict is not None and \\\n",
        "           'label_encoder' in locals() and label_encoder is not None and \\\n",
        "           'loaded_models' in locals() and loaded_models.get('YAMNet') is not None:\n",
        "\n",
        "            # Ensure predict_on_new_audio is defined and available\n",
        "            if 'predict_on_new_audio' not in locals():\n",
        "                 print(\"오류: 'predict_on_new_audio' 함수가 정의되지 않았습니다. 예측을 건너뜁니다.\")\n",
        "            else:\n",
        "                # Call the predict_on_new_audio function\n",
        "                # Pass the original YAMNet model for preprocessing\n",
        "                predicted_label = predict_on_new_audio(model_to_predict, loaded_models.get('YAMNet'), label_encoder, predict_audio_path)\n",
        "                # The predicted label is printed inside the function\n",
        "\n",
        "        else:\n",
        "            print(\"\\n예측을 수행할 수 없습니다:\")\n",
        "            if not predict_audio_path or not os.path.exists(predict_audio_path):\n",
        "                 print(\"  예측할 오디오 파일을 찾을 수 없습니다.\")\n",
        "            if model_to_predict is None:\n",
        "                 print(f\"  학습된 '{model_to_predict_name}' 모델이 없습니다.\")\n",
        "            if 'label_encoder' not in locals() or label_encoder is None:\n",
        "                 print(\"  LabelEncoder가 없습니다.\")\n",
        "            if 'loaded_models' not in locals() or loaded_models.get('YAMNet') is not None:\n",
        "                 print(\"  YAMNet 모델이 없습니다 (예측 전처리용).\")\n",
        "\n",
        "else: # No models were trained\n",
        "    print(\"\\n학습된 모델이 없어 예측을 수행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\n모델별 전체 파이프라인 실행 및 결과 비교 단계 완료.\")\n",
        "\n",
        "# Subtask is completed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4d54c7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The refactoring process successfully defined functions for initial setup, data loading/preparation, audio preprocessing/embedding extraction, model loading, classifier building/training, evaluation/visualization, and prediction.\n",
        "*   The data loading and preparation step (`load_and_prepare_dataset`) was executed but failed to collect any audio files from either the cloned DeepShip directory or the specified MBARI noise data directory.\n",
        "*   This lack of data (0 samples collected, 0 classes identified) prevented the subsequent steps of embedding extraction, label one-hot encoding, model training, and evaluation from executing, as designed by the implemented data availability checks.\n",
        "*   The pipeline correctly identified the data insufficiency and skipped the computationally intensive steps.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Critical Data Acquisition:** The most critical next step is to acquire the necessary audio data. This includes:\n",
        "    *   Verifying the structure of the cloned DeepShip repository (`/content/DeepShip`) to understand why the `load_and_prepare_dataset` function is not finding the `.wav` files within the expected class subdirectories. Manual inspection of the `/content/DeepShip` directory contents might be necessary.\n",
        "    *   Acquiring a substantial amount of MBARI noise data (or other relevant noise data) and placing it in the designated `MBARI_NOISE_BASE_DIR` (`/content/MBARI_noise_data`). The previous attempts to download sample files were not sufficient or successful in populating this directory with enough noise data.\n",
        "*   **Re-run Pipeline:** Once sufficient data for both 'ship' and 'noise' classes (at least 2 samples per class for stratified splitting) is placed in the correct directories, the entire pipeline (starting from Step 6 which executes data loading, embedding, training, evaluation) needs to be re-executed. The existing code is designed to handle the process once data is available.\n",
        "*   **Review Data Loading Logic:** If DeepShip files are still not found after verifying the directory structure, the `load_and_prepare_dataset` function's DeepShip traversal logic may need further debugging or adjustment based on the actual file paths."
      ]
    }
  ]
}