{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "SONAR3.ipynb",
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyNIJOKA8wyLtCKPhjX2ElOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEOUL-ABSS/SHIPSHIP/blob/main/SONAR3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ceae40"
      },
      "source": [
        "## 1. 환경 설정 및 필수 라이브러리 임포트\n",
        "\n",
        "프로젝트에 필요한 라이브러리를 설치/임포트하고, 전역 상수 및 기본 설정을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16f4c6a",
        "outputId": "5bf89d60-798b-4149-d4e0-889c2ae4e278"
      },
      "source": [
        "# Install tensorflow\n",
        "!pip install -q tensorflow tensorflow-hub soundfile librosa\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. 환경 설정 및 필수 라이브러리 임포트\n",
        "# ==============================================================================\n",
        "print(\"1. 환경 설정 및 라이브러리 임포트 중...\")\n",
        "\n",
        "# 필요한 라이브러리 임포트\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import soundfile as sf # WAV 파일 처리용\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.font_manager as fm # 폰트 관리자 임포트\n",
        "import requests # MBARI 데이터 다운로드용\n",
        "import subprocess # 오프라인 환경 패키지 다운로드용 (선택 사항)\n",
        "# from tensorflow_addons.optimizers import RectifiedAdam # 예시: TFA 옵티마이저 사용 시\n",
        "\n",
        "print(\"라이브러리 임포트 완료.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# Matplotlib 한글 폰트 설정 (오류 수정 및 안정화)\n",
        "# ==============================================================================\n",
        "print(\"\\nMatplotlib 한글 폰트 설정 중...\")\n",
        "\n",
        "# Colab 환경에서 나눔고딕 폰트 설치 및 설정 시도\n",
        "# 설치 오류 방지를 위해 출력을 숨깁니다.\n",
        "!sudo apt-get update > /dev/null # Ensure apt cache is updated\n",
        "!sudo apt-get install -y fonts-nanum > /dev/null\n",
        "!sudo fc-cache -fv > /dev_null\n",
        "\n",
        "# 폰트 관리자 캐시 재로드 및 폰트 설정\n",
        "try:\n",
        "    # 나눔고딕 폰트 파일 경로 (Colab에 일반적으로 설치되는 위치)\n",
        "    font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "    if os.path.exists(font_path):\n",
        "        fm.fontManager.addfont(font_path)\n",
        "        plt.rc('font', family='NanumGothic') # 나눔고딕으로 설정\n",
        "        plt.rcParams['axes.unicode_minus'] = False # 마이너스 기호 깨짐 방지\n",
        "        print(\"Matplotlib 폰트 설정 완료: NanumGothic\")\n",
        "    else:\n",
        "        print(f\"경고: 폰트 파일 '{font_path}'를 찾을 수 없습니다. 기본 폰트를 사용합니다.\")\n",
        "except Exception as e:\n",
        "    print(f\"Matplotlib 폰트 설정 중 오류 발생: {e}. 기본 폰트를 사용합니다.\")\n",
        "\n",
        "print(\"Matplotlib 폰트 설정 완료.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 전역 상수 정의\n",
        "# ==============================================================================\n",
        "print(\"\\n전역 상수 정의 중...\")\n",
        "YAMNET_SAMPLE_RATE = 16000\n",
        "YAMNET_EMBEDDING_DIM = 1024 # YAMNet embedding dimension\n",
        "\n",
        "# VGGish embedding dimension (usually 128)\n",
        "# Based on TF Hub documentation for vggish/1, the output is 128-dimensional.\n",
        "VGGISH_EMBEDDING_DIM = 128\n",
        "\n",
        "# PANNs embedding dimension (using YAMNet placeholder for now)\n",
        "# If using a real PANNs model, this dimension would need to be updated based on the model's output.\n",
        "PANNS_EMBEDDING_DIM = YAMNET_EMBEDDING_DIM # Placeholder dimension, assuming similar output shape to YAMNet placeholder\n",
        "\n",
        "# Dataset Paths\n",
        "DEEPSHIP_BASE_PATH = '/content/DeepShip'\n",
        "# Directory where MBARI Noise Data will be stored.\n",
        "# Assuming this directory will contain .wav files acting as 'noise'.\n",
        "MBARI_NOISE_BASE_DIR = '/content/MBARI_noise_data'\n",
        "\n",
        "# List of DeepShip ship classes\n",
        "DEEPSHIP_CLASSES = ['Cargo', 'Passengership', 'Tanker', 'Tug']\n",
        "\n",
        "# List of models to process for comparison\n",
        "MODELS_TO_PROCESS = ['YAMNet', 'PANNs', 'VGGish'] # Use 'PANNs' as the key for the placeholder\n",
        "\n",
        "print(\"전역 상수 정의 완료.\")\n",
        "\n",
        "import os\n",
        "\n",
        "# Assuming DEEPSHIP_BASE_PATH and MBARI_NOISE_BASE_DIR are defined\n",
        "\n",
        "print(\"\\nDeepShip 데이터 디렉토리 내용 확인:\")\n",
        "if os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    print(f\"'{DEEPSHIP_BASE_PATH}' 내용:\")\n",
        "    # List contents of the DeepShip base directory, focusing on the expected class folders\n",
        "    expected_deepship_subdirs = DEEPSHIP_CLASSES # Use the global constant\n",
        "    found_content = False\n",
        "    for item in os.listdir(DEEPSHIP_BASE_PATH):\n",
        "        item_path = os.path.join(DEEPSHIP_BASE_PATH, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"  {item}/\")\n",
        "            # If it's an expected class directory, list some of its contents\n",
        "            if item in expected_deepship_subdirs:\n",
        "                 try:\n",
        "                     files_in_class_dir = os.listdir(item_path)\n",
        "                     print(f\"    ({len(files_in_class_dir)} items)\")\n",
        "                     for f in files_in_class_dir[:5]: # List up to 5 files\n",
        "                         print(f\"      {f}\")\n",
        "                     if len(files_in_class_dir) > 5:\n",
        "                         print(\"      ...\")\n",
        "                     found_content = True\n",
        "                 except Exception as e:\n",
        "                      print(f\"    오류: 디렉토리 내용 확인 중 오류 발생: {e}\")\n",
        "            else:\n",
        "                 # List contents of unexpected subdirectories briefly\n",
        "                 try:\n",
        "                      sub_items = os.listdir(item_path)\n",
        "                      print(f\"    ({len(sub_items)} items)\")\n",
        "                      for f in sub_items[:3]: # List up to 3 items in other subdirs\n",
        "                          print(f\"      {f}\")\n",
        "                      if len(sub_items) > 3:\n",
        "                          print(\"      ...\")\n",
        "                 except Exception as e:\n",
        "                      print(f\"    오류: 디렉토리 내용 확인 중 오류 발생: {e}\")\n",
        "\n",
        "        elif os.path.isfile(item_path):\n",
        "            print(f\"  {item}\")\n",
        "            found_content = True\n",
        "\n",
        "    if not found_content:\n",
        "        print(\"  (디렉토리가 비어 있습니다)\")\n",
        "\n",
        "else:\n",
        "    print(f\"경고: DeepShip Base Path '{DEEPSHIP_BASE_PATH}'를 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\nMBARI 노이즈 데이터 디렉토리 내용 확인:\")\n",
        "if os.path.exists(MBARI_NOISE_BASE_DIR):\n",
        "    print(f\"'{MBARI_NOISE_BASE_DIR}' 내용:\")\n",
        "    found_noise_content = False\n",
        "    for root, dirs, files in os.walk(MBARI_NOISE_BASE_DIR):\n",
        "        level = root.replace(MBARI_NOISE_BASE_DIR, '').count(os.sep)\n",
        "        indent = '  ' * level\n",
        "        print(f'{indent}{os.path.basename(root)}/')\n",
        "        subindent = '  ' * (level + 1)\n",
        "        if dirs:\n",
        "             for d in dirs[:5]: # List up to 5 subdirectories\n",
        "                  print(f'{subindent}{d}/')\n",
        "             if len(dirs) > 5:\n",
        "                  print(f'{subindent}...')\n",
        "\n",
        "        if files:\n",
        "             print(f'{subindent}파일들 ({len(files)}개):')\n",
        "             for f in files[:5]: # List up to 5 files\n",
        "                 print(f'{subindent}{f}')\n",
        "                 if f.endswith('.wav'):\n",
        "                      found_noise_content = True # Found at least one wav file\n",
        "             if len(files) > 5:\n",
        "                  print(f'{subindent}...')\n",
        "        if not dirs and not files:\n",
        "             print(f'{subindent}(비어 있음)')\n",
        "\n",
        "\n",
        "    if not found_noise_content:\n",
        "        print(\"\\n경고: MBARI 노이즈 데이터 디렉토리에서 .wav 파일을 찾지 못했습니다.\")\n",
        "\n",
        "else:\n",
        "    print(f\"경고: MBARI Noise Base Directory '{MBARI_NOISE_BASE_DIR}'를 찾을 수 없습니다.\")\n",
        "\n",
        "print(\"\\n데이터 디렉토리 내용 확인 완료.\")\n",
        "\n",
        "# Install boto3 for S3 access\n",
        "!pip install -q boto3\n",
        "print(\"boto3 설치 완료.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. 환경 설정 및 라이브러리 임포트 중...\n",
            "라이브러리 임포트 완료.\n",
            "\n",
            "Matplotlib 한글 폰트 설정 중...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Matplotlib 폰트 설정 완료: NanumGothic\n",
            "Matplotlib 폰트 설정 완료.\n",
            "\n",
            "전역 상수 정의 중...\n",
            "전역 상수 정의 완료.\n",
            "\n",
            "DeepShip 데이터 디렉토리 내용 확인:\n",
            "'/content/DeepShip' 내용:\n",
            "  Tug/\n",
            "    (4 items)\n",
            "      40.wav\n",
            "      9.wav\n",
            "      49.wav\n",
            "      tug-metafile\n",
            "  Passengership/\n",
            "    (21 items)\n",
            "      27.wav\n",
            "      23.wav\n",
            "      1.wav\n",
            "      50.wav\n",
            "      17.wav\n",
            "      ...\n",
            "  Cargo/\n",
            "    (13 items)\n",
            "      27.wav\n",
            "      78.wav\n",
            "      110.wav\n",
            "      cargo-metafile\n",
            "      38.wav\n",
            "      ...\n",
            "  Tanker/\n",
            "    (29 items)\n",
            "      19.wav\n",
            "      24.wav\n",
            "      50.wav\n",
            "      43.wav\n",
            "      47.wav\n",
            "      ...\n",
            "  .git/\n",
            "    (12 items)\n",
            "      logs\n",
            "      refs\n",
            "      objects\n",
            "      ...\n",
            "  README.txt\n",
            "\n",
            "MBARI 노이즈 데이터 디렉토리 내용 확인:\n",
            "'/content/MBARI_noise_data' 내용:\n",
            "MBARI_noise_data/\n",
            "  파일들 (12개):\n",
            "  MARS-20180109T000000Z-16kHz.wav\n",
            "  MARS-20180110T000000Z-16kHz.wav\n",
            "  MARS-20180102T000000Z-16kHz.wav\n",
            "  MARS-20180111T000000Z-16kHz.wav\n",
            "  MARS-20180105T000000Z-16kHz.wav\n",
            "  ...\n",
            "\n",
            "데이터 디렉토리 내용 확인 완료.\n",
            "boto3 설치 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45088e0e"
      },
      "source": [
        "## 2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비\n",
        "\n",
        "DeepShip 데이터셋을 클론하고, MBARI 노이즈 데이터 디렉토리를 준비합니다. 이전에 다운로드된 MBARI 노이즈 샘플 파일이 있다면 해당 디렉토리로 이동시킵니다.\n",
        "\n",
        "**주의**: 실제 MBARI Pacific Sound 16kHz 데이터셋은 직접 다운로드 또는 접근 설정이 필요할 수 있습니다. 아래 코드는 DeepShip 클론 및 샘플 노이즈 파일 처리를 위한 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b99722d3",
        "outputId": "6b6fb777-5fe0-4079-a8e3-970a6db2a5b3"
      },
      "source": [
        "# ==============================================================================\n",
        "# 2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 (MBARI 다운로드 포함)\n",
        "# ==============================================================================\n",
        "import boto3 # Ensure boto3 is imported\n",
        "from botocore import UNSIGNED # Ensure UNSIGNED config is imported\n",
        "from botocore.client import Config # Ensure Config is imported\n",
        "from pathlib import Path # Ensure Path is imported\n",
        "import io # Ensure io is imported for potential in-memory reads (though we're downloading)\n",
        "from six.moves.urllib.request import urlopen # Ensure urlopen is imported if still needed (less likely with direct S3 download)\n",
        "import os # Ensure os is imported\n",
        "import subprocess # Ensure subprocess is imported\n",
        "\n",
        "print(\"\\n2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 중...\")\n",
        "\n",
        "# Check if DeepShip is already cloned\n",
        "if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    print(f\"DeepShip 데이터셋 클론 중: {DEEPSHIP_BASE_PATH}\")\n",
        "    # Clone the DeepShip repository\n",
        "    # Use --depth 1 to clone only the latest commit, saving time and space\n",
        "    try:\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', 'https://github.com/irfankamboh/DeepShip.git', DEEPSHIP_BASE_PATH], check=True, capture_output=True)\n",
        "        print(\"DeepShip 데이터셋 클론 완료.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"오류: DeepShip 데이터셋 클론 실패: {e.stderr.decode()}\")\n",
        "        print(\"수동으로 https://github.com/irfankamboh/DeepShip.git 를 클론하거나 다운로드하여\")\n",
        "        print(f\"'{DEEPSHIP_BASE_PATH}' 경로에 위치시켜주세요.\")\n",
        "    except Exception as e:\n",
        "         print(f\"오류: DeepShip 데이터셋 클론 중 예기치 않은 오류 발생: {e}\")\n",
        "else:\n",
        "    print(f\"DeepShip 데이터셋이 이미 존재합니다: {DEEPSHIP_BASE_PATH}\")\n",
        "\n",
        "# Ensure the MBARI noise base directory exists\n",
        "os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "print(f\"MBARI 노이즈 데이터 디렉토리 확인/생성 완료: {MBARI_NOISE_BASE_DIR}\")\n",
        "\n",
        "# --- Check if MBARI Noise Data already exists ---\n",
        "# Count the number of .wav files in the MBARI_NOISE_BASE_DIR\n",
        "existing_noise_files = [f for f in os.listdir(MBARI_NOISE_BASE_DIR) if f.endswith('.wav')]\n",
        "\n",
        "if existing_noise_files:\n",
        "    print(f\"\\nMBARI 노이즈 데이터가 지정된 디렉토리('{MBARI_NOISE_BASE_DIR}')에 이미 존재합니다. 다운로드를 건너뜁니다. (발견된 .wav 파일 수: {len(existing_noise_files)})\")\n",
        "else:\n",
        "    # --- MBARI Noise Data Download ---\n",
        "    # Use Boto3 to access the public S3 bucket and download a limited number of files\n",
        "    # Based on the provided documentation example.\n",
        "    s3_client = boto3.client('s3',\n",
        "        aws_access_key_id='',\n",
        "        aws_secret_access_key='',\n",
        "        config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "    bucket = 'pacific-sound-16khz'\n",
        "    # Define a prefix to narrow down the files (e.g., a specific year and month)\n",
        "    # The documentation example uses '2018/01/'. Let's keep this or choose another if needed.\n",
        "    prefix = '2018/01/' # Using January 2018 data as example\n",
        "\n",
        "    # Limit the number of files to download to avoid excessive processing time and storage\n",
        "    MAX_NOISE_FILES_TO_DOWNLOAD = 10 # Set the limit to 10 as requested\n",
        "\n",
        "    print(f\"\\nMBARI 노이즈 데이터 다운로드 시도 중 (S3 버킷: {bucket}, Prefix: {prefix}, 최대 {MAX_NOISE_FILES_TO_DOWNLOAD} 파일):\")\n",
        "\n",
        "    try:\n",
        "        # List objects in the specified bucket and prefix, potentially in pages\n",
        "        paginator = s3_client.get_paginator('list_objects_v2')\n",
        "        pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
        "\n",
        "        downloaded_count = 0\n",
        "        found_any_objects = False # Track if any objects were found at all\n",
        "\n",
        "        for page in pages:\n",
        "            if 'Contents' in page:\n",
        "                found_any_objects = True\n",
        "                # print(f\"  페이지에서 {len(page['Contents'])}개의 파일 발견. 다운로드 가능한 .wav 파일 탐색 중...\") # Too verbose\n",
        "\n",
        "                for obj in page['Contents']:\n",
        "                    key = obj['Key']\n",
        "                    # Only download .wav files and avoid directories or empty files\n",
        "                    if key.endswith('.wav') and obj.get('Size', 0) > 0:\n",
        "                        # Construct the local file path to save within the MBARI_NOISE_BASE_DIR\n",
        "                        local_file_path = os.path.join(MBARI_NOISE_BASE_DIR, os.path.basename(key))\n",
        "\n",
        "                        # Check if the file already exists locally to avoid re-downloading\n",
        "                        if os.path.exists(local_file_path):\n",
        "                            # print(f\"    파일이 이미 존재합니다. 건너뜁니다: {os.path.basename(key)}\") # Too verbose\n",
        "                            pass # Skip if file already exists\n",
        "                        else:\n",
        "                            print(f\"    다운로드 중: {os.path.basename(key)}...\")\n",
        "                            try:\n",
        "                                s3_client.download_file(bucket, key, local_file_path)\n",
        "                                downloaded_count += 1\n",
        "                                print(f\"      다운로드 완료 ({downloaded_count}/{MAX_NOISE_FILES_TO_DOWNLOAD})\")\n",
        "                            except Exception as download_e:\n",
        "                                 print(f\"    오류: 파일 다운로드 실패 ({os.path.basename(key)}): {download_e}\")\n",
        "\n",
        "                        # Stop downloading once the limit is reached\n",
        "                        if downloaded_count >= MAX_NOISE_FILES_TO_DOWNLOAD:\n",
        "                            print(f\"\\n  최대 다운로드 파일 수({MAX_NOISE_FILES_TO_DOWNLOAD})에 도달했습니다. 다운로드를 중지합니다.\")\n",
        "                            break # Break from the inner loop (files in this page)\n",
        "\n",
        "                if downloaded_count >= MAX_NOISE_FILES_TO_DOWNLOAD:\n",
        "                     break # Break from the outer loop (pages)\n",
        "\n",
        "\n",
        "        if not found_any_objects:\n",
        "            print(f\"  경고: 지정된 Prefix '{prefix}'에서 파일을 찾을 수 없습니다.\")\n",
        "        elif downloaded_count == 0:\n",
        "             # response might not be defined if no objects were found at all\n",
        "             num_total_objects = 0\n",
        "             try:\n",
        "                  initial_response = s3_client.list_objects_v2(Bucket=bucket, Prefix=prefix, MaxKeys=1) # Check if any object exists\n",
        "                  if 'Contents' in initial_response:\n",
        "                       num_total_objects = len(initial_response['Contents']) # This is just the first page count if MaxKeys > 1, or just 1 if MaxKeys=1\n",
        "             except Exception:\n",
        "                  pass # Ignore error if listing fails\n",
        "\n",
        "             if num_total_objects > 0:\n",
        "                  print(f\"\\n  지정된 Prefix '{prefix}'에 파일이 존재하지만, 다운로드 가능한 .wav 파일을 찾지 못했거나 모두 건너뛰었습니다.\")\n",
        "             else:\n",
        "                  print(f\"\\n  지정된 Prefix '{prefix}'에 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "        print(f\"\\n총 {downloaded_count}개의 노이즈 .wav 파일을 다운로드했습니다.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: MBARI 노이즈 데이터 다운로드 중 오류 발생: {e}\")\n",
        "        print(\"S3 버킷 접근 권한, Prefix 설정, 또는 Boto3 설정/설치를 확인해주세요.\")\n",
        "\n",
        "\n",
        "# Note: To get sufficient noise data for meaningful training, you may need to adjust the 'prefix'\n",
        "# or 'MAX_NOISE_FILES_TO_DOWNLOAD', or implement more complex logic to gather data from multiple\n",
        "# prefixes/months, depending on your data needs and the S3 bucket structure.\n",
        "# Ensure that the downloaded data includes enough samples from the 'noise' category.\n",
        "\n",
        "\n",
        "print(\"\\n2. 데이터 확보 단계 완료.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 중...\n",
            "DeepShip 데이터셋이 이미 존재합니다: /content/DeepShip\n",
            "MBARI 노이즈 데이터 디렉토리 확인/생성 완료: /content/MBARI_noise_data\n",
            "\n",
            "MBARI 노이즈 데이터가 지정된 디렉토리('/content/MBARI_noise_data')에 이미 존재합니다. 다운로드를 건너뜁니다. (발견된 .wav 파일 수: 12)\n",
            "\n",
            "2. 데이터 확보 단계 완료.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6181734b"
      },
      "source": [
        "## 3. 데이터 로드 및 준비 함수 정의\n",
        "\n",
        "DeepShip 데이터와 노이즈 데이터를 수집하고, 'ship' 및 'noise' 레이블을 할당하며, 훈련 및 테스트 세트로 분할하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9386cf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming DEEPSHIP_BASE_PATH, MBARI_NOISE_BASE_DIR, DEEPSHIP_CLASSES are defined in previous cells.\n",
        "\n",
        "def load_and_prepare_dataset(deepship_path, noise_data_dir, deepship_classes, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    DeepShip 데이터셋과 노이즈 데이터를 로드하고 이진 분류(ship vs noise)를 위해 준비합니다.\n",
        "\n",
        "    Args:\n",
        "        deepship_path (str): DeepShip 데이터셋의 기본 경로.\n",
        "        noise_data_dir (str): 노이즈 오디오 파일이 있는 디렉토리 경로.\n",
        "        deepship_classes (list): DeepShip 데이터셋의 선박 클래스 이름 목록.\n",
        "        test_size (float): 테스트 세트의 비율.\n",
        "        random_state (int): 데이터 분할을 위한 랜덤 시드.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths)\n",
        "               데이터 로드 및 준비 상태에 따라 결과가 달라질 수 있습니다.\n",
        "               데이터 부족 시 X_train/test_paths, y_train/test_encoded는 빈 리스트/NumPy 배열이 됩니다.\n",
        "               noise_audio_paths는 수집된 노이즈 파일 경로 목록입니다.\n",
        "    \"\"\"\n",
        "    all_audio_paths = []\n",
        "    all_labels = []\n",
        "    noise_audio_paths = [] # List to store noise file paths for augmentation\n",
        "    is_data_prepared = False\n",
        "    label_encoder = None\n",
        "    num_classes = 0\n",
        "\n",
        "    print(\"\\n데이터셋 로드 및 준비 시작: Ship vs Noise\")\n",
        "    print(f\"DeepShip Base Path: {deepship_path}\")\n",
        "    print(f\"MBARI Noise Data Directory: {noise_data_dir}\")\n",
        "\n",
        "    # --- 1. Integrate DeepShip Data ('ship') ---\n",
        "    is_deepship_available = os.path.exists(deepship_path)\n",
        "    if is_deepship_available:\n",
        "        print(f\"DeepShip 데이터셋에서 'ship' 오디오 파일 수집 중: {deepship_path}\")\n",
        "        found_ship_files = False\n",
        "        # CORRECTED: Iterate directly through the class subdirectories at the top level of DeepShip\n",
        "        for class_name in deepship_classes: # Use the provided deepship_classes list\n",
        "            class_path = os.path.join(deepship_path, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                print(f\"  클래스 폴더 발견: {class_path} -> Class: {class_name}\")\n",
        "                for file_name in os.listdir(class_path):\n",
        "                    if file_name.endswith('.wav'):\n",
        "                        audio_path = os.path.join(class_path, file_name)\n",
        "                        all_audio_paths.append(audio_path)\n",
        "                        all_labels.append('ship') # Label all DeepShip ship types as 'ship'\n",
        "                        found_ship_files = True\n",
        "            else:\n",
        "                 print(f\"  경고: 예상 클래스 폴더 '{class_name}'를 '{deepship_path}'에서 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "        if not found_ship_files:\n",
        "            print(f\"경고: '{deepship_path}' 내의 예상 클래스 폴더에서 'ship'으로 사용할 .wav 파일을 찾지 못했습니다. DeepShip 데이터셋 구조를 확인하세요.\")\n",
        "    else:\n",
        "        print(f\"경고: DeepShip 데이터셋을 찾을 수 없어 'ship' 데이터 수집을 건너뜁니다: {deepship_path}\")\n",
        "\n",
        "\n",
        "    # --- 2. Integrate Noise Data ('noise') ---\n",
        "    is_noise_data_available_dir = os.path.exists(noise_data_dir)\n",
        "    if is_noise_data_available_dir:\n",
        "        print(f\"노이즈 데이터 수집 중: {noise_data_dir}\")\n",
        "        found_noise_files = False\n",
        "        # Collect all .wav files under the noise data directory\n",
        "        for root, _, files in os.walk(noise_data_dir):\n",
        "             # Exclude the DeepShip directory itself if it was downloaded into the noise dir by mistake\n",
        "             if root.startswith(deepship_path):\n",
        "                  continue\n",
        "             for file_name in files:\n",
        "                 if file_name.endswith('.wav'):\n",
        "                     audio_path = os.path.join(root, file_name)\n",
        "                     # Ensure we don't duplicate paths if DeepShip and downloaded DeepShip point to the same files\n",
        "                     if audio_path not in all_audio_paths: # Avoid adding DeepShip files if they somehow ended up here\n",
        "                         all_audio_paths.append(audio_path)\n",
        "                         all_labels.append('noise') # 모든 노이즈 데이터를 'noise'로 레이블링\n",
        "                         noise_audio_paths.append(audio_path) # Also add to noise_audio_paths for augmentation\n",
        "                         found_noise_files = True\n",
        "\n",
        "        if not found_noise_files:\n",
        "            print(f\"경고: '{noise_data_dir}'에서 'noise'로 사용할 .wav 파일을 찾지 못했습니다.\")\n",
        "    else:\n",
        "        print(f\"경고: 노이즈 데이터 디렉토리 '{noise_data_dir}'를 찾을 수 없어 'noise' 데이터 수집을 건너뜁니다.\")\n",
        "        print(\"실제 노이즈 데이터를 다운로드하여 이 디렉토리에 위치시켜주세요.\")\n",
        "\n",
        "\n",
        "    # --- 3. Data Preparation and Split ---\n",
        "    unique_labels = np.unique(all_labels)\n",
        "\n",
        "    # Check if data for both 'ship' and 'noise' classes is available and sufficient\n",
        "    # We need at least 2 classes and some data for each class to perform a stratified split\n",
        "    if len(all_audio_paths) > 0 and len(unique_labels) >= 2:\n",
        "        # Check if each unique label has at least 2 samples for stratified split\n",
        "        label_counts = pd.Series(all_labels).value_counts()\n",
        "        if all(count >= 2 for count in label_counts):\n",
        "            print(f\"\\n데이터 수집 완료. 총 샘플 수: {len(all_audio_paths)}\")\n",
        "            print(f\"클래스 분포: {label_counts.to_dict()}\")\n",
        "\n",
        "            # 레이블 인코딩 ('ship', 'noise' 등 -> 0, 1 등)\n",
        "            label_encoder = LabelEncoder()\n",
        "            encoded_labels = label_encoder.fit_transform(all_labels)\n",
        "            num_classes = len(label_encoder.classes_)\n",
        "            print(f\"레이블 인코딩 완료. 클래스: {label_encoder.classes_}, 총 {num_classes}개\")\n",
        "\n",
        "            # 데이터셋 분할 (훈련 및 테스트) - Stratified split으로 클래스 비율 유지\n",
        "            X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = train_test_split(\n",
        "                all_audio_paths, encoded_labels, test_size=test_size, random_state=random_state, stratify=encoded_labels\n",
        "            )\n",
        "\n",
        "            print(f\"데이터 분할 완료.\")\n",
        "            print(f\"훈련 데이터 샘플 수: {len(X_train_paths)}\")\n",
        "            print(f\"테스트 데이터 샘플 수: {len(X_test_paths)}\")\n",
        "            is_data_prepared = True # 데이터 준비 성공 플래그\n",
        "\n",
        "        else:\n",
        "             print(\"\\n오류: 각 클래스별 샘플 수가 부족하여 데이터 분할(stratified split)을 수행할 수 없습니다.\")\n",
        "             print(f\"클래스별 샘플 수: {label_counts.to_dict()}\")\n",
        "             is_data_prepared = False\n",
        "             X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = [], [], np.array([]), np.array([])\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\"\\n오류: 'ship'과 'noise' 이진 분류를 위한 데이터가 충분하지 않습니다.\")\n",
        "        print(f\"수집된 총 샘플 수: {len(all_audio_paths)}, 확인된 클래스: {unique_labels}\")\n",
        "        print(\"DeepShip 데이터셋이 올바르게 클론되었는지, 노이즈 데이터가 '{noise_data_dir}'에 충분히 있는지 확인해주세요.\")\n",
        "        is_data_prepared = False\n",
        "        X_train_paths, X_test_paths, y_train_encoded, y_test_encoded = [], [], np.array([]), np.array([])\n",
        "\n",
        "\n",
        "    print(\"\\n데이터셋 로드 및 준비 함수 정의 완료.\")\n",
        "\n",
        "    # Return values regardless of success, check is_data_prepared flag later\n",
        "    # Also return noise_audio_paths for potential augmentation\n",
        "    return X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7be3e41"
      },
      "source": [
        "## 4. 오디오 전처리 및 임베딩 추출 함수 정의\n",
        "\n",
        "각 오디오 모델(YAMNet, PANNs, VGGish)에 대한 오디오 전처리 및 임베딩 추출 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "617c87ca",
        "outputId": "c21b8730-cfa4-4e89-8ae0-f05f456b3186"
      },
      "source": [
        "import tensorflow as tf # Ensure tf is imported\n",
        "import tensorflow_hub as hub # Ensure hub is imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "import soundfile as sf # Ensure soundfile is imported\n",
        "import librosa # Ensure librosa is imported\n",
        "import os # Ensure os is imported if needed within functions\n",
        "import random # Import random for selecting noise file\n",
        "\n",
        "print(\"\\n4. 오디오 전처리 및 임베딩 추출 함수 정의 중 (데이터 증강 포함)...\")\n",
        "\n",
        "# Assuming YAMNET_SAMPLE_RATE is defined in previous cells (should be 16000)\n",
        "# Assuming global variables like noise_audio_paths (list of paths to noise files)\n",
        "# will be available for data augmentation, or passed as an argument.\n",
        "# For this modification, we assume noise_audio_paths is available in the scope where extract_embedding is called.\n",
        "\n",
        "# Helper function for basic audio loading and resampling to a target sample rate\n",
        "def load_and_resample_audio(audio_path, target_sample_rate):\n",
        "    \"\"\"오디오 파일을 로드하고 지정된 샘플링 레이트로 리샘플링합니다.\"\"\"\n",
        "    try:\n",
        "        # soundfile.read returns waveform and sample rate\n",
        "        waveform, sr = sf.read(audio_path, dtype='float32')\n",
        "        if sr != target_sample_rate:\n",
        "            # Resample if sample rate doesn't match\n",
        "            # Use 'soxr_vq' backend for potentially faster resampling\n",
        "            # CORRECTED: Removed invalid res_type='soxr_vq'\n",
        "            waveform = librosa.resample(y=waveform, orig_sr=sr, target_sr=target_sample_rate)\n",
        "        if waveform.ndim > 1:\n",
        "            # Convert stereo to mono by averaging channels\n",
        "            waveform = np.mean(waveform, axis=1)\n",
        "        return waveform, target_sample_rate\n",
        "    except Exception as e:\n",
        "        # Print specific error for debugging\n",
        "        print(f\"오류: 오디오 파일 로드 및 리샘플링 실패 - {audio_path}, 오류: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "# --- Data Augmentation Function: Mixing Noise ---\n",
        "def mix_audio_with_noise(audio_waveform, audio_sr, noise_audio_paths, noise_level=0.1):\n",
        "    \"\"\"\n",
        "    주어진 오디오 파형에 랜덤한 노이즈 오디오를 섞습니다.\n",
        "\n",
        "    Args:\n",
        "        audio_waveform (np.ndarray): 원본 오디오 파형.\n",
        "        audio_sr (int): 원본 오디오 샘플링 레이트.\n",
        "        noise_audio_paths (list): 사용 가능한 노이즈 오디오 파일 경로 목록.\n",
        "        noise_level (float): 노이즈의 상대적인 볼륨 레벨 (0.0 to 1.0).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: 노이즈가 혼합된 오디오 파형, 또는 혼합 실패 시 원본 파형.\n",
        "    \"\"\"\n",
        "    if not noise_audio_paths:\n",
        "        # print(\"경고: 노이즈 오디오 파일 경로 목록이 비어 있어 노이즈 혼합을 수행할 수 없습니다.\")\n",
        "        return audio_waveform # Return original if no noise sources\n",
        "\n",
        "    try:\n",
        "        # Select a random noise file\n",
        "        random_noise_path = random.choice(noise_audio_paths)\n",
        "\n",
        "        # Load and resample noise audio to match the original audio's sample rate\n",
        "        noise_waveform, noise_sr = load_and_resample_audio(random_noise_path, audio_sr)\n",
        "\n",
        "        if noise_waveform is None or noise_sr != audio_sr:\n",
        "            # print(f\"경고: 노이즈 파일 로드 또는 리샘플링 실패 ({os.path.basename(random_noise_path)}). 노이즈 혼합 건너뜜.\")\n",
        "            return audio_waveform # Return original if noise loading fails\n",
        "\n",
        "        # Ensure noise waveform is at least as long as the audio waveform\n",
        "        if len(noise_waveform) < len(audio_waveform):\n",
        "            # Pad the noise or tile it to match the audio length\n",
        "            # Simple tiling for demonstration\n",
        "            tile_factor = (len(audio_waveform) // len(noise_waveform)) + 1\n",
        "            noise_waveform = np.tile(noise_waveform, tile_factor)\n",
        "            noise_waveform = noise_waveform[:len(audio_waveform)]\n",
        "        elif len(noise_waveform) > len(audio_waveform):\n",
        "            # Trim the noise to match the audio length\n",
        "            noise_waveform = noise_waveform[:len(audio_waveform)]\n",
        "\n",
        "\n",
        "        # Mix the audio and noise waveforms\n",
        "        # Normalize both signals to prevent clipping after mixing (optional but recommended)\n",
        "        # max_amp = max(np.max(np.abs(audio_waveform)), np.max(np.abs(noise_waveform)))\n",
        "        # if max_amp > 0:\n",
        "        #     audio_waveform /= max_amp\n",
        "        #     noise_waveform /= max_amp\n",
        "\n",
        "        mixed_waveform = audio_waveform + noise_level * noise_waveform\n",
        "\n",
        "        # Simple clipping to prevent values outside [-1, 1] range\n",
        "        mixed_waveform = np.clip(mixed_waveform, -1.0, 1.0)\n",
        "\n",
        "        return mixed_waveform\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 오디오와 노이즈 혼합 실패 - 오류: {e}\")\n",
        "        return audio_waveform # Return original on error\n",
        "\n",
        "\n",
        "# 1. Embedding Extraction for YAMNet (with optional augmentation)\n",
        "def extract_yamnet_embedding(audio_path, yamnet_model, target_sample_rate=YAMNET_SAMPLE_RATE,\n",
        "                             augment_with_noise=False, noise_audio_paths=None, noise_level=0.1):\n",
        "    \"\"\"오디오 파일을 YAMNet 입력에 맞춰 전처리하고 임베딩을 추출합니다 (데이터 증강 포함).\"\"\"\n",
        "    waveform, sr = load_and_resample_audio(audio_path, target_sample_rate)\n",
        "\n",
        "    if waveform is None or sr is None:\n",
        "        return None # Return None if basic loading/resampling failed\n",
        "\n",
        "    # --- Apply Data Augmentation (Noise Mixing) ---\n",
        "    if augment_with_noise and noise_audio_paths:\n",
        "        # print(f\"  {os.path.basename(audio_path)}에 노이즈 혼합 적용 중...\")\n",
        "        mixed_waveform = mix_audio_with_noise(waveform, sr, noise_audio_paths, noise_level)\n",
        "        waveform = mixed_waveform # Use the mixed waveform for embedding extraction\n",
        "\n",
        "\n",
        "    try:\n",
        "        # YAMNet model expects a tensor input\n",
        "        scores, embeddings, spectrogram = yamnet_model(tf.constant(waveform, dtype=tf.float32))\n",
        "        # Average frame-level embeddings to get a single embedding vector per audio file\n",
        "        mean_embedding = tf.reduce_mean(embeddings, axis=0)\n",
        "        return mean_embedding.numpy() # Return as NumPy array\n",
        "\n",
        "    except Exception as e:\n",
        "        # Print specific error for debugging\n",
        "        print(f\"오류: YAMNet 임베딩 추출 실패 - {audio_path}, 오류: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 2. Embedding Extraction for PANNs (using YAMNet placeholder, with optional augmentation)\n",
        "def extract_panns_embedding(audio_path, panns_model, target_sample_rate=YAMNET_SAMPLE_RATE,\n",
        "                            augment_with_noise=False, noise_audio_paths=None, noise_level=0.1):\n",
        "     \"\"\"오디오 파일을 PANNs 입력에 맞춰 전처리하고 임베딩을 추출합니다 (YAMNet 플레이스홀더 사용, 데이터 증강 포함).\"\"\"\n",
        "     # 이 함수는 PANNs 플레이스홀더(현재 YAMNet 사용)를 위한 임베딩 추출 함수입니다.\n",
        "     # 플레이스홀더 모델은 YAMNet과 동일하게 파형을 입력으로 받습니다.\n",
        "     # In a real scenario with a true PANNs model, this function would be adapted for its specific input/output.\n",
        "     # We still check for model existence before calling\n",
        "     if panns_model is None:\n",
        "         # print(f\"경고: PANNs 모델(플레이스홀더)이 로드되지 않았습니다. 임베딩 추출을 건너뜜: {audio_path}\")\n",
        "         return None\n",
        "\n",
        "     waveform, sr = load_and_resample_audio(audio_path, target_sample_rate)\n",
        "\n",
        "     if waveform is None or sr is None:\n",
        "        return None # Return None if basic loading/resampling failed\n",
        "\n",
        "     # --- Apply Data Augmentation (Noise Mixing) ---\n",
        "     if augment_with_noise and noise_audio_paths:\n",
        "         # print(f\"  {os.path.basename(audio_path)}에 노이즈 혼합 적용 중 (PANNs placeholder)...\")\n",
        "         mixed_waveform = mix_audio_with_noise(waveform, sr, noise_audio_paths, noise_level)\n",
        "         waveform = mixed_waveform # Use the mixed waveform for embedding extraction\n",
        "\n",
        "\n",
        "     try:\n",
        "        # PANNs placeholder (YAMNet) expects a tensor input\n",
        "        _, embeddings, _ = panns_model(tf.constant(waveform, dtype=tf.float32))\n",
        "        mean_embedding = tf.reduce_mean(embeddings, axis=0).numpy() # Average frame-level embeddings\n",
        "        return mean_embedding\n",
        "\n",
        "     except Exception as e:\n",
        "         print(f\"오류: PANNs 임베딩 추출 실패 - {audio_path}, 오류: {e}\")\n",
        "         return None\n",
        "\n",
        "\n",
        "# 3. Embedding Extraction for VGGish (with optional augmentation)\n",
        "# VGGish expects 16kHz mono float32 waveform and the model handles framing internally.\n",
        "def extract_vggish_embedding(audio_path, vggish_model, target_sample_rate=YAMNET_SAMPLE_RATE):\n",
        "    \"\"\"오디오 파일을 VGGish 입력에 맞춰 전처리하고 임베딩을 추출합니다 (데이터 증강 미포함 - VGGish 특성 고려).\"\"\"\n",
        "    # VGGish는 YAMNet과 다소 다른 전처리 및 특징 추출 방식을 사용하므로,\n",
        "    # 간단한 오디오 파형 혼합 증강이 VGGish의 내부 스펙트로그램 계산 방식과 잘 맞지 않을 수 있습니다.\n",
        "    # VGGish에 대한 증강은 좀 더 복잡한 접근 방식이 필요할 수 있으므로 여기서는 제외합니다.\n",
        "    # 또는 오디오 파형 자체에 노이즈를 섞은 후 VGGish 입력으로 사용할 수도 있습니다.\n",
        "    # 현재 코드는 YAMNet과 PANNs 플레이스홀더에만 노이즈 혼합 증강을 적용합니다.\n",
        "\n",
        "    waveform, sr = load_and_resample_audio(audio_path, target_sample_rate)\n",
        "\n",
        "    if vggish_model is None:\n",
        "        # print(f\"경고: VGGish 모델이 로드되지 않았습니다. 임베딩 추출을 건너뜜: {audio_path}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    if waveform is None or sr is None:\n",
        "        return None # Return None if basic loading/resampling failed\n",
        "\n",
        "    try:\n",
        "        # VGGish model directly handles the framing and embedding extraction from the waveform.\n",
        "        # The model returns frame-level embeddings.\n",
        "        embeddings = vggish_model(tf.constant(waveform, dtype=tf.float32))\n",
        "        # For classification, we typically average the frame embeddings\n",
        "        mean_embedding = tf.reduce_mean(embeddings, axis=0).numpy()\n",
        "        return mean_embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: VGGish 임베딩 추출 실패 - {audio_path}, 오류: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"오디오 전처리 및 임베딩 추출 함수 정의 완료 (데이터 증강 기능 포함).\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "4. 오디오 전처리 및 임베딩 추출 함수 정의 중 (데이터 증강 포함)...\n",
            "오디오 전처리 및 임베딩 추출 함수 정의 완료 (데이터 증강 기능 포함).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82bd8653"
      },
      "source": [
        "## 5. 오디오 모델 로드 함수 정의\n",
        "\n",
        "전이 학습에 사용할 YAMNet, PANNs, VGGish 사전 학습 모델을 TensorFlow Hub에서 로드하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "646d6907",
        "outputId": "9386ff8b-9473-4919-d570-21386edac33f"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf # Ensure tensorflow is imported for model loading\n",
        "\n",
        "print(\"\\n5. 오디오 모델 로드 함수 정의 중...\")\n",
        "\n",
        "# Define the TensorFlow Hub handles for the models.\n",
        "# Using the global constants defined in Step 1\n",
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "vggish_model_handle = 'https://tfhub.dev/google/vggish/1'\n",
        "# Using the YAMNet handle as a placeholder for PANNs as per previous discussion.\n",
        "panns_model_handle = 'https://tfhub.dev/google/yamnet/1' # Using YAMNet as placeholder for PANNs\n",
        "\n",
        "def load_audio_models():\n",
        "    \"\"\"\n",
        "    TensorFlow Hub에서 YAMNet, PANNs, VGGish 모델을 로드합니다.\n",
        "\n",
        "    Returns:\n",
        "        dict: 로드된 모델 객체를 담고 있는 딕셔너리.\n",
        "              모델 로드 실패 시 해당 모델 이름에 대해 값은 None이 됩니다.\n",
        "    \"\"\"\n",
        "    models = {}\n",
        "    are_models_loaded_successfully = True\n",
        "\n",
        "    print(\"\\n오디오 모델 로드 중...\")\n",
        "\n",
        "    # Load YAMNet\n",
        "    try:\n",
        "        print(\"  YAMNet 모델 로드 중...\")\n",
        "        models['YAMNet'] = hub.load(yamnet_model_handle)\n",
        "        print(\"  YAMNet 모델 로드 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: YAMNet 모델 로드 중 오류 발생: {e}\")\n",
        "        models['YAMNet'] = None # Set to None if loading fails\n",
        "        are_models_loaded_successfully = False\n",
        "\n",
        "    # Load PANNs (Placeholder)\n",
        "    try:\n",
        "        print(\"  PANNs 모델 로드 중 (YAMNet 플레이스홀더 사용)...\")\n",
        "        models['PANNs'] = hub.load(panns_model_handle)\n",
        "        print(\"  PANNs 모델 로드 완료 (YAMNet 플레이스홀더).\")\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: PANNs 모델 로드 중 오류 발생: {e}\")\n",
        "        models['PANNs'] = None # Set to None if loading fails\n",
        "        are_models_loaded_successfully = False\n",
        "\n",
        "\n",
        "    # Load VGGish\n",
        "    try:\n",
        "        print(\"  VGGish 모델 로드 중...\")\n",
        "        models['VGGish'] = hub.load(vggish_model_handle)\n",
        "        print(\"  VGGish 모델 로드 완료.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: VGGish 모델 로드 중 오류 발생: {e}\")\n",
        "        models['VGGish'] = None # Set to None if loading fails\n",
        "        are_models_loaded_successfully = False\n",
        "\n",
        "    # Check if at least one model loaded successfully\n",
        "    if all(model is None for model in models.values()):\n",
        "        print(\"오류: 모든 오디오 모델 로드에 실패했습니다.\")\n",
        "        are_models_loaded_successfully = False # Ensure this is False if all failed\n",
        "    else:\n",
        "         print(\"모델 로드 상태:\")\n",
        "         for name, model in models.items():\n",
        "             status = \"Loaded\" if model else \"Failed\"\n",
        "             print(f\"  {name}: {status}\")\n",
        "\n",
        "\n",
        "    print(\"\\n오디오 모델 로드 함수 정의 완료.\")\n",
        "\n",
        "    # Return the dictionary of models. The caller must check for None values.\n",
        "    return models, are_models_loaded_successfully\n",
        "\n",
        "# Example usage (will be called in a later cell):\n",
        "# loaded_models, are_models_loaded = load_audio_models()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. 오디오 모델 로드 함수 정의 중...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98da7922"
      },
      "source": [
        "## 6. 데이터 로드, 임베딩 추출 및 데이터 준비 실행\n",
        "\n",
        "정의된 함수들을 사용하여 데이터셋을 로드하고, 각 모델별로 임베딩을 추출하며, 훈련 및 테스트를 위한 최종 데이터셋(임베딩 및 레이블)을 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "62888c74",
        "outputId": "dd8a5f22-b6d8-479d-8f8f-1929253a5367"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Ensure tf is imported for constant conversion and one-hot encoding\n",
        "\n",
        "# Assuming load_and_prepare_dataset, extract_yamnet_embedding, extract_panns_embedding, extract_vggish_embedding,\n",
        "# load_audio_models, YAMNET_SAMPLE_RATE, YAMNET_EMBEDDING_DIM, VGGISH_EMBEDDING_DIM, PANNS_EMBEDDING_DIM,\n",
        "# DEEPSHIP_BASE_PATH, MBARI_NOISE_BASE_DIR, DEEPSHIP_CLASSES are defined and available from previous cells.\n",
        "\n",
        "\n",
        "# --- 1. Load and Prepare Dataset Paths and Labels ---\n",
        "# This calls the function defined in Step 3\n",
        "# Ensure load_and_prepare_dataset is defined and available\n",
        "if 'load_and_prepare_dataset' not in locals():\n",
        "    print(\"오류: 'load_and_prepare_dataset' 함수가 정의되지 않았습니다. 데이터 로드 및 준비를 건너뜀.\")\n",
        "    X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes = [], [], np.array([]), np.array([]), None, False, 0\n",
        "else:\n",
        "    X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes = load_and_prepare_dataset(\n",
        "        deepship_path=DEEPSHIP_BASE_PATH,\n",
        "        noise_data_dir=MBARI_NOISE_BASE_DIR,\n",
        "        deepship_classes=DEEPSHIP_CLASSES # Pass the global constant\n",
        "    )\n",
        "\n",
        "\n",
        "# --- 2. Load Audio Models ---\n",
        "# This calls the function defined in Step 5\n",
        "# Ensure load_audio_models is defined and available\n",
        "if 'load_audio_models' not in locals():\n",
        "     print(\"오류: 'load_audio_models' 함수가 정의되지 않았습니다. 모델 로드를 건너뜀.\")\n",
        "     loaded_models, are_models_loaded = {}, False\n",
        "else:\n",
        "    loaded_models, are_models_loaded = load_audio_models()\n",
        "\n",
        "# --- 3. Model-wise Embedding Extraction and Data Filtering ---\n",
        "X_train_embeddings = {}\n",
        "X_test_embeddings = {}\n",
        "y_train_filtered = {} # Store encoded labels corresponding to successfully extracted train embeddings\n",
        "y_test_filtered = {}  # Store encoded labels corresponding to successfully extracted test embeddings\n",
        "y_test_encoded_filtered = {} # Store encoded test labels filtered by successful embedding extraction for evaluation reports\n",
        "\n",
        "# Dictionary mapping model names to their loaded model object, embedding dimension, and extraction function\n",
        "# Ensure embedding dimension constants and extraction functions are defined and available\n",
        "models_info = {}\n",
        "if are_models_loaded: # Only populate models_info if models were loaded\n",
        "    if 'extract_yamnet_embedding' in locals() and 'YAMNET_EMBEDDING_DIM' in locals() and loaded_models.get('YAMNet') is not None:\n",
        "        models_info['YAMNet'] = {'model': loaded_models['YAMNet'], 'dim': YAMNET_EMBEDDING_DIM, 'extract_func': extract_yamnet_embedding}\n",
        "    else:\n",
        "        print(\"경고: YAMNet 모델 정보 또는 함수가 누락되었습니다. YAMNet 임베딩 추출을 건너뜁니다.\")\n",
        "    if 'extract_panns_embedding' in locals() and 'PANNS_EMBEDDING_DIM' in locals() and loaded_models.get('PANNs') is not None:\n",
        "        models_info['PANNs'] = {'model': loaded_models['PANNs'], 'dim': PANNS_EMBEDDING_DIM, 'extract_func': extract_panns_embedding}\n",
        "    else:\n",
        "         print(\"경고: PANNs 모델 정보 또는 함수가 누락되었습니다. PANNs 임베딩 추출을 건너뜁니다.\")\n",
        "    if 'extract_vggish_embedding' in locals() and 'VGGISH_EMBEDDING_DIM' in locals() and loaded_models.get('VGGish') is not None:\n",
        "        models_info['VGGish'] = {'model': loaded_models['VGGish'], 'dim': VGGISH_EMBEDDING_DIM, 'extract_func': extract_vggish_embedding}\n",
        "    else:\n",
        "         print(\"경고: VGGish 모델 정보 또는 함수가 누락되었습니다. VGGish 임베딩 추출을 건너뜁니다.\")\n",
        "\n",
        "\n",
        "# Flag to indicate if embeddings were successfully extracted for at least one model with sufficient data\n",
        "are_embeddings_extracted_successfully = False\n",
        "\n",
        "if is_data_prepared and are_models_loaded and models_info:\n",
        "    print(\"\\n모델별 임베딩 추출 시작 (시간이 오래 걸릴 수 있습니다)...\")\n",
        "\n",
        "    for model_name, info in models_info.items():\n",
        "        model = info['model']\n",
        "        extract_func = info['extract_func']\n",
        "        # embedding_dim = info['dim'] # Dim not needed here, used later for model building\n",
        "\n",
        "        # Check if the model loaded successfully for this specific model_name (already done in models_info population)\n",
        "        if model is None: # This case should be handled by not adding to models_info, but double check\n",
        "             print(f\"\\n--- {model_name} 모델 로드 실패. 임베딩 추출 건너뜀 (내부 오류). ---\")\n",
        "             continue\n",
        "\n",
        "        print(f\"\\n--- {model_name} 임베딩 추출 중 ---\")\n",
        "        train_embeddings_list = []\n",
        "        test_embeddings_list = []\n",
        "        train_labels_filtered_list = []\n",
        "        test_labels_filtered_list = []\n",
        "\n",
        "        # Process training data paths\n",
        "        print(\"  훈련 데이터 처리 중...\")\n",
        "        for i, path in enumerate(X_train_paths):\n",
        "            embedding = extract_func(path, model) # Pass the specific model object\n",
        "            if embedding is not None:\n",
        "                train_embeddings_list.append(embedding)\n",
        "                train_labels_filtered_list.append(y_train_encoded[i]) # Keep the original encoded label\n",
        "\n",
        "            if (i + 1) % 100 == 0: # Increased interval for less verbose output\n",
        "                print(f\"    {i+1}/{len(X_train_paths)} 훈련 파일 처리 완료.\")\n",
        "\n",
        "        # Process testing data paths\n",
        "        print(\"  테스트 데이터 처리 중...\")\n",
        "        for i, path in enumerate(X_test_paths):\n",
        "            embedding = extract_func(path, model) # Pass the specific model object\n",
        "            if embedding is not None:\n",
        "                test_embeddings_list.append(embedding)\n",
        "                test_labels_filtered_list.append(y_test_encoded[i]) # Keep the original encoded label\n",
        "\n",
        "            if (i + 1) % 50 == 0: # Increased interval for less verbose output\n",
        "                print(f\"    {i+1}/{len(X_test_paths)} 테스트 파일 처리 완료.\")\n",
        "\n",
        "\n",
        "        # Convert lists to NumPy arrays\n",
        "        X_train_embeddings[model_name] = np.array(train_embeddings_list)\n",
        "        X_test_embeddings[model_name] = np.array(test_embeddings_list)\n",
        "        y_train_filtered[model_name] = np.array(train_labels_filtered_list)\n",
        "        y_test_filtered[model_name] = np.array(test_labels_filtered_list)\n",
        "        y_test_encoded_filtered[model_name] = np.array(test_labels_filtered_list) # Store for evaluation reports\n",
        "\n",
        "\n",
        "        print(f\"\\n  {model_name} 임베딩 추출 및 필터링 완료.\")\n",
        "        print(f\"  훈련 임베딩 형태: {X_train_embeddings[model_name].shape}\")\n",
        "        print(f\"  훈련 레이블 형태: {y_train_filtered[model_name].shape}\")\n",
        "        print(f\"  테스트 임베딩 형태: {X_test_embeddings[model_name].shape}\")\n",
        "        print(f\"  테스트 레이블 형태: {y_test_filtered[model_name].shape}\")\n",
        "\n",
        "        # Check if embeddings were successfully extracted for this model with sufficient samples\n",
        "        # Need at least 2 samples for training/validation split implicitly in Keras fit\n",
        "        # And at least 2 classes in the filtered training data for training viability\n",
        "        if X_train_embeddings[model_name].shape[0] >= 2 and model_name in y_train_filtered and len(np.unique(y_train_filtered[model_name])) >= 2:\n",
        "            are_embeddings_extracted_successfully = True # Set flag to True if at least one model has data\n",
        "\n",
        "\n",
        "    print(\"\\n모델별 임베딩 추출 단계 완료.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 모델 로드, 또는 모델 정보 누락으로 임베딩 추출을 건너뜁니다.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Labels for Training (One-Hot Encoding) ---\n",
        "y_train_one_hot = {}\n",
        "y_test_one_hot = {}\n",
        "\n",
        "# Perform one-hot encoding only if embeddings were extracted successfully for at least one model\n",
        "# and if label_encoder and num_classes are available and valid from data preparation\n",
        "is_data_ready_for_training = False # Reset and determine based on one-hot encoding success\n",
        "\n",
        "if are_embeddings_extracted_successfully and 'label_encoder' in locals() and label_encoder is not None and 'num_classes' in locals() and num_classes >= 2:\n",
        "    print(\"\\n모델별 레이블 One-Hot 인코딩 시작...\")\n",
        "    all_models_encoded_successfully = True # Track if all models that had embeddings are encoded\n",
        "\n",
        "    for model_name in models_info.keys(): # Iterate through original model names that were intended to be processed\n",
        "        # Check if filtered labels exist and are not empty for this model, and have at least 2 classes\n",
        "        if model_name in y_train_filtered and y_train_filtered[model_name].size > 0 and len(np.unique(y_train_filtered[model_name])) >= 2 and \\\n",
        "           model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and len(np.unique(y_test_filtered[model_name])) >= 2:\n",
        "\n",
        "             print(f\"--- {model_name} 레이블 인코딩 중 ---\")\n",
        "             try:\n",
        "                 # One-hot Encode the filtered labels using the shared label_encoder\n",
        "                 y_train_one_hot[model_name] = tf.keras.utils.to_categorical(y_train_filtered[model_name], num_classes=num_classes)\n",
        "                 y_test_one_hot[model_name] = tf.keras.utils.to_categorical(y_test_filtered[model_name], num_classes=num_classes)\n",
        "                 print(f\"  {model_name} 훈련 레이블 형태 (One-Hot): {y_train_one_hot[model_name].shape}\")\n",
        "                 print(f\"  {model_name} 테스트 레이블 형태 (One-Hot): {y_test_one_hot[model_name].shape}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"  오 오류: {model_name} 레이블 One-Hot 인코딩 중 오류 발생: {e}\")\n",
        "                 # Initialize empty arrays if encoding fails\n",
        "                 y_train_one_hot[model_name] = np.array([])\n",
        "                 y_test_one_hot[model_name] = np.array([])\n",
        "                 all_models_encoded_successfully = False # Mark failure\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"  경고: {model_name}에 대한 필터링된 레이블이 부족하거나 클래스가 2개 미만이어서 One-Hot 인코딩을 건너뜁니다.\")\n",
        "            # Initialize empty arrays if filtered labels are missing or empty or insufficient classes\n",
        "            y_train_one_hot[model_name] = np.array([])\n",
        "            y_test_one_hot[model_name] = np.array([])\n",
        "            all_models_encoded_successfully = False # Mark failure\n",
        "\n",
        "\n",
        "    if all_models_encoded_successfully:\n",
        "         print(\"\\n모델별 레이블 One-Hot 인코딩 단계 완료.\")\n",
        "         is_data_ready_for_training = True # Set the flag to True if all intended models were encoded successfully\n",
        "    else:\n",
        "         print(\"\\n일부 모델의 레이블 One-Hot 인코딩 실패 또는 데이터 부족.\")\n",
        "         is_data_ready_for_training = False # Set the flag to False if any intended model failed encoding\n",
        "\n",
        "else:\n",
        "    print(\"\\n임베딩 추출 실패, 클래스 수 부족, 또는 label_encoder 누락으로 레이블 One-Hot 인코딩을 건너뜁니다.\")\n",
        "    is_data_ready_for_training = False # Set the flag to False\n",
        "\n",
        "\n",
        "if is_data_ready_for_training:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 성공.\")\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 실패: 훈련에 필요한 데이터가 부족합니다.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "데이터셋 로드 및 준비 시작: Ship vs Noise\n",
            "DeepShip Base Path: /content/DeepShip\n",
            "MBARI Noise Data Directory: /content/MBARI_noise_data\n",
            "DeepShip 데이터셋에서 'ship' 오디오 파일 수집 중: /content/DeepShip\n",
            "  클래스 폴더 발견: /content/DeepShip/Cargo -> Class: Cargo\n",
            "  클래스 폴더 발견: /content/DeepShip/Passengership -> Class: Passengership\n",
            "  클래스 폴더 발견: /content/DeepShip/Tanker -> Class: Tanker\n",
            "  클래스 폴더 발견: /content/DeepShip/Tug -> Class: Tug\n",
            "노이즈 데이터 수집 중: /content/MBARI_noise_data\n",
            "\n",
            "데이터 수집 완료. 총 샘플 수: 75\n",
            "클래스 분포: {'ship': 63, 'noise': 12}\n",
            "레이블 인코딩 완료. 클래스: ['noise' 'ship'], 총 2개\n",
            "데이터 분할 완료.\n",
            "훈련 데이터 샘플 수: 60\n",
            "테스트 데이터 샘플 수: 15\n",
            "\n",
            "데이터셋 로드 및 준비 함수 정의 완료.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 7)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-670158946.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mX_train_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_data_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes = load_and_prepare_dataset(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdeepship_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEEPSHIP_BASE_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnoise_data_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMBARI_NOISE_BASE_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 7)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e9acd0b"
      },
      "source": [
        "## 7. 모델 구축 및 학습 함수 정의\n",
        "\n",
        "각 모델에서 추출된 임베딩을 입력으로 받아 최종 분류를 수행하는 Keras 모델(분류 헤드)을 구축하고 학습시키는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "385c3e80"
      },
      "source": [
        "import tensorflow as tf # Ensure tf is imported\n",
        "from tensorflow.keras.models import Model # Ensure Model is imported\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout # Ensure layers are imported\n",
        "from tensorflow.keras.optimizers import Adam # Ensure Adam is imported\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau # Ensure callbacks are imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n7. 분류기 모델 구축 및 학습 함수 정의 중...\")\n",
        "\n",
        "def build_classifier_model(input_shape, num_classes, learning_rate=0.001):\n",
        "    \"\"\"\n",
        "    임베딩 입력을 위한 분류 헤드 Keras 모델을 구축하고 컴파일합니다.\n",
        "\n",
        "    Args:\n",
        "        input_shape (int): 입력 임베딩의 차원.\n",
        "        num_classes (int): 출력 클래스의 수 (이진 분류의 경우 2).\n",
        "        learning_rate (float): Adam 옵티마이저의 학습률.\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.keras.models.Model: 컴파일된 Keras 모델 객체.\n",
        "    \"\"\"\n",
        "    embedding_input = Input(shape=(input_shape,), name='embedding_input')\n",
        "\n",
        "    x = Dense(128, activation='relu')(embedding_input)\n",
        "    x = Dropout(0.4)(x) # Increased dropout for regularization\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.4)(x) # Increased dropout for regularization\n",
        "    # Output layer for binary classification (num_classes=2) or multi-class\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=embedding_input, outputs=output)\n",
        "\n",
        "    # Model compilation\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Use categorical_crossentropy loss for multi-class (including binary with 2 classes)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"  분류 헤드 모델 구축 및 컴파일 완료.\")\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, X_train, y_train_one_hot, X_test, y_test_one_hot,\n",
        "                               epochs=50, batch_size=16):\n",
        "    \"\"\"\n",
        "    주어진 데이터로 Keras 모델을 학습시킵니다.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.models.Model): 학습할 컴파일된 Keras 모델.\n",
        "        X_train (np.ndarray): 訓練 임베딩 데이터.\n",
        "        y_train_one_hot (np.ndarray): One-Hot 인코딩된 訓練 레이블.\n",
        "        X_test (np.ndarray): 테스트 임베딩 데이터 (검증에 사용).\n",
        "        y_test_one_hot (np.ndarray): One-Hot 인코딩된 테스트 레이블 (검증에 사용).\n",
        "        epochs (int): 학습 에폭 수.\n",
        "        batch_size (int): 배치 크기.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (trained_model, history) 학습된 모델 객체와 학습 기록.\n",
        "               データ不足またはエラー発生時 (None, None) 返還。\n",
        "    \"\"\"\n",
        "    print(\"\\n  모델 학습 시작...\")\n",
        "\n",
        "    # Data validation and sufficiency checks\n",
        "    if X_train.size == 0 or y_train_one_hot.size == 0 or X_test.size == 0 or y_test_one_hot.size == 0:\n",
        "        print(\"  경고: 분류기 학습을 위한 훈련 또는 테스트 데이터가 부족합니다. 학습을 건너뜁니다.\")\n",
        "        return None, None\n",
        "\n",
        "    if X_train.shape[0] < 2 or X_test.shape[0] < 2:\n",
        "        print(\"  경고: 분류기 학습을 위한 훈련 또는 테스트 데이터 샘플 수가 2개 미만입니다. 학습을 건너뜁니다.\")\n",
        "        return None, None\n",
        "\n",
        "    # Ensure there are at least 2 unique classes in the training labels\n",
        "    # np.unique(np.argmax(y_train_one_hot, axis=1)) gets the unique original encoded labels\n",
        "    if y_train_one_hot.ndim > 1 and len(np.unique(np.argmax(y_train_one_hot, axis=1))) < 2:\n",
        "         print(\"  경고: 분류기 학습을 위한 훈련 레이블에 클래스가 2개 미만입니다. 학습을 건너뜁니다.\")\n",
        "         return None, None\n",
        "    elif y_train_one_hot.ndim == 1 and len(np.unique(y_train_one_hot)) < 2: # Handle case where labels might not be one-hot yet (should be one-hot here)\n",
        "         print(\"  경고: 분류기 학습을 위한 훈련 레이블에 클래스가 2개 미만입니다 (One-Hot 인코딩 전 상태 확인). 학습을 건너뜁니다.\")\n",
        "         return None, None\n",
        "\n",
        "\n",
        "    # EarlyStopping 및 ReduceLROnPlateau 콜백 설정\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=0.000001)\n",
        "    callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "    # Model training\n",
        "    try:\n",
        "        history = model.fit(\n",
        "            X_train, y_train_one_hot,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_test, y_test_one_hot), # Use validation_data for test set evaluation during training\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "        print(\"  모델 학습 완료.\")\n",
        "        return model, history\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: 모델 학습 중 오류 발생: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "print(\"\\n모델 구축 및 학습 함수 정의 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23bdbafd"
      },
      "source": [
        "## 8. 모델 평가 및 결과 시각화 함수 정의\n",
        "\n",
        "학습된 모델의 성능을 테스트 데이터에 대해 평가하고, 분류 리포트, 혼동 행렬, 학습 곡선 등을 시각화하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf25291a"
      },
      "source": [
        "import matplotlib.pyplot as plt # Ensure matplotlib is imported\n",
        "import seaborn as sns # Ensure seaborn is imported\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Ensure sklearn metrics are imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n8. 모델 평가 및 결과 시각화 함수 정의 중...\")\n",
        "\n",
        "# Assuming necessary libraries (matplotlib, seaborn, sklearn.metrics, numpy) are imported.\n",
        "# Assuming label_encoder is available if evaluation is attempted.\n",
        "\n",
        "def evaluate_and_visualize_model(model_name, trained_model, X_test, y_test_one_hot, y_test_encoded_filtered,\n",
        "                                 label_encoder, history):\n",
        "    \"\"\"\n",
        "    학습된 모델의 성능을 평가하고 결과를 시각화합니다.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): 모델 이름 (예: 'YAMNet', 'VGGish').\n",
        "        trained_model (tf.keras.Model): 학습된 모델 객체.\n",
        "        X_test (np.ndarray): 테스트 임베딩 데이터.\n",
        "        y_test_one_hot (np.ndarray): One-Hot 인코딩된 테스트 레이블.\n",
        "        y_test_encoded_filtered (np.ndarray): 필터링된 실제 인코딩 레이블 (혼동 행렬, 리포트용).\n",
        "        label_encoder (sklearn.preprocessing.LabelEncoder): 레이블 인코더 객체.\n",
        "        history (tf.keras.callbacks.History): 모델 학습 기록.\n",
        "\n",
        "    Returns:\n",
        "        dict: 평가 결과를 담고 있는 딕셔너리 (loss, accuracy).\n",
        "              평가 실패 시 None 값을 가질 수 있습니다.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- {model_name} 모델 성능 평가 및 시각화 시작 ---\")\n",
        "    evaluation_metrics = {'loss': None, 'accuracy': None} # Initialize metrics dictionary\n",
        "\n",
        "    # --- 1. 데이터 및 모델 유효성 확인 ---\n",
        "    # Check if the model and data are valid and not empty\n",
        "    if trained_model is None:\n",
        "        print(f\"  경고: {model_name} 모델이 학습되지 않았습니다. 평가를 건너뜁니다.\")\n",
        "        return evaluation_metrics\n",
        "\n",
        "    if not isinstance(X_test, np.ndarray) or X_test.size == 0:\n",
        "        print(f\"  경고: {model_name} 모델의 테스트 임베딩 데이터가 유효하지 않거나 비어 있습니다. 평가를 건너뜁니다.\")\n",
        "        return evaluation_metrics\n",
        "\n",
        "    if not isinstance(y_test_one_hot, np.ndarray) or y_test_one_hot.size == 0:\n",
        "         print(f\"  경고: {model_name} 모델의 One-Hot 테스트 레이블이 유효하지 않거나 비어 있습니다. 평가를 건너뜁니다.\")\n",
        "         return evaluation_metrics\n",
        "\n",
        "    if not isinstance(y_test_encoded_filtered, np.ndarray) or y_test_encoded_filtered.size == 0:\n",
        "         print(f\"  경고: {model_name} 모델의 필터링된 실제 인코딩 레이블이 유효하지 않거나 비어 있습니다. 평가를 건너뜁니다.\")\n",
        "         return evaluation_metrics\n",
        "\n",
        "    if label_encoder is None:\n",
        "        print(f\"  경고: 레이블 인코더가 None입니다. 평가 리포트 및 혼동 행렬 레이블이 정확하지 않을 수 있습니다.\")\n",
        "        # Proceed with evaluation but without accurate labels\n",
        "\n",
        "    # Ensure there are at least 2 unique classes in the filtered test labels for meaningful evaluation\n",
        "    unique_test_labels = np.unique(y_test_encoded_filtered)\n",
        "    if len(unique_test_labels) < 2:\n",
        "         print(f\"  경고: 필터링된 테스트 데이터에 클래스가 2개 미만입니다 ({len(unique_test_labels)}개). 평가를 건너뜁니다.\")\n",
        "         return evaluation_metrics\n",
        "\n",
        "    # Determine the number of classes from the one-hot labels shape or label_encoder\n",
        "    num_classes = y_test_one_hot.shape[1] if y_test_one_hot.ndim > 1 else 1\n",
        "    if label_encoder is not None:\n",
        "        num_classes_from_encoder = len(label_encoder.classes_)\n",
        "        if num_classes != num_classes_from_encoder:\n",
        "             print(f\"  경고: One-Hot 레이블 형태와 LabelEncoder의 클래스 수가 일치하지 않습니다 ({num_classes} vs {num_classes_from_encoder}).\")\n",
        "             # Use the number from one-hot labels for consistency with model output\n",
        "             pass # Continue, using num_classes from one-hot shape\n",
        "\n",
        "\n",
        "    print(\"  데이터 및 모델 유효성 확인 완료. 평가 진행.\")\n",
        "\n",
        "    # --- 2. 모델 평가 ---\n",
        "    print(\"  테스트 데이터로 모델 평가...\")\n",
        "    try:\n",
        "        loss, accuracy = trained_model.evaluate(X_test, y_test_one_hot, verbose=0)\n",
        "        print(f\"  테스트 세트 손실: {loss:.4f}\")\n",
        "        print(f\"  테스트 세트 정확도: {accuracy:.4f}\")\n",
        "        evaluation_metrics['loss'] = loss\n",
        "        evaluation_metrics['accuracy'] = accuracy\n",
        "    except Exception as e:\n",
        "         print(f\"  오류: {model_name} 모델 평가 중 오류 발생: {e}\")\n",
        "         # Continue to prediction and reporting if evaluation fails but prediction might work\n",
        "\n",
        "\n",
        "    # --- 3. 예측 및 리포트 생성 ---\n",
        "    print(\"\\n  예측 수행 및 리포트 생성...\")\n",
        "    try:\n",
        "        y_pred_probs = trained_model.predict(X_test)\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "        print(\"\\n  분류 리포트:\")\n",
        "        # Use target_names from label_encoder if available and matches unique test labels\n",
        "        if label_encoder is not None and len(unique_test_labels) == num_classes:\n",
        "             print(classification_report(y_test_encoded_filtered, y_pred, target_names=label_encoder.classes_))\n",
        "        else:\n",
        "             # Fallback without target names\n",
        "             print(classification_report(y_test_encoded_filtered, y_pred))\n",
        "             print(\"  경고: 레이블 인코더 또는 클래스 불일치로 인해 target_names를 사용할 수 없습니다.\")\n",
        "\n",
        "\n",
        "        # --- 4. 혼동 행렬 시각화 ---\n",
        "        print(\"\\n  혼동 행렬 시각화:\")\n",
        "        # Ensure the unique classes in the filtered test data match the number of classes for the matrix size\n",
        "        if len(unique_test_labels) == num_classes:\n",
        "             # Ensure labels for confusion matrix calculation cover all unique predicted and true labels\n",
        "             all_possible_labels = np.unique(np.concatenate((y_test_encoded_filtered, y_pred)))\n",
        "             # If label_encoder is available, use its classes order for consistent matrix\n",
        "             if label_encoder is not None and hasattr(label_encoder, 'classes_'):\n",
        "                 labels_for_matrix = np.arange(len(label_encoder.classes_))\n",
        "                 # Filter labels_for_matrix to only include those present in y_test_encoded_filtered or y_pred for smaller datasets\n",
        "                 # This avoids plotting empty rows/columns if not all classes are in the test set (post-filtering)\n",
        "                 present_labels_in_data = np.unique(np.concatenate((y_test_encoded_filtered, y_pred))).tolist()\n",
        "                 labels_for_matrix = [l for l in labels_for_matrix if l in present_labels_in_data]\n",
        "\n",
        "                 cm = confusion_matrix(y_test_encoded_filtered, y_pred, labels=labels_for_matrix)\n",
        "\n",
        "                 plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix)))) # Adjust figure size based on num classes\n",
        "                 # Use label_encoder classes for tick labels if available, filtered to present labels\n",
        "                 tick_labels = [label_encoder.classes_[i] for i in labels_for_matrix]\n",
        "                 sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                            xticklabels=tick_labels, yticklabels=tick_labels)\n",
        "             else:\n",
        "                  # Fallback without labels if label_encoder or classes don't match\n",
        "                  # Use unique labels from the data for matrix labels if label_encoder is not fully usable\n",
        "                  labels_for_matrix = np.unique(np.concatenate((y_test_encoded_filtered, y_pred)))\n",
        "                  cm = confusion_matrix(y_test_encoded_filtered, y_pred, labels=labels_for_matrix)\n",
        "                  plt.figure(figsize=(max(6, len(labels_for_matrix)), max(5, len(labels_for_matrix)))) # Adjust figure size\n",
        "                  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues') # Fallback without labels\n",
        "             plt.xlabel('예측 레이블')\n",
        "             plt.ylabel('실제 레이블')\n",
        "             plt.title(f'{model_name} 혼동 행렬')\n",
        "             plt.show()\n",
        "        else:\n",
        "             print(\"  경고: 필터링된 테스트 데이터에 모든 클래스가 포함되지 않아 혼동 행렬을 생성할 수 없습니다.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  오류: {model_name} 모델 예측 또는 리포트 생성 중 오류 발생: {e}\")\n",
        "\n",
        "\n",
        "    # --- 5. 학습 과정 시각화 ---\n",
        "    print(\"\\n  학습 과정 시각화:\")\n",
        "    # Check if history object is valid and has the 'history' attribute\n",
        "    if history is not None and hasattr(history, 'history'):\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Accuracy plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history.get('accuracy', []), label='훈련 정확도') # Use .get() for safety\n",
        "        if 'val_accuracy' in history.history: # Check if validation accuracy exists\n",
        "             plt.plot(history.history['val_accuracy'], label='검증 정확도')\n",
        "        plt.xlabel('에폭')\n",
        "        plt.ylabel('정확도')\n",
        "        plt.title(f'{model_name} 훈련 및 검증 정확도')\n",
        "        plt.legend()\n",
        "\n",
        "        # Loss plot\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history.get('loss', []), label='훈련 손실') # Use .get() for safety\n",
        "        if 'val_loss' in history.history: # Check if validation loss exists\n",
        "             plt.plot(history.history['val_loss'], label='검증 손실')\n",
        "        plt.xlabel('에폭')\n",
        "        plt.ylabel('손실')\n",
        "        plt.title(f'{model_name} 훈련 및 검증 손실')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"  경고: 학습 기록(history)이 없어 그래프를 그릴 수 없습니다.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n--- {model_name} 모델 성능 평가 및 시각화 완료 ---\")\n",
        "    return evaluation_metrics # Return evaluation results\n",
        "\n",
        "\n",
        "print(\"\\n모델 평가 및 결과 시각화 함수 정의 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9868cc6"
      },
      "source": [
        "## 9. 예측 함수 정의\n",
        "\n",
        "학습된 모델을 사용하여 새로운 오디오 파일에 대한 예측을 수행하는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bfd471f"
      },
      "source": [
        "import os # Ensure os is imported\n",
        "import numpy as np # Ensure numpy is imported\n",
        "\n",
        "print(\"\\n9. 예측 함수 정의 중...\")\n",
        "\n",
        "def predict_on_new_audio(model, yamnet_model, label_encoder, audio_path):\n",
        "    \"\"\"\n",
        "    새로운 오디오 파일에 대해 학습된 모델로 예측을 수행합니다.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.models.Model): 예측에 사용할 학습된 Keras 모델.\n",
        "        yamnet_model: YAMNet 모델 객체 (오디오 전처리 및 임베딩 추출에 사용).\n",
        "        label_encoder (sklearn.preprocessing.LabelEncoder): 레이블 인코더 객체.\n",
        "        audio_path (str): 예측할 오디오 파일 경로.\n",
        "\n",
        "    Returns:\n",
        "        str: 예측된 레이블 문자열, 또는 예측 실패 시 None.\n",
        "    \"\"\"\n",
        "    print(f\"\\n새 오디오 파일('{os.path.basename(audio_path)}') 예측 시작...\")\n",
        "\n",
        "    if not os.path.exists(audio_path):\n",
        "        print(f\"오류: 예측할 오디오 파일을 찾을 수 없습니다: {audio_path}\")\n",
        "        return None\n",
        "\n",
        "    # Use the defined YAMNet embedding extraction function for preprocessing\n",
        "    # Ensure extract_yamnet_embedding is defined and available\n",
        "    if 'extract_yamnet_embedding' not in locals():\n",
        "        print(\"오류: 'extract_yamnet_embedding' 함수가 정의되지 않았습니다. 예측을 건너뜁니다.\")\n",
        "        return None\n",
        "\n",
        "    new_audio_embedding = extract_yamnet_embedding(audio_path, yamnet_model)\n",
        "\n",
        "    if new_audio_embedding is None:\n",
        "        print(\"새 오디오 파일 임베딩 추출에 실패했습니다.\")\n",
        "        return None\n",
        "\n",
        "    # Reshape the embedding to match the model's expected input shape (add batch dimension)\n",
        "    new_audio_embedding = np.expand_dims(new_audio_embedding, axis=0)\n",
        "\n",
        "    # Perform prediction\n",
        "    try:\n",
        "        prediction_probs = model.predict(new_audio_embedding)[0]\n",
        "        predicted_class_idx = np.argmax(prediction_probs)\n",
        "\n",
        "        # Convert predicted index back to label using the label encoder\n",
        "        if label_encoder is not None and hasattr(label_encoder, 'inverse_transform'):\n",
        "            predicted_label = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
        "        else:\n",
        "            print(\"경고: label_encoder가 없거나 inverse_transform 메서드를 사용할 수 없습니다. 예측된 인덱스만 반환합니다.\")\n",
        "            predicted_label = predicted_class_idx # Return index if label_encoder is not usable\n",
        "\n",
        "\n",
        "        print(f\"\\n예측 결과 for '{os.path.basename(audio_path)}':\")\n",
        "        if label_encoder is not None and hasattr(label_encoder, 'classes_'):\n",
        "            # Print probabilities for each class\n",
        "            for i, class_name in enumerate(label_encoder.classes_):\n",
        "                print(f\"  {class_name}: {prediction_probs[i]*100:.2f}%\")\n",
        "        else:\n",
        "             # Print probabilities by index if class names are not available\n",
        "             for i in range(len(prediction_probs)):\n",
        "                  print(f\"  Class {i} (Index {i}): {prediction_probs[i]*100:.2f}%\")\n",
        "\n",
        "        print(f\"최종 예측: {predicted_label}\")\n",
        "        return predicted_label\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류: 예측 수행 중 오류 발생: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"예측 함수 정의 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28d37bbf"
      },
      "source": [
        "## 10. 모델별 전체 파이프라인 실행 및 결과 비교\n",
        "\n",
        "정의된 함수들을 사용하여 각 모델(YAMNet, PANNs, VGGish)에 대해 데이터 준비(임베딩 추출 포함), 학습, 평가 과정을 순차적으로 실행하고, 최종 성능을 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e95caffe"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os # Ensure os is imported\n",
        "import matplotlib.pyplot as plt # Ensure matplotlib is imported\n",
        "import seaborn as sns # Ensure seaborn is imported\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Ensure sklearn metrics are imported\n",
        "import random # Ensure random is imported for augmentation\n",
        "\n",
        "\n",
        "print(\"\\n10. 모델별 전체 파이프라인 실행 및 결과 비교 시작...\")\n",
        "\n",
        "# --- 1. 데이터 로드 및 준비 ---\n",
        "# Calls the function defined in Step 3 (corrected version)\n",
        "# Ensure load_and_prepare_dataset is defined and available\n",
        "if 'load_and_prepare_dataset' not in locals():\n",
        "    print(\"오류: 'load_and_prepare_dataset' 함수가 정의되지 않았습니다. 파이프라인 실행을 중단합니다.\")\n",
        "    is_data_prepared = False\n",
        "    X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, num_classes, noise_audio_paths = [], [], np.array([]), np.array([]), None, 0, [] # Initialize noise_audio_paths\n",
        "else:\n",
        "    # Modified to also return noise_audio_paths\n",
        "    X_train_paths, X_test_paths, y_train_encoded, y_test_encoded, label_encoder, is_data_prepared, num_classes, noise_audio_paths = load_and_prepare_dataset(\n",
        "        deepship_path=DEEPSHIP_BASE_PATH,\n",
        "        noise_data_dir=MBARI_NOISE_BASE_DIR,\n",
        "        deepship_classes=DEEPSHIP_CLASSES # Pass the global constant\n",
        "    )\n",
        "\n",
        "# --- 2. 오디오 모델 로드 ---\n",
        "# Calls the function defined in Step 5\n",
        "# Ensure load_audio_models is defined and available\n",
        "if 'load_audio_models' not in locals():\n",
        "     print(\"오류: 'load_audio_models' 함수가 정의되지 않았습니다. 파이프라인 실행을 중단합니다.\")\n",
        "     are_models_loaded = False\n",
        "     loaded_models = {}\n",
        "else:\n",
        "    loaded_models, are_models_loaded = load_audio_models()\n",
        "\n",
        "\n",
        "# --- 3. 모델별 임베딩 추출 및 데이터 필터링 (배치 처리 및 증강 포함) ---\n",
        "X_train_embeddings = {}\n",
        "X_test_embeddings = {}\n",
        "y_train_filtered = {} # Store encoded labels corresponding to successfully extracted train embeddings\n",
        "y_test_filtered = {}  # Store encoded labels corresponding to successfully extracted test embeddings\n",
        "y_test_encoded_filtered = {} # Store encoded test labels filtered by successful embedding extraction for evaluation reports\n",
        "\n",
        "# Dictionary mapping model names to their loaded model object, embedding dimension, and extraction function\n",
        "# Ensure embedding dimension constants and extraction functions are defined and available\n",
        "models_info = {}\n",
        "if are_models_loaded: # Only populate models_info if models were loaded\n",
        "    if 'extract_yamnet_embedding' in locals() and 'YAMNET_EMBEDDING_DIM' in locals() and loaded_models.get('YAMNet') is not None:\n",
        "        models_info['YAMNet'] = {'model': loaded_models['YAMNet'], 'dim': YAMNET_EMBEDDING_DIM, 'extract_func': extract_yamnet_embedding}\n",
        "    else:\n",
        "        print(\"경고: YAMNet 모델 정보 또는 함수가 누락되었습니다. YAMNet 처리를 건너뜁니다.\")\n",
        "    if 'extract_panns_embedding' in locals() and 'PANNS_EMBEDDING_DIM' in locals() and loaded_models.get('PANNs') is not None:\n",
        "        models_info['PANNs'] = {'model': loaded_models['PANNs'], 'dim': PANNS_EMBEDDING_DIM, 'extract_func': extract_panns_embedding}\n",
        "    else:\n",
        "         print(\"경고: PANNs 모델 정보 또는 함수가 누락되었습니다. PANNs 처리를 건너뜁니다.\")\n",
        "    if 'extract_vggish_embedding' in locals() and 'VGGISH_EMBEDDING_DIM' in locals() and loaded_models.get('VGGish') is not None:\n",
        "        models_info['VGGish'] = {'model': loaded_models['VGGish'], 'dim': VGGISH_EMBEDDING_DIM, 'extract_func': extract_vggish_embedding}\n",
        "    else:\n",
        "         print(\"경고: VGGish 모델 정보 또는 함수가 누락되었습니다. VGGish 처리를 건너뜁니다.\")\n",
        "\n",
        "\n",
        "# Flag to indicate if embeddings were successfully extracted for at least one model with sufficient data\n",
        "are_embeddings_extracted_successfully = False\n",
        "\n",
        "# Define batch size for embedding extraction\n",
        "EMBEDDING_EXTRACTION_BATCH_SIZE = 32 # Adjust based on available RAM\n",
        "\n",
        "if is_data_prepared and are_models_loaded and models_info:\n",
        "    print(\"\\n모델별 임베딩 추출 시작 (배치 처리 및 증강 포함 - 시간이 오래 걸릴 수 있습니다)...\")\n",
        "\n",
        "    # Combine train and test paths and labels for easier iteration\n",
        "    all_paths = X_train_paths + X_test_paths\n",
        "    all_encoded_labels = list(y_train_encoded) + list(y_test_encoded)\n",
        "    split_indices = {'train': (0, len(X_train_paths)), 'test': (len(X_train_paths), len(all_paths))}\n",
        "\n",
        "\n",
        "    for model_name, info in models_info.items():\n",
        "        model = info['model']\n",
        "        extract_func = info['extract_func']\n",
        "\n",
        "        if model is None:\n",
        "             print(f\"\\n--- {model_name} 모델 로드 실패. 임베딩 추출 건너뜁니다. ---\")\n",
        "             # Initialize empty arrays for this model to avoid errors later\n",
        "             X_train_embeddings[model_name] = np.array([])\n",
        "             X_test_embeddings[model_name] = np.array([])\n",
        "             y_train_filtered[model_name] = np.array([])\n",
        "             y_test_filtered[model_name] = np.array([])\n",
        "             y_test_encoded_filtered[model_name] = np.array([]) # Also for evaluation reports\n",
        "             continue # Skip to the next model\n",
        "\n",
        "\n",
        "        print(f\"\\n--- {model_name} 임베딩 추출 중 ---\")\n",
        "        current_model_embeddings_list = []\n",
        "        current_model_labels_filtered_list = []\n",
        "\n",
        "\n",
        "        # Process all data in batches for embedding extraction\n",
        "        for i in range(0, len(all_paths), EMBEDDING_EXTRACTION_BATCH_SIZE):\n",
        "            batch_paths = all_paths[i:i + EMBEDDING_EXTRACTION_BATCH_SIZE]\n",
        "            batch_labels = all_encoded_labels[i:i + EMBEDDING_EXTRACTION_BATCH_SIZE]\n",
        "\n",
        "            print(f\"  처리 중: 배치 {i // EMBEDDING_EXTRACTION_BATCH_SIZE + 1} / {len(all_paths) // EMBEDDING_EXTRACTION_BATCH_SIZE + (1 if len(all_paths) % EMBEDDING_EXTRACTION_BATCH_SIZE > 0 else 0)}\")\n",
        "\n",
        "\n",
        "            for j, audio_path in enumerate(batch_paths):\n",
        "                 original_label_encoded = batch_labels[j]\n",
        "                 original_label_str = label_encoder.inverse_transform([original_label_encoded])[0] if label_encoder is not None and hasattr(label_encoder, 'inverse_transform') else str(original_label_encoded)\n",
        "\n",
        "\n",
        "                 # Apply augmentation (mix noise) only for 'ship' samples during training data processing\n",
        "                 # Check if this sample is originally from the training set\n",
        "                 is_training_sample = i + j < split_indices['train'][1]\n",
        "\n",
        "                 # Determine if augmentation should be applied\n",
        "                 # Apply augmentation if it's a training sample, the original label is 'ship', and noise data is available\n",
        "                 apply_augmentation = is_training_sample and original_label_str == 'ship' and noise_audio_paths\n",
        "\n",
        "                 # Extract embedding, potentially with augmentation\n",
        "                 # Pass noise_audio_paths to the extract function if augmentation is needed\n",
        "                 embedding = extract_func(\n",
        "                     audio_path,\n",
        "                     model,\n",
        "                     augment_with_noise=apply_augmentation,\n",
        "                     noise_audio_paths=noise_audio_paths,\n",
        "                     noise_level=0.1 # Define noise level\n",
        "                 )\n",
        "\n",
        "\n",
        "                 if embedding is not None:\n",
        "                    current_model_embeddings_list.append(embedding)\n",
        "                    current_model_labels_filtered_list.append(original_label_encoded) # Keep the original encoded label\n",
        "\n",
        "            # Optional: Add augmented samples for 'ship' class in training set\n",
        "            # This is a simple approach; more sophisticated augmentation strategies exist.\n",
        "            if is_training_sample and original_label_str == 'ship' and noise_audio_paths:\n",
        "                 # Augment the current batch of ship training samples\n",
        "                 for j, audio_path in enumerate(batch_paths):\n",
        "                     if label_encoder.inverse_transform([batch_labels[j]])[0] == 'ship':\n",
        "                         # Re-extract embedding with augmentation\n",
        "                         augmented_embedding = extract_func(\n",
        "                             audio_path,\n",
        "                             model,\n",
        "                             augment_with_noise=True, # Force augmentation\n",
        "                             noise_audio_paths=noise_audio_paths,\n",
        "                             noise_level=0.1 # Define noise level\n",
        "                         )\n",
        "                         if augmented_embedding is not None:\n",
        "                              current_model_embeddings_list.append(augmented_embedding)\n",
        "                              current_model_labels_filtered_list.append(batch_labels[j]) # Original label for augmented sample\n",
        "\n",
        "\n",
        "        # Convert list to NumPy array after processing all batches for this model\n",
        "        all_model_embeddings = np.array(current_model_embeddings_list)\n",
        "        all_model_labels_filtered = np.array(current_model_labels_filtered_list)\n",
        "\n",
        "        # Split the combined embeddings and labels back into train and test sets\n",
        "        # This requires re-splitting based on the original distribution or tracking which samples were original/augmented\n",
        "        # A simpler approach for demonstration is to re-split the combined filtered data\n",
        "        # However, this loses the original train/test split integrity if samples failed extraction or were augmented.\n",
        "        # A more robust approach would be to build train/test lists separately during batch processing.\n",
        "\n",
        "        # Let's rebuild train/test lists separately during batch processing for correctness\n",
        "        train_embeddings_list = []\n",
        "        test_embeddings_list = []\n",
        "        train_labels_filtered_list = []\n",
        "        test_labels_filtered_list = []\n",
        "\n",
        "\n",
        "        print(\"\\n  훈련 데이터 임베딩 추출 및 필터링 (재처리, 증강 포함)...\")\n",
        "        for i, path in enumerate(X_train_paths):\n",
        "            original_label_encoded = y_train_encoded[i]\n",
        "            original_label_str = label_encoder.inverse_transform([original_label_encoded])[0] if label_encoder is not None and hasattr(label_encoder, 'inverse_transform') else str(original_label_encoded)\n",
        "\n",
        "            # Extract original embedding\n",
        "            embedding = extract_func(path, model, augment_with_noise=False) # No augmentation for original samples\n",
        "\n",
        "            if embedding is not None:\n",
        "                 train_embeddings_list.append(embedding)\n",
        "                 train_labels_filtered_list.append(original_label_encoded)\n",
        "\n",
        "            # Add augmented samples for 'ship' class if noise data is available\n",
        "            if original_label_str == 'ship' and noise_audio_paths:\n",
        "                 augmented_embedding = extract_func(\n",
        "                      path,\n",
        "                      model,\n",
        "                      augment_with_noise=True, # Apply augmentation\n",
        "                      noise_audio_paths=noise_audio_paths,\n",
        "                      noise_level=0.1\n",
        "                 )\n",
        "                 if augmented_embedding is not None:\n",
        "                      train_embeddings_list.append(augmented_embedding)\n",
        "                      train_labels_filtered_list.append(original_label_encoded) # Augmented sample keeps original label\n",
        "\n",
        "\n",
        "            if (i + 1) % 50 == 0:\n",
        "                 print(f\"    {i+1}/{len(X_train_paths)} 훈련 파일 처리 완료 (증강 포함).\")\n",
        "\n",
        "\n",
        "        print(\"  테스트 데이터 임베딩 추출 및 필터링...\")\n",
        "        for i, path in enumerate(X_test_paths):\n",
        "            original_label_encoded = y_test_encoded[i]\n",
        "            # No augmentation for test samples\n",
        "            embedding = extract_func(path, model, augment_with_noise=False)\n",
        "\n",
        "            if embedding is not None:\n",
        "                test_embeddings_list.append(embedding)\n",
        "                test_labels_filtered_list.append(original_label_encoded)\n",
        "\n",
        "            if (i + 1) % 20 == 0:\n",
        "                print(f\"    {i+1}/{len(X_test_paths)} 테스트 파일 처리 완료.\")\n",
        "\n",
        "\n",
        "        # Convert lists to NumPy arrays\n",
        "        X_train_embeddings[model_name] = np.array(train_embeddings_list)\n",
        "        X_test_embeddings[model_name] = np.array(test_embeddings_list)\n",
        "        y_train_filtered[model_name] = np.array(train_labels_filtered_list)\n",
        "        y_test_filtered[model_name] = np.array(test_labels_filtered_list)\n",
        "        y_test_encoded_filtered[model_name] = np.array(test_labels_filtered_list) # Store for evaluation reports\n",
        "\n",
        "\n",
        "        print(f\"\\n  {model_name} 임베딩 추출 및 필터링 완료.\")\n",
        "        print(f\"  훈련 임베딩 형태 (증강 포함): {X_train_embeddings[model_name].shape}\")\n",
        "        print(f\"  훈련 레이블 형태 (증강 포함): {y_train_filtered[model_name].shape}\")\n",
        "        print(f\"  테스트 임베딩 형태: {X_test_embeddings[model_name].shape}\")\n",
        "        print(f\"  테스트 레이블 형태: {y_test_filtered[model_name].shape}\")\n",
        "\n",
        "        # Check if embeddings were successfully extracted for this model with sufficient samples\n",
        "        # Need at least 2 samples for training/validation split implicitly in Keras fit\n",
        "        # And at least 2 classes in the filtered training data for training viability\n",
        "        if X_train_embeddings[model_name].shape[0] >= 2 and model_name in y_train_filtered and len(np.unique(y_train_filtered[model_name])) >= 2:\n",
        "            are_embeddings_extracted_successfully = True # Set flag to True if at least one model has data\n",
        "\n",
        "\n",
        "    print(\"\\n모델별 임베딩 추출 단계 완료.\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 모델 로드, 또는 모델 정보 누락으로 임베딩 추출을 건너뜁니다.\")\n",
        "\n",
        "\n",
        "# --- 4. Prepare Labels for Training (One-Hot Encoding) ---\n",
        "y_train_one_hot = {}\n",
        "y_test_one_hot = {}\n",
        "\n",
        "# Perform one-hot encoding only if embeddings were extracted successfully for at least one model\n",
        "# and if label_encoder and num_classes are available and valid from data preparation\n",
        "is_data_ready_for_training = False # Reset and determine based on one-hot encoding success\n",
        "\n",
        "if are_embeddings_extracted_successfully and 'label_encoder' in locals() and label_encoder is not None and 'num_classes' in locals() and num_classes >= 2:\n",
        "    print(\"\\n모델별 레이블 One-Hot 인코딩 시작...\")\n",
        "    all_models_encoded_successfully = True # Track if all models that had embeddings are encoded\n",
        "\n",
        "    for model_name in models_info.keys(): # Iterate through original model names that were intended to be processed\n",
        "        # Check if filtered labels exist and are not empty for this model, and have at least 2 classes\n",
        "        if model_name in y_train_filtered and y_train_filtered[model_name].size > 0 and len(np.unique(y_train_filtered[model_name])) >= 2 and \\\n",
        "           model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and len(np.unique(y_test_filtered[model_name])) >= 2:\n",
        "\n",
        "             print(f\"--- {model_name} 레이블 인코딩 중 ---\")\n",
        "             try:\n",
        "                 # One-hot Encode the filtered labels using the shared label_encoder\n",
        "                 y_train_one_hot[model_name] = tf.keras.utils.to_categorical(y_train_filtered[model_name], num_classes=num_classes)\n",
        "                 y_test_one_hot[model_name] = tf.keras.utils.to_categorical(y_test_filtered[model_name], num_classes=num_classes)\n",
        "                 print(f\"  {model_name} 훈련 레이블 형태 (One-Hot): {y_train_one_hot[model_name].shape}\")\n",
        "                 print(f\"  {model_name} 테스트 레이블 형태 (One-Hot): {y_test_one_hot[model_name].shape}\")\n",
        "             except Exception as e:\n",
        "                 print(f\"  오 오류: {model_name} 레이블 One-Hot 인코딩 중 오류 발생: {e}\")\n",
        "                 # Initialize empty arrays if encoding fails\n",
        "                 y_train_one_hot[model_name] = np.array([])\n",
        "                 y_test_one_hot[model_name] = np.array([])\n",
        "                 all_models_encoded_successfully = False # Mark failure\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(f\"  경고: {model_name}에 대한 필터링된 레이블이 부족하거나 클래스가 2개 미만이어서 One-Hot 인코딩을 건너뜁니다.\")\n",
        "            # Initialize empty arrays if filtered labels are missing or empty or insufficient classes\n",
        "            y_train_one_hot[model_name] = np.array([])\n",
        "            y_test_one_hot[model_name] = np.array([])\n",
        "            all_models_encoded_successfully = False # Mark failure\n",
        "\n",
        "\n",
        "    if all_models_encoded_successfully:\n",
        "         print(\"\\n모델별 레이블 One-Hot 인코딩 단계 완료.\")\n",
        "         is_data_ready_for_training = True # Set the flag to True if all intended models were encoded successfully\n",
        "    else:\n",
        "         print(\"\\n일부 모델의 레이블 One-Hot 인코딩 실패 또는 데이터 부족.\")\n",
        "         is_data_ready_for_training = False # Set the flag to False if any intended model failed encoding\n",
        "\n",
        "else:\n",
        "    print(\"\\n임베딩 추출 실패, 클래스 수 부족, 또는 label_encoder 누락으로 레이블 One-Hot 인코딩을 건너뜁니다.\")\n",
        "    is_data_ready_for_training = False # Set the flag to False\n",
        "\n",
        "\n",
        "if is_data_ready_for_training:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 성공.\")\n",
        "else:\n",
        "    print(\"\\n데이터 로드, 임베딩 추출 및 데이터셋 준비 단계 실패: 훈련에 필요한 데이터가 부족합니다.\")\n",
        "\n",
        "\n",
        "# --- 5. 모델 구축, 학습 및 평가 실행 ---\n",
        "# Ensure build_and_train_classifier, evaluate_and_visualize_model are defined\n",
        "if 'build_and_train_classifier' not in locals():\n",
        "     print(\"오류: 'build_and_train_classifier' 함수가 정의되지 않았습니다. 모델 학습/평가를 건너뜁니다.\")\n",
        "     are_models_trained = False\n",
        "     trained_models = {}\n",
        "     training_histories = {}\n",
        "     evaluation_results = {}\n",
        "elif 'evaluate_and_visualize_model' not in locals():\n",
        "     print(\"오류: 'evaluate_and_visualize_model' 함수가 정의되지 않았습니다. 모델 평가를 건너뜁니다.\")\n",
        "     # Proceed with training if possible, but evaluation will be skipped/fail\n",
        "     pass # Let the code below handle training if possible\n",
        "\n",
        "else: # Functions are defined, proceed with training and evaluation if data is ready\n",
        "    print(\"\\n모델 구축, 학습 및 평가 실행 시작...\")\n",
        "\n",
        "    # Dictionaries to store trained models, histories, and evaluation results\n",
        "    trained_models = {}\n",
        "    training_histories = {}\n",
        "    evaluation_results = {} # To store metrics for comparison\n",
        "\n",
        "    # Ensure embedding_dims is defined (from Step 1 constants)\n",
        "    if 'embedding_dims' not in locals():\n",
        "         print(\"오류: 'embedding_dims' 전역 변수가 정의되지 않았습니다. 모델 구축/학습을 건너뜁니다.\")\n",
        "         are_models_trained = False\n",
        "    else: # embedding_dims is defined\n",
        "        are_models_trained = False # Initialize flag\n",
        "\n",
        "        if is_data_ready_for_training:\n",
        "            print(\"\\n모델별 분류기 구축, 학습 및 평가 진행 중...\")\n",
        "\n",
        "            # Use the keys from models_info to iterate through the models we intended to process\n",
        "            models_to_process_keys = models_info.keys() if 'models_info' in locals() else []\n",
        "\n",
        "            if not models_to_process_keys:\n",
        "                print(\"오류: 처리할 모델 정보가 누락되었습니다 (models_info).\")\n",
        "\n",
        "            for model_name in models_to_process_keys:\n",
        "                print(f\"\\n--- {model_name} 모델 처리 중 ---\")\n",
        "\n",
        "                # Check if all necessary data for training and evaluation exists and is not empty for this specific model\n",
        "                # These checks should align with the validation in build_and_train_classifier and evaluate_and_visualize_model\n",
        "                if model_name in X_train_embeddings and X_train_embeddings[model_name].size > 0 and \\\n",
        "                   model_name in y_train_one_hot and y_train_one_hot[model_name].size > 0 and \\\n",
        "                   model_name in X_test_embeddings and X_test_embeddings[model_name].size > 0 and \\\n",
        "                   model_name in y_test_one_hot and y_test_one_hot[model_name].size > 0 and \\\n",
        "                   model_name in y_test_filtered and y_test_filtered[model_name].size > 0 and \\\n",
        "                   model_name in y_test_encoded_filtered and y_test_encoded_filtered[model_name].size > 0 and \\\n",
        "                   model_name in embedding_dims and 'num_classes' in locals() and num_classes >= 2 and \\\n",
        "                   'label_encoder' in locals() and label_encoder is not None:\n",
        "\n",
        "                    # Get embedding dimension for the current model\n",
        "                    embedding_dim = embedding_dims[model_name]\n",
        "                    print(f\"  {model_name} 임베딩 차원: {embedding_dim}\")\n",
        "\n",
        "                    # Build and train the classifier model\n",
        "                    model, history = build_and_train_classifier(\n",
        "                        model_name=model_name,\n",
        "                        X_train=X_train_embeddings[model_name],\n",
        "                        y_train_one_hot=y_train_one_hot[model_name],\n",
        "                        X_test=X_test_embeddings[model_name], # Use X_test for validation during training\n",
        "                        y_test_one_hot=y_test_one_hot[model_name], # Use y_test_one_hot for validation during training\n",
        "                        embedding_dim=embedding_dim,\n",
        "                        num_classes=num_classes,\n",
        "                        epochs=50, # Define epochs and batch_size\n",
        "                        batch_size=16\n",
        "                    )\n",
        "\n",
        "                    # Store the trained model and history if training was successful\n",
        "                    if model is not None and history is not None:\n",
        "                        trained_models[model_name] = model\n",
        "                        training_histories[model_name] = history\n",
        "                        print(f\"  {model_name} 모델 학습 및 결과 저장 완료.\")\n",
        "                        are_models_trained = True # Set flag to True if at least one model trained\n",
        "\n",
        "                        # Evaluate the model\n",
        "                        print(f\"\\n  --- {model_name} 모델 평가 ---\")\n",
        "                        # Ensure correct arguments are passed to evaluate_and_visualize_model\n",
        "                        evaluation_metrics = evaluate_and_visualize_model(\n",
        "                            model_name=model_name,\n",
        "                            trained_model=trained_models[model_name],\n",
        "                            X_test=X_test_embeddings[model_name],\n",
        "                            y_test_one_hot=y_test_one_hot[model_name],\n",
        "                            y_test_encoded_filtered=y_test_encoded_filtered[model_name],\n",
        "                            label_encoder=label_encoder,\n",
        "                            history=training_histories[model_name]\n",
        "                        )\n",
        "                        evaluation_results[model_name] = evaluation_metrics # Store evaluation metrics\n",
        "                        print(f\"\\n  {model_name} 평가 완료.\")\n",
        "\n",
        "                    else:\n",
        "                        print(f\"  {model_name} 모델 학습 실패. 평가를 건너뜁니다.\")\n",
        "                        trained_models[model_name] = None\n",
        "                        training_histories[model_name] = None\n",
        "                        evaluation_results[model_name] = {'loss': None, 'accuracy': None} # Store None for metrics if skipped\n",
        "\n",
        "\n",
        "                else:\n",
        "                    print(f\"경고: {model_name} 모델 학습/평가를 위한 데이터 또는 필수 변수가 부족합니다. 건너뜁니다.\")\n",
        "                    trained_models[model_name] = None\n",
        "                    training_histories[model_name] = None\n",
        "                    evaluation_results[model_name] = {'loss': None, 'accuracy': None} # Store None for metrics if skipped\n",
        "\n",
        "\n",
        "            print(\"\\n모델 구축, 학습 및 평가 실행 단계 완료.\")\n",
        "\n",
        "        else:\n",
        "            print(\"\\n데이터 준비 실패로 모델 학습 및 평가를 건너뜁니다.\")\n",
        "            are_models_trained = False # Ensure flag is False if data not ready\n",
        "\n",
        "\n",
        "# --- 6. 모델 성능 비교 (요약) ---\n",
        "print(\"\\n6. 모델 성능 비교 (요약) 중...\")\n",
        "print(\"\\n--- 모델별 최종 성능 비교 ---\")\n",
        "if evaluation_results and any(metrics['accuracy'] is not None for metrics in evaluation_results.values()):\n",
        "    # Sort results by accuracy (optional, but helps in comparison)\n",
        "    sorted_results = sorted(evaluation_results.items(), key=lambda item: item[1].get('accuracy') if item[1].get('accuracy') is not None else -1, reverse=True)\n",
        "\n",
        "    for model_name, metrics in sorted_results:\n",
        "        print(f\"  {model_name}:\")\n",
        "        print(f\"    테스트 손실: {metrics['loss']:.4f}\" if metrics['loss'] is not None else \"    테스트 손실: N/A\")\n",
        "        print(f\"    테스트 정확도: {metrics['accuracy']:.4f}\" if metrics['accuracy'] is not None else \"    테스트 정확도: N/A\")\n",
        "else:\n",
        "    print(\"평가 결과가 없어 모델 성능 비교를 수행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "# --- 7. 새로운 오디오 파일에 대한 예측 (예시) ---\n",
        "print(\"\\n7. 새로운 오디오 파일 예측 예시 중...\")\n",
        "print(\"\\n--- 새로운 오디오 파일 예측 예시 ---\")\n",
        "\n",
        "# Choose one of the trained models for prediction, e.g., the best performing one or YAMNet\n",
        "# If trained_models is not empty, attempt prediction\n",
        "if trained_models:\n",
        "    # Choose the first successfully trained model for prediction example\n",
        "    model_to_predict_name = next(iter(trained_models)) # Get the name of the first key\n",
        "    model_to_predict = trained_models[model_to_predict_name]\n",
        "    print(f\"\\n예측에 사용할 모델: {model_to_predict_name}\")\n",
        "\n",
        "\n",
        "    # Need a sample audio file path for prediction\n",
        "    # Use the first path from the original combined list if available, or a dummy file\n",
        "    predict_audio_path = None\n",
        "\n",
        "    # Attempt to use the first path from the original combined list if it was populated\n",
        "    if 'all_audio_paths' in locals() and all_audio_paths:\n",
        "        predict_audio_path = all_audio_paths[0]\n",
        "        print(f\"예측을 위해 데이터셋에서 샘플 파일 선택: {predict_audio_path}\")\n",
        "    elif 'DEEPSHIP_BASE_PATH' in locals() and os.path.exists(os.path.join(DEEPSHIP_BASE_PATH, 'Cargo', '103.wav')): # Fallback to a known DeepShip file\n",
        "        predict_audio_path = os.path.join(DEEPSHIP_BASE_PATH, 'Cargo', '103.wav')\n",
        "        print(f\"예측을 위해 DeepShip에서 샘플 파일 선택: {predict_audio_path}\")\n",
        "    # Add other fallbacks here if needed\n",
        "\n",
        "    # Ensure the chosen model, label_encoder, and yamnet_model are available for prediction\n",
        "    if predict_audio_path and os.path.exists(predict_audio_path) and \\\n",
        "       model_to_predict is not None and \\\n",
        "       'label_encoder' in locals() and label_encoder is not None and \\\n",
        "       'yamnet_model' in locals() and yamnet_model is not None: # yamnet_model is needed for preprocessing in predict_on_new_audio\n",
        "\n",
        "        # Ensure predict_on_new_audio is defined and available\n",
        "        if 'predict_on_new_audio' not in locals():\n",
        "             print(\"오류: 'predict_on_new_audio' 함수가 정의되지 않았습니다. 예측을 건너뜁니다.\")\n",
        "        else:\n",
        "            # Call the predict_on_new_audio function\n",
        "            predicted_label = predict_on_new_audio(model_to_predict, yamnet_model, label_encoder, predict_audio_path)\n",
        "            # The predicted label is printed inside the function\n",
        "\n",
        "    else:\n",
        "        print(\"\\n예측을 수행할 수 없습니다:\")\n",
        "        if not predict_audio_path or not os.path.exists(predict_audio_path):\n",
        "             print(\"  예측할 오디오 파일을 찾을 수 없습니다.\")\n",
        "        if model_to_predict is None:\n",
        "             print(f\"  학습된 '{model_to_predict_name}' 모델이 없습니다.\")\n",
        "        if 'label_encoder' not in locals() or label_encoder is None:\n",
        "             print(\"  LabelEncoder가 없습니다.\")\n",
        "        if 'yamnet_model' not in locals() or yamnet_model is None:\n",
        "             print(\"  YAMNet 모델이 없습니다 (예측 전처리용).\")\n",
        "\n",
        "else: # No models were trained\n",
        "    print(\"\\n학습된 모델이 없어 예측을 수행할 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\n모델별 전체 파이프라인 실행 및 결과 비교 단계 완료.\")\n",
        "\n",
        "# Subtask is completed."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca4d54c7"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The refactoring process successfully defined functions for initial setup, data loading/preparation, audio preprocessing/embedding extraction, model loading, classifier building/training, evaluation/visualization, and prediction.\n",
        "*   The data loading and preparation step (`load_and_prepare_dataset`) was executed but failed to collect any audio files from either the cloned DeepShip directory or the specified MBARI noise data directory.\n",
        "*   This lack of data (0 samples collected, 0 classes identified) prevented the subsequent steps of embedding extraction, label one-hot encoding, model training, and evaluation from executing, as designed by the implemented data availability checks.\n",
        "*   The pipeline correctly identified the data insufficiency and skipped the computationally intensive steps.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Critical Data Acquisition:** The most critical next step is to acquire the necessary audio data. This includes:\n",
        "    *   Verifying the structure of the cloned DeepShip repository (`/content/DeepShip`) to understand why the `load_and_prepare_dataset` function is not finding the `.wav` files within the expected class subdirectories. Manual inspection of the `/content/DeepShip` directory contents might be necessary.\n",
        "    *   Acquiring a substantial amount of MBARI noise data (or other relevant noise data) and placing it in the designated `MBARI_NOISE_BASE_DIR` (`/content/MBARI_noise_data`). The previous attempts to download sample files were not sufficient or successful in populating this directory with enough noise data.\n",
        "*   **Re-run Pipeline:** Once sufficient data for both 'ship' and 'noise' classes (at least 2 samples per class for stratified splitting) is placed in the correct directories, the entire pipeline (starting from Step 6 which executes data loading, embedding, training, evaluation) needs to be re-executed. The existing code is designed to handle the process once data is available.\n",
        "*   **Review Data Loading Logic:** If DeepShip files are still not found after verifying the directory structure, the `load_and_prepare_dataset` function's DeepShip traversal logic may need further debugging or adjustment based on the actual file paths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edb528a8"
      },
      "source": [
        "## 데이터 디렉토리 구조 및 내용 확인\n",
        "\n",
        "DeepShip 데이터셋 및 MBARI 노이즈 데이터 디렉토리의 실제 내용을 확인하여 데이터 로드 문제의 원인을 파악합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3b50a70"
      },
      "source": [
        "import os\n",
        "\n",
        "# Assuming DEEPSHIP_BASE_PATH and MBARI_NOISE_BASE_DIR are defined\n",
        "\n",
        "print(\"\\nDeepShip 데이터 디렉토리 내용 확인:\")\n",
        "if os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    print(f\"'{DEEPSHIP_BASE_PATH}' 내용:\")\n",
        "    # List contents of the DeepShip base directory, focusing on the expected class folders\n",
        "    expected_deepship_subdirs = DEEPSHIP_CLASSES # Use the global constant\n",
        "    found_content = False\n",
        "    for item in os.listdir(DEEPSHIP_BASE_PATH):\n",
        "        item_path = os.path.join(DEEPSHIP_BASE_PATH, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"  {item}/\")\n",
        "            # If it's an expected class directory, list some of its contents\n",
        "            if item in expected_deepship_subdirs:\n",
        "                 try:\n",
        "                     files_in_class_dir = os.listdir(item_path)\n",
        "                     print(f\"    ({len(files_in_class_dir)} items)\")\n",
        "                     for f in files_in_class_dir[:5]: # List up to 5 files\n",
        "                         print(f\"      {f}\")\n",
        "                     if len(files_in_class_dir) > 5:\n",
        "                         print(\"      ...\")\n",
        "                     found_content = True\n",
        "                 except Exception as e:\n",
        "                      print(f\"    오류: 디렉토리 내용 확인 중 오류 발생: {e}\")\n",
        "            else:\n",
        "                 # List contents of unexpected subdirectories briefly\n",
        "                 try:\n",
        "                      sub_items = os.listdir(item_path)\n",
        "                      print(f\"    ({len(sub_items)} items)\")\n",
        "                      for f in sub_items[:3]: # List up to 3 items in other subdirs\n",
        "                          print(f\"      {f}\")\n",
        "                      if len(sub_items) > 3:\n",
        "                          print(\"      ...\")\n",
        "                 except Exception as e:\n",
        "                      print(f\"    오류: 디렉토리 내용 확인 중 오류 발생: {e}\")\n",
        "\n",
        "        elif os.path.isfile(item_path):\n",
        "            print(f\"  {item}\")\n",
        "            found_content = True\n",
        "\n",
        "    if not found_content:\n",
        "        print(\"  (디렉토리가 비어 있습니다)\")\n",
        "\n",
        "else:\n",
        "    print(f\"경고: DeepShip Base Path '{DEEPSHIP_BASE_PATH}'를 찾을 수 없습니다.\")\n",
        "\n",
        "\n",
        "print(\"\\nMBARI 노이즈 데이터 디렉토리 내용 확인:\")\n",
        "if os.path.exists(MBARI_NOISE_BASE_DIR):\n",
        "    print(f\"'{MBARI_NOISE_BASE_DIR}' 내용:\")\n",
        "    found_noise_content = False\n",
        "    for root, dirs, files in os.walk(MBARI_NOISE_BASE_DIR):\n",
        "        level = root.replace(MBARI_NOISE_BASE_DIR, '').count(os.sep)\n",
        "        indent = '  ' * level\n",
        "        print(f'{indent}{os.path.basename(root)}/')\n",
        "        subindent = '  ' * (level + 1)\n",
        "        if dirs:\n",
        "             for d in dirs[:5]: # List up to 5 subdirectories\n",
        "                  print(f'{subindent}{d}/')\n",
        "             if len(dirs) > 5:\n",
        "                  print(f'{subindent}...')\n",
        "\n",
        "        if files:\n",
        "             print(f'{subindent}파일들 ({len(files)}개):')\n",
        "             for f in files[:5]: # List up to 5 files\n",
        "                 print(f'{subindent}{f}')\n",
        "                 if f.endswith('.wav'):\n",
        "                      found_noise_content = True # Found at least one wav file\n",
        "             if len(files) > 5:\n",
        "                  print(f'{subindent}...')\n",
        "        if not dirs and not files:\n",
        "             print(f'{subindent}(비어 있음)')\n",
        "\n",
        "\n",
        "    if not found_noise_content:\n",
        "        print(\"\\n경고: MBARI 노이즈 데이터 디렉토리에서 .wav 파일을 찾지 못했습니다.\")\n",
        "\n",
        "else:\n",
        "    print(f\"경고: MBARI Noise Base Directory '{MBARI_NOISE_BASE_DIR}'를 찾을 수 없습니다.\")\n",
        "\n",
        "print(\"\\n데이터 디렉토리 내용 확인 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57a87fcb"
      },
      "source": [
        "# Install boto3 for S3 access\n",
        "!pip install -q boto3\n",
        "print(\"boto3 설치 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21045205"
      },
      "source": [
        "## 2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비\n",
        "\n",
        "DeepShip 데이터셋을 클론하고, MBARI 노이즈 데이터 디렉토리를 준비합니다. 이전에 다운로드된 MBARI 노이즈 샘플 파일이 있다면 해당 디렉토리로 이동시킵니다.\n",
        "\n",
        "**주의**: 실제 MBARI Pacific Sound 16kHz 데이터셋은 직접 다운로드 또는 접근 설정이 필요할 수 있습니다. 아래 코드는 DeepShip 클론 및 샘플 노이즈 파일 처리를 위한 예시입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8ec3652"
      },
      "source": [
        "# ==============================================================================\n",
        "# 2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 (MBARI 다운로드 포함)\n",
        "# ==============================================================================\n",
        "import boto3 # Ensure boto3 is imported\n",
        "from botocore import UNSIGNED # Ensure UNSIGNED config is imported\n",
        "from botocore.client import Config # Ensure Config is imported\n",
        "from pathlib import Path # Ensure Path is imported\n",
        "import io # Ensure io is imported for potential in-memory reads (though we're downloading)\n",
        "from six.moves.urllib.request import urlopen # Ensure urlopen is imported if still needed (less likely with direct S3 download)\n",
        "import os # Ensure os is imported\n",
        "import subprocess # Ensure subprocess is imported\n",
        "\n",
        "print(\"\\n2. 데이터 확보: DeepShip 클론 및 노이즈 데이터 준비 중...\")\n",
        "\n",
        "# Check if DeepShip is already cloned\n",
        "if not os.path.exists(DEEPSHIP_BASE_PATH):\n",
        "    print(f\"DeepShip 데이터셋 클론 중: {DEEPSHIP_BASE_PATH}\")\n",
        "    # Clone the DeepShip repository\n",
        "    # Use --depth 1 to clone only the latest commit, saving time and space\n",
        "    try:\n",
        "        subprocess.run(['git', 'clone', '--depth', '1', 'https://github.com/irfankamboh/DeepShip.git', DEEPSHIP_BASE_PATH], check=True, capture_output=True)\n",
        "        print(\"DeepShip 데이터셋 클론 완료.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"오류: DeepShip 데이터셋 클론 실패: {e.stderr.decode()}\")\n",
        "        print(\"수동으로 https://github.com/irfankamboh/DeepShip.git 를 클론하거나 다운로드하여\")\n",
        "        print(f\"'{DEEPSHIP_BASE_PATH}' 경로에 위치시켜주세요.\")\n",
        "    except Exception as e:\n",
        "         print(f\"오류: DeepShip 데이터셋 클론 중 예기치 않은 오류 발생: {e}\")\n",
        "else:\n",
        "    print(f\"DeepShip 데이터셋이 이미 존재합니다: {DEEPSHIP_BASE_PATH}\")\n",
        "\n",
        "# Ensure the MBARI noise base directory exists\n",
        "os.makedirs(MBARI_NOISE_BASE_DIR, exist_ok=True)\n",
        "print(f\"MBARI 노이즈 데이터 디렉토리 확인/생성 완료: {MBARI_NOISE_BASE_DIR}\")\n",
        "\n",
        "\n",
        "# --- MBARI Noise Data Download ---\n",
        "# Use Boto3 to access the public S3 bucket and download a limited number of files\n",
        "# Based on the provided documentation example.\n",
        "s3_client = boto3.client('s3',\n",
        "    aws_access_key_id='',\n",
        "    aws_secret_access_key='',\n",
        "    config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "bucket = 'pacific-sound-16khz'\n",
        "# Define a prefix to narrow down the files (e.g., a specific year and month)\n",
        "# The documentation example uses '2018/01/'. Let's keep this or choose another if needed.\n",
        "prefix = '2018/01/' # Using January 2018 data as example\n",
        "\n",
        "# Limit the number of files to download to avoid excessive processing time and storage\n",
        "MAX_NOISE_FILES_TO_DOWNLOAD = 200 # Set a reasonable limit for demonstration\n",
        "\n",
        "print(f\"\\nMBARI 노이즈 데이터 다운로드 시도 중 (S3 버킷: {bucket}, Prefix: {prefix}, 최대 {MAX_NOISE_FILES_TO_DOWNLOAD} 파일):\")\n",
        "\n",
        "try:\n",
        "    # List objects in the specified bucket and prefix, potentially in pages\n",
        "    paginator = s3_client.get_paginator('list_objects_v2')\n",
        "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
        "\n",
        "    downloaded_count = 0\n",
        "    found_any_objects = False # Track if any objects were found at all\n",
        "\n",
        "    for page in pages:\n",
        "        if 'Contents' in page:\n",
        "            found_any_objects = True\n",
        "            # print(f\"  페이지에서 {len(page['Contents'])}개의 파일 발견. 다운로드 가능한 .wav 파일 탐색 중...\") # Too verbose\n",
        "\n",
        "            for obj in page['Contents']:\n",
        "                key = obj['Key']\n",
        "                # Only download .wav files and avoid directories or empty files\n",
        "                if key.endswith('.wav') and obj.get('Size', 0) > 0:\n",
        "                    # Construct the local file path to save within the MBARI_NOISE_BASE_DIR\n",
        "                    local_file_path = os.path.join(MBARI_NOISE_BASE_DIR, os.path.basename(key))\n",
        "\n",
        "                    # Check if the file already exists locally to avoid re-downloading\n",
        "                    if os.path.exists(local_file_path):\n",
        "                        # print(f\"    파일이 이미 존재합니다. 건너뜁니다: {os.path.basename(key)}\") # Too verbose\n",
        "                        pass # Skip if file already exists\n",
        "                    else:\n",
        "                        print(f\"    다운로드 중: {os.path.basename(key)}...\")\n",
        "                        try:\n",
        "                            s3_client.download_file(bucket, key, local_file_path)\n",
        "                            downloaded_count += 1\n",
        "                            print(f\"      다운로드 완료 ({downloaded_count}/{MAX_NOISE_FILES_TO_DOWNLOAD})\")\n",
        "                        except Exception as download_e:\n",
        "                             print(f\"    오류: 파일 다운로드 실패 ({os.path.basename(key)}): {download_e}\")\n",
        "\n",
        "                    # Stop downloading once the limit is reached\n",
        "                    if downloaded_count >= MAX_NOISE_FILES_TO_DOWNLOAD:\n",
        "                        print(f\"\\n  최대 다운로드 파일 수({MAX_NOISE_FILES_TO_DOWNLOAD})에 도달했습니다. 다운로드를 중지합니다.\")\n",
        "                        break # Break from the inner loop (files in this page)\n",
        "\n",
        "            if downloaded_count >= MAX_NOISE_FILES_TO_DOWNLOAD:\n",
        "                 break # Break from the outer loop (pages)\n",
        "\n",
        "\n",
        "    if not found_any_objects:\n",
        "        print(f\"  경고: 지정된 Prefix '{prefix}'에서 파일을 찾을 수 없습니다.\")\n",
        "    elif downloaded_count == 0:\n",
        "         print(f\"\\n  총 {len(response.get('Contents', []))}개 이상의 파일이 S3 버킷에 있지만, 지정된 Prefix에서 다운로드 가능한 .wav 파일을 찾지 못했거나 모두 건너뛰었습니다.\")\n",
        "\n",
        "\n",
        "    print(f\"\\n총 {downloaded_count}개의 노이즈 .wav 파일을 다운로드했습니다.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"오류: MBARI 노이즈 데이터 다운로드 중 오류 발생: {e}\")\n",
        "    print(\"S3 버킷 접근 권한, Prefix 설정, 또는 Boto3 설정/설치를 확인해주세요.\")\n",
        "\n",
        "\n",
        "# Note: To get sufficient noise data for meaningful training, you may need to adjust the 'prefix'\n",
        "# or 'MAX_NOISE_FILES_TO_DOWNLOAD', or implement more complex logic to gather data from multiple\n",
        "# prefixes/months, depending on your data needs and the S3 bucket structure.\n",
        "# Ensure that the downloaded data includes enough samples from the 'noise' category.\n",
        "print(\"\\n2. 데이터 확보 단계 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}